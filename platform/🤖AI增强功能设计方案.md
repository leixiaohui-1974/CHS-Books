# ğŸ¤– AIå¢å¼ºåŠŸèƒ½è®¾è®¡æ–¹æ¡ˆ

**ç‰ˆæœ¬**: v1.0  
**åˆ¶å®šæ—¥æœŸ**: 2025-11-12  
**è´Ÿè´£æ¨¡å—**: AIæ™ºèƒ½åŒ–åŠŸèƒ½

---

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [æ™ºèƒ½æ¨èç³»ç»Ÿ](#æ™ºèƒ½æ¨èç³»ç»Ÿ)
- [æ™ºèƒ½ç­”ç–‘ç³»ç»Ÿ](#æ™ºèƒ½ç­”ç–‘ç³»ç»Ÿ)
- [ä»£ç æ™ºèƒ½åˆ†æ](#ä»£ç æ™ºèƒ½åˆ†æ)
- [å­¦ä¹ è·¯å¾„è§„åˆ’](#å­¦ä¹ è·¯å¾„è§„åˆ’)
- [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)

---

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

### AIåŠŸèƒ½å…¨æ™¯å›¾

```
Platform AIèƒ½åŠ›çŸ©é˜µ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚  ğŸ¯ æ™ºèƒ½æ¨è                                 â”‚
â”‚  â”œâ”€ å†…å®¹æ¨è (è¯¾ç¨‹ã€ç« èŠ‚ã€æ¡ˆä¾‹)              â”‚
â”‚  â”œâ”€ ååŒè¿‡æ»¤ (åŸºäºç›¸ä¼¼ç”¨æˆ·)                  â”‚
â”‚  â”œâ”€ çŸ¥è¯†å›¾è°±æ¨è                             â”‚
â”‚  â””â”€ è‡ªé€‚åº”éš¾åº¦æ¨è                           â”‚
â”‚                                             â”‚
â”‚  ğŸ’¬ æ™ºèƒ½ç­”ç–‘                                 â”‚
â”‚  â”œâ”€ å¤šè½®å¯¹è¯                                 â”‚
â”‚  â”œâ”€ ä¸Šä¸‹æ–‡ç†è§£                               â”‚
â”‚  â”œâ”€ çŸ¥è¯†æ£€ç´¢å¢å¼º (RAG)                       â”‚
â”‚  â””â”€ å¾ªåºæ¸è¿›æç¤º                             â”‚
â”‚                                             â”‚
â”‚  ğŸ’» ä»£ç åˆ†æ                                 â”‚
â”‚  â”œâ”€ ä»£ç è´¨é‡åˆ†æ                             â”‚
â”‚  â”œâ”€ Bugæ£€æµ‹                                  â”‚
â”‚  â”œâ”€ æ€§èƒ½ä¼˜åŒ–å»ºè®®                             â”‚
â”‚  â””â”€ æœ€ä½³å®è·µæ¨è                             â”‚
â”‚                                             â”‚
â”‚  ğŸ“š å­¦ä¹ è§„åˆ’                                 â”‚
â”‚  â”œâ”€ ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„                           â”‚
â”‚  â”œâ”€ è–„å¼±ç¯èŠ‚è¯Šæ–­                             â”‚
â”‚  â”œâ”€ è¿›åº¦é¢„æµ‹                                 â”‚
â”‚  â””â”€ å¤ä¹ è®¡åˆ’ç”Ÿæˆ                             â”‚
â”‚                                             â”‚
â”‚  ğŸ“ å†…å®¹ç”Ÿæˆ                                 â”‚
â”‚  â”œâ”€ ç»ƒä¹ é¢˜ç”Ÿæˆ                               â”‚
â”‚  â”œâ”€ è§£é‡Šç”Ÿæˆ                                 â”‚
â”‚  â”œâ”€ ç¤ºä¾‹ä»£ç ç”Ÿæˆ                             â”‚
â”‚  â””â”€ çŸ¥è¯†æ€»ç»“                                 â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç›®æ ‡

```yaml
å‡†ç¡®æ€§: 
  - ç­”æ¡ˆå‡†ç¡®ç‡ > 90%
  - æ¨èå‡†ç¡®ç‡ > 85%
  - ä»£ç åˆ†æå‡†ç¡®ç‡ > 95%

å“åº”é€Ÿåº¦:
  - æ¨èå“åº” < 500ms
  - å¯¹è¯å“åº” < 2s
  - ä»£ç åˆ†æ < 3s

ç”¨æˆ·ä½“éªŒ:
  - ç”¨æˆ·æ»¡æ„åº¦ > 4.5/5
  - é‡‡çº³ç‡ > 70%
  - åé¦ˆæ”¹è¿›ç‡ > 80%

æˆæœ¬æ§åˆ¶:
  - APIè°ƒç”¨æˆæœ¬ < Â¥0.1/æ¬¡
  - ç¼“å­˜å‘½ä¸­ç‡ > 60%
  - æœ¬åœ°æ¨¡å‹è¦†ç›–ç‡ > 40%
```

---

## ğŸ¯ æ™ºèƒ½æ¨èç³»ç»Ÿ

### 1. å¤šç»´æ¨èå¼•æ“

```python
from typing import List, Dict
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class RecommendationEngine:
    """å¤šç»´æ¨èå¼•æ“"""
    
    def __init__(self):
        self.user_embeddings = {}
        self.content_embeddings = {}
        self.knowledge_graph = KnowledgeGraph()
        
    async def recommend(
        self, 
        user_id: int, 
        context: dict,
        limit: int = 10
    ) -> List[Dict]:
        """ç»¼åˆæ¨è"""
        # 1. è·å–ç”¨æˆ·ç”»åƒ
        user_profile = await self.get_user_profile(user_id)
        
        # 2. å¤šè·¯å¬å›
        candidates = await self.multi_recall(user_id, user_profile, context)
        
        # 3. ç‰¹å¾å·¥ç¨‹
        features = await self.extract_features(candidates, user_profile)
        
        # 4. æ’åº
        ranked = await self.rank_candidates(candidates, features)
        
        # 5. å¤šæ ·æ€§&å»é‡
        final = self.diversify(ranked, limit)
        
        return final
    
    async def multi_recall(
        self, 
        user_id: int, 
        user_profile: dict,
        context: dict
    ) -> List[Dict]:
        """å¤šè·¯å¬å›ç­–ç•¥"""
        candidates = []
        
        # è·¯å¾„1: ååŒè¿‡æ»¤
        cf_items = await self.collaborative_filtering(user_id, limit=50)
        candidates.extend(cf_items)
        
        # è·¯å¾„2: å†…å®¹åŒ¹é…
        content_items = await self.content_based_filtering(
            user_profile, limit=50
        )
        candidates.extend(content_items)
        
        # è·¯å¾„3: çŸ¥è¯†å›¾è°±
        kg_items = await self.knowledge_graph_recommend(
            user_profile, context, limit=30
        )
        candidates.extend(kg_items)
        
        # è·¯å¾„4: çƒ­é—¨æ¨è
        popular_items = await self.popular_recommend(limit=20)
        candidates.extend(popular_items)
        
        # è·¯å¾„5: åºåˆ—æ¨è
        seq_items = await self.sequence_recommend(user_id, limit=30)
        candidates.extend(seq_items)
        
        return candidates
    
    async def collaborative_filtering(
        self, 
        user_id: int, 
        limit: int
    ) -> List[Dict]:
        """ååŒè¿‡æ»¤æ¨è"""
        # 1. æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·
        similar_users = await self.find_similar_users(user_id, k=20)
        
        # 2. æ”¶é›†ç›¸ä¼¼ç”¨æˆ·çš„å­¦ä¹ å†…å®¹
        items = []
        for sim_user, similarity in similar_users:
            # è·å–è¯¥ç”¨æˆ·æœ€è¿‘å­¦ä¹ çš„å†…å®¹
            user_items = await LearningProgress.filter(
                user_id=sim_user,
                completed=True
            ).order_by('-updated_at').limit(10)
            
            for item in user_items:
                # æ£€æŸ¥å½“å‰ç”¨æˆ·æ˜¯å¦å·²å­¦ä¹ 
                learned = await LearningProgress.filter(
                    user_id=user_id,
                    chapter_id=item.chapter_id
                ).exists()
                
                if not learned:
                    items.append({
                        'chapter_id': item.chapter_id,
                        'score': similarity,
                        'reason': f'ç›¸ä¼¼ç”¨æˆ·ä¹Ÿåœ¨å­¦ä¹ ',
                        'source': 'collaborative_filtering'
                    })
        
        # 3. æŒ‰ç›¸ä¼¼åº¦å¾—åˆ†æ’åº
        items.sort(key=lambda x: x['score'], reverse=True)
        
        return items[:limit]
    
    async def find_similar_users(
        self, 
        user_id: int, 
        k: int = 20
    ) -> List[tuple]:
        """æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·"""
        # 1. è·å–ç”¨æˆ·çš„å­¦ä¹ å‘é‡
        user_vector = await self.get_user_vector(user_id)
        
        # 2. è®¡ç®—ä¸æ‰€æœ‰ç”¨æˆ·çš„ç›¸ä¼¼åº¦
        all_users = await User.all()
        similarities = []
        
        for other_user in all_users:
            if other_user.id == user_id:
                continue
                
            other_vector = await self.get_user_vector(other_user.id)
            similarity = cosine_similarity(
                [user_vector], 
                [other_vector]
            )[0][0]
            
            similarities.append((other_user.id, similarity))
        
        # 3. è¿”å›Top-K
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:k]
    
    async def get_user_vector(self, user_id: int) -> np.ndarray:
        """è·å–ç”¨æˆ·å‘é‡"""
        # åŸºäºç”¨æˆ·çš„å­¦ä¹ å†å²æ„å»ºå‘é‡
        # [ç« èŠ‚åå¥½, éš¾åº¦åå¥½, ä¸»é¢˜åå¥½, ...]
        
        progress = await LearningProgress.filter(
            user_id=user_id
        ).prefetch_related('chapter')
        
        # ç‰¹å¾ç»´åº¦
        features = {
            'total_chapters': len(progress),
            'completion_rate': sum(1 for p in progress if p.completed) / len(progress) if progress else 0,
            'avg_time_spent': np.mean([p.time_spent for p in progress]) if progress else 0,
            # ... æ›´å¤šç‰¹å¾
        }
        
        # è½¬æ¢ä¸ºå‘é‡
        vector = np.array(list(features.values()))
        
        # ç¼“å­˜
        self.user_embeddings[user_id] = vector
        
        return vector
    
    async def content_based_filtering(
        self, 
        user_profile: dict, 
        limit: int
    ) -> List[Dict]:
        """åŸºäºå†…å®¹çš„æ¨è"""
        # 1. è·å–ç”¨æˆ·åå¥½çš„ä¸»é¢˜
        preferred_topics = user_profile.get('preferred_topics', [])
        
        # 2. è·å–ç”¨æˆ·å½“å‰æ°´å¹³
        current_level = user_profile.get('level', 'intermediate')
        
        # 3. æŸ¥è¯¢åŒ¹é…çš„å†…å®¹
        chapters = await Chapter.filter(
            tags__overlap=preferred_topics,
            difficulty=current_level
        ).order_by('-created_at').limit(limit)
        
        items = []
        for chapter in chapters:
            items.append({
                'chapter_id': chapter.id,
                'score': 0.8,  # åŸºç¡€å¾—åˆ†
                'reason': f'åŒ¹é…æ‚¨çš„å…´è¶£: {", ".join(preferred_topics)}',
                'source': 'content_based'
            })
        
        return items
    
    async def knowledge_graph_recommend(
        self, 
        user_profile: dict,
        context: dict,
        limit: int
    ) -> List[Dict]:
        """åŸºäºçŸ¥è¯†å›¾è°±çš„æ¨è"""
        # 1. è·å–ç”¨æˆ·å½“å‰å­¦ä¹ çš„çŸ¥è¯†ç‚¹
        current_chapter_id = context.get('current_chapter_id')
        if not current_chapter_id:
            return []
        
        # 2. ä»çŸ¥è¯†å›¾è°±ä¸­æŸ¥æ‰¾ç›¸å…³çŸ¥è¯†ç‚¹
        related_points = await self.knowledge_graph.get_related(
            current_chapter_id,
            relation_types=['prerequisite', 'related', 'advanced']
        )
        
        # 3. æ¨èåŒ…å«è¿™äº›çŸ¥è¯†ç‚¹çš„ç« èŠ‚
        items = []
        for point, relation, strength in related_points:
            chapters = await Chapter.filter(
                knowledge_points__contains=[point]
            ).limit(5)
            
            for chapter in chapters:
                items.append({
                    'chapter_id': chapter.id,
                    'score': strength,
                    'reason': f'{relation}: {point}',
                    'source': 'knowledge_graph'
                })
        
        items.sort(key=lambda x: x['score'], reverse=True)
        return items[:limit]
    
    async def sequence_recommend(
        self, 
        user_id: int, 
        limit: int
    ) -> List[Dict]:
        """åºåˆ—æ¨è (åŸºäºå­¦ä¹ è·¯å¾„)"""
        # 1. è·å–ç”¨æˆ·çš„å­¦ä¹ åºåˆ—
        learning_seq = await LearningProgress.filter(
            user_id=user_id,
            completed=True
        ).order_by('completed_at').values_list('chapter_id', flat=True)
        
        # 2. ä½¿ç”¨åºåˆ—æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªç« èŠ‚
        # (å¯ä»¥ä½¿ç”¨RNN/LSTM/Transformerç­‰åºåˆ—æ¨¡å‹)
        next_chapters = await self.predict_next_chapters(
            learning_seq, 
            limit
        )
        
        items = []
        for chapter_id, prob in next_chapters:
            items.append({
                'chapter_id': chapter_id,
                'score': prob,
                'reason': 'æ¨èçš„å­¦ä¹ è·¯å¾„',
                'source': 'sequence'
            })
        
        return items
    
    async def rank_candidates(
        self, 
        candidates: List[Dict],
        features: np.ndarray
    ) -> List[Dict]:
        """å€™é€‰æ’åº"""
        # ä½¿ç”¨LightGBMæˆ–æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œæ’åº
        # è¿™é‡Œç®€åŒ–ä¸ºåŠ æƒç»„åˆ
        
        weights = {
            'collaborative_filtering': 0.3,
            'content_based': 0.25,
            'knowledge_graph': 0.25,
            'sequence': 0.15,
            'popular': 0.05
        }
        
        for candidate in candidates:
            source = candidate['source']
            candidate['final_score'] = (
                candidate['score'] * weights.get(source, 0.1)
            )
        
        # å»é‡ (åŒä¸€ç« èŠ‚åªä¿ç•™å¾—åˆ†æœ€é«˜çš„)
        seen = {}
        for candidate in candidates:
            chapter_id = candidate['chapter_id']
            if chapter_id not in seen or \
               candidate['final_score'] > seen[chapter_id]['final_score']:
                seen[chapter_id] = candidate
        
        # æ’åº
        ranked = list(seen.values())
        ranked.sort(key=lambda x: x['final_score'], reverse=True)
        
        return ranked
    
    def diversify(self, items: List[Dict], limit: int) -> List[Dict]:
        """å¤šæ ·æ€§å¤„ç†"""
        # MMR (Maximal Marginal Relevance) ç®—æ³•
        selected = []
        candidates = items.copy()
        
        if not candidates:
            return []
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ä½œä¸ºç¬¬ä¸€ä¸ª
        selected.append(candidates.pop(0))
        
        while len(selected) < limit and candidates:
            max_mmr = -float('inf')
            max_idx = 0
            
            for i, candidate in enumerate(candidates):
                # è®¡ç®—ä¸å·²é€‰é¡¹çš„ç›¸ä¼¼åº¦
                similarities = [
                    self.item_similarity(candidate, s) 
                    for s in selected
                ]
                max_sim = max(similarities) if similarities else 0
                
                # MMRå¾—åˆ†
                mmr = 0.7 * candidate['final_score'] - 0.3 * max_sim
                
                if mmr > max_mmr:
                    max_mmr = mmr
                    max_idx = i
            
            selected.append(candidates.pop(max_idx))
        
        return selected
    
    def item_similarity(self, item1: dict, item2: dict) -> float:
        """è®¡ç®—é¡¹ç›®ç›¸ä¼¼åº¦"""
        # ç®€åŒ–ç‰ˆ: åŸºäºç« èŠ‚æ‰€å±çš„ä¹¦ç±
        # å®é™…å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç›¸ä¼¼åº¦è®¡ç®—
        if item1.get('book_id') == item2.get('book_id'):
            return 0.8
        return 0.2
```

### 2. è‡ªé€‚åº”éš¾åº¦æ¨è

```python
class AdaptiveDifficultyRecommender:
    """è‡ªé€‚åº”éš¾åº¦æ¨è"""
    
    async def recommend_exercises(
        self, 
        user_id: int, 
        knowledge_point_id: int,
        count: int = 5
    ) -> List[Exercise]:
        """æ¨èåˆé€‚éš¾åº¦çš„ç»ƒä¹ """
        # 1. è¯„ä¼°ç”¨æˆ·èƒ½åŠ›
        user_ability = await self.estimate_user_ability(
            user_id, 
            knowledge_point_id
        )
        
        # 2. é€‰æ‹©åˆé€‚éš¾åº¦çš„ç»ƒä¹ 
        exercises = await self.select_exercises(
            knowledge_point_id,
            user_ability,
            count
        )
        
        return exercises
    
    async def estimate_user_ability(
        self, 
        user_id: int, 
        knowledge_point_id: int
    ) -> float:
        """ä¼°è®¡ç”¨æˆ·èƒ½åŠ› (IRTæ¨¡å‹)"""
        # è·å–ç”¨æˆ·çš„å†å²è¡¨ç°
        records = await ExerciseRecord.filter(
            user_id=user_id,
            exercise__knowledge_points__contains=[knowledge_point_id]
        ).order_by('-created_at').limit(20)
        
        if not records:
            return 0.5  # é»˜è®¤ä¸­ç­‰èƒ½åŠ›
        
        # è®¡ç®—æ­£ç¡®ç‡
        correct = sum(1 for r in records if r.passed)
        total = len(records)
        accuracy = correct / total
        
        # è€ƒè™‘é¢˜ç›®éš¾åº¦
        # (ç®€åŒ–ç‰ˆIRTï¼Œå®é™…å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å‹)
        ability = accuracy
        
        # è°ƒæ•´: å¦‚æœæœ€è¿‘è¡¨ç°å¥½ï¼Œæé«˜èƒ½åŠ›è¯„ä¼°
        recent_records = records[:5]
        recent_accuracy = sum(1 for r in recent_records if r.passed) / len(recent_records)
        
        if recent_accuracy > accuracy + 0.2:
            ability = min(1.0, ability + 0.1)
        elif recent_accuracy < accuracy - 0.2:
            ability = max(0.0, ability - 0.1)
        
        return ability
    
    async def select_exercises(
        self, 
        knowledge_point_id: int,
        user_ability: float,
        count: int
    ) -> List[Exercise]:
        """é€‰æ‹©ç»ƒä¹ """
        # é€‰æ‹©éš¾åº¦æ¥è¿‘ç”¨æˆ·èƒ½åŠ›çš„ç»ƒä¹ 
        target_difficulty = user_ability
        
        # åˆ†å¸ƒ: 70%æ¥è¿‘èƒ½åŠ›, 20%ç¨éš¾, 10%ç¨æ˜“
        exercises = []
        
        # 70% æ¥è¿‘èƒ½åŠ›
        near_count = int(count * 0.7)
        near_exercises = await Exercise.filter(
            knowledge_points__contains=[knowledge_point_id],
            difficulty_score__gte=target_difficulty - 0.1,
            difficulty_score__lte=target_difficulty + 0.1
        ).order_by('?').limit(near_count)
        exercises.extend(near_exercises)
        
        # 20% ç¨éš¾
        hard_count = int(count * 0.2)
        hard_exercises = await Exercise.filter(
            knowledge_points__contains=[knowledge_point_id],
            difficulty_score__gt=target_difficulty + 0.1,
            difficulty_score__lte=target_difficulty + 0.3
        ).order_by('?').limit(hard_count)
        exercises.extend(hard_exercises)
        
        # 10% ç¨æ˜“
        easy_count = count - len(exercises)
        easy_exercises = await Exercise.filter(
            knowledge_points__contains=[knowledge_point_id],
            difficulty_score__gte=target_difficulty - 0.3,
            difficulty_score__lt=target_difficulty - 0.1
        ).order_by('?').limit(easy_count)
        exercises.extend(easy_exercises)
        
        return exercises
```

---

## ğŸ’¬ æ™ºèƒ½ç­”ç–‘ç³»ç»Ÿ

### RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) æ¶æ„

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

class IntelligentTutorSystem:
    """æ™ºèƒ½å¯¼å¸ˆç³»ç»Ÿ"""
    
    def __init__(self):
        # åˆå§‹åŒ–ç»„ä»¶
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            embedding_function=self.embeddings,
            persist_directory="./chroma_db"
        )
        self.llm = ChatOpenAI(
            model_name="gpt-4",
            temperature=0.7
        )
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
    async def answer_question(
        self, 
        user_id: int,
        question: str,
        context: dict = None
    ) -> dict:
        """å›ç­”é—®é¢˜"""
        # 1. ç†è§£é—®é¢˜æ„å›¾
        intent = await self.understand_intent(question)
        
        # 2. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        relevant_docs = await self.retrieve_knowledge(
            question, 
            context,
            k=5
        )
        
        # 3. è·å–ç”¨æˆ·å­¦ä¹ å†å²
        user_context = await self.get_user_context(user_id)
        
        # 4. ç”Ÿæˆç­”æ¡ˆ
        answer = await self.generate_answer(
            question,
            relevant_docs,
            user_context,
            intent
        )
        
        # 5. åå¤„ç†
        answer = await self.post_process(answer, intent)
        
        return {
            'answer': answer['text'],
            'sources': answer['sources'],
            'confidence': answer['confidence'],
            'follow_up_questions': answer['follow_ups']
        }
    
    async def understand_intent(self, question: str) -> dict:
        """ç†è§£é—®é¢˜æ„å›¾"""
        prompt = f"""
        åˆ†æä»¥ä¸‹é—®é¢˜çš„æ„å›¾ç±»å‹:
        é—®é¢˜: {question}
        
        å¯èƒ½çš„æ„å›¾ç±»å‹:
        - concept_explanation: æ¦‚å¿µè§£é‡Š
        - problem_solving: é—®é¢˜æ±‚è§£
        - code_debug: ä»£ç è°ƒè¯•
        - learning_guidance: å­¦ä¹ æŒ‡å¯¼
        - comparison: æ¦‚å¿µå¯¹æ¯”
        - application: å®é™…åº”ç”¨
        
        è¿”å›JSONæ ¼å¼:
        {{
            "intent": "æ„å›¾ç±»å‹",
            "entities": ["æå–çš„å®ä½“"],
            "difficulty": "easy/medium/hard"
        }}
        """
        
        response = await self.llm.agenerate([prompt])
        intent = json.loads(response.generations[0][0].text)
        
        return intent
    
    async def retrieve_knowledge(
        self, 
        question: str,
        context: dict,
        k: int = 5
    ) -> List[Document]:
        """æ£€ç´¢ç›¸å…³çŸ¥è¯†"""
        # 1. åŸºç¡€æ£€ç´¢
        docs = self.vectorstore.similarity_search(question, k=k)
        
        # 2. å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œè¿›è¡Œè¿‡æ»¤
        if context and context.get('current_chapter_id'):
            chapter_id = context['current_chapter_id']
            # ä¼˜å…ˆè¿”å›å½“å‰ç« èŠ‚çš„å†…å®¹
            chapter_docs = [
                d for d in docs 
                if d.metadata.get('chapter_id') == chapter_id
            ]
            
            if chapter_docs:
                docs = chapter_docs + [
                    d for d in docs 
                    if d not in chapter_docs
                ][:k-len(chapter_docs)]
        
        return docs
    
    async def get_user_context(self, user_id: int) -> dict:
        """è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡"""
        # è·å–ç”¨æˆ·çš„å­¦ä¹ å†å²
        progress = await LearningProgress.filter(
            user_id=user_id
        ).order_by('-updated_at').limit(5)
        
        # è·å–ç”¨æˆ·çš„çŸ¥è¯†æŒæ¡æƒ…å†µ
        mastery = await KnowledgeMastery.filter(
            user_id=user_id
        ).order_by('-confidence_score').limit(10)
        
        return {
            'recent_chapters': [p.chapter_id for p in progress],
            'strong_topics': [m.knowledge_point_id for m in mastery if m.confidence_score > 0.7],
            'weak_topics': [m.knowledge_point_id for m in mastery if m.confidence_score < 0.5]
        }
    
    async def generate_answer(
        self,
        question: str,
        docs: List[Document],
        user_context: dict,
        intent: dict
    ) -> dict:
        """ç”Ÿæˆç­”æ¡ˆ"""
        # æ„å»ºæç¤ºè¯
        context_text = "\n\n".join([doc.page_content for doc in docs])
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä½è€å¿ƒçš„å·¥ç¨‹å­¦å¯¼å¸ˆã€‚æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚
        
        å­¦ç”Ÿé—®é¢˜: {question}
        é—®é¢˜ç±»å‹: {intent['intent']}
        
        ç›¸å…³çŸ¥è¯†:
        {context_text}
        
        å­¦ç”ŸèƒŒæ™¯:
        - æœ€è¿‘å­¦ä¹ : {user_context.get('recent_chapters', [])}
        - æ“…é•¿é¢†åŸŸ: {user_context.get('strong_topics', [])}
        - è–„å¼±ç¯èŠ‚: {user_context.get('weak_topics', [])}
        
        è¦æ±‚:
        1. å›ç­”è¦å‡†ç¡®ã€æ¸…æ™°ã€æ˜“æ‡‚
        2. æ ¹æ®å­¦ç”ŸèƒŒæ™¯è°ƒæ•´è§£é‡Šæ·±åº¦
        3. å¦‚æœæ¶‰åŠå…¬å¼ï¼Œä½¿ç”¨LaTeXæ ¼å¼
        4. å¦‚æœæœ‰ä»£ç ï¼Œæä¾›å®Œæ•´å¯è¿è¡Œçš„ç¤ºä¾‹
        5. æä¾›2-3ä¸ªåç»­é—®é¢˜å»ºè®®
        6. è¯„ä¼°ç­”æ¡ˆçš„ç½®ä¿¡åº¦ (0-1)
        
        è¿”å›JSONæ ¼å¼:
        {{
            "text": "ç­”æ¡ˆå†…å®¹",
            "sources": ["å¼•ç”¨æ¥æº"],
            "confidence": 0.95,
            "follow_ups": ["åç»­é—®é¢˜1", "åç»­é—®é¢˜2"]
        }}
        """
        
        response = await self.llm.agenerate([prompt])
        answer = json.loads(response.generations[0][0].text)
        
        return answer
    
    async def post_process(self, answer: dict, intent: dict) -> dict:
        """åå¤„ç†ç­”æ¡ˆ"""
        # 1. æ ¼å¼åŒ–æ•°å­¦å…¬å¼
        answer['text'] = self.format_math(answer['text'])
        
        # 2. è¯­æ³•é«˜äº®ä»£ç 
        answer['text'] = self.highlight_code(answer['text'])
        
        # 3. æ·»åŠ ç›¸å…³èµ„æºé“¾æ¥
        answer['resources'] = await self.find_related_resources(intent)
        
        return answer
    
    def format_math(self, text: str) -> str:
        """æ ¼å¼åŒ–æ•°å­¦å…¬å¼"""
        # å°†LaTeXå…¬å¼åŒ…è£…ä¸ºå‰ç«¯å¯è¯†åˆ«çš„æ ¼å¼
        import re
        
        # è¡Œå†…å…¬å¼ $...$
        text = re.sub(
            r'\$([^\$]+)\$',
            r'\\(\1\\)',
            text
        )
        
        # è¡Œé—´å…¬å¼ $$...$$
        text = re.sub(
            r'\$\$([^\$]+)\$\$',
            r'\\[\1\\]',
            text
        )
        
        return text
    
    def highlight_code(self, text: str) -> str:
        """ä»£ç é«˜äº®"""
        # ä½¿ç”¨Pygmentsè¿›è¡Œä»£ç é«˜äº®
        import re
        from pygments import highlight
        from pygments.lexers import get_lexer_by_name
        from pygments.formatters import HtmlFormatter
        
        # åŒ¹é…ä»£ç å— ```language\ncode\n```
        pattern = r'```(\w+)\n(.*?)\n```'
        
        def replace_code(match):
            language = match.group(1)
            code = match.group(2)
            
            try:
                lexer = get_lexer_by_name(language)
                formatter = HtmlFormatter()
                return highlight(code, lexer, formatter)
            except:
                return match.group(0)
        
        text = re.sub(pattern, replace_code, text, flags=re.DOTALL)
        
        return text
    
    async def provide_hints(
        self,
        user_id: int,
        exercise_id: int,
        user_code: str
    ) -> List[str]:
        """æä¾›å¾ªåºæ¸è¿›çš„æç¤º"""
        # 1. åˆ†æç”¨æˆ·ä»£ç 
        code_analysis = await self.analyze_code(user_code)
        
        # 2. è·å–ç»ƒä¹ çš„æ ‡å‡†ç­”æ¡ˆ
        exercise = await Exercise.get(id=exercise_id)
        solution = exercise.solution
        
        # 3. ç”Ÿæˆæ¸è¿›å¼æç¤º
        prompt = f"""
        å­¦ç”Ÿæ­£åœ¨è§£å†³ä»¥ä¸‹ç»ƒä¹ :
        é¢˜ç›®: {exercise.title}
        æè¿°: {exercise.description}
        
        å­¦ç”Ÿä»£ç :
        ```python
        {user_code}
        ```
        
        ä»£ç åˆ†æ:
        {code_analysis}
        
        æ ‡å‡†ç­”æ¡ˆ:
        ```python
        {solution}
        ```
        
        è¯·ç”Ÿæˆ3ä¸ªæ¸è¿›å¼æç¤º,ä»æœ€ä¸å…·ä½“åˆ°æœ€å…·ä½“:
        1. ç¬¬ä¸€ä¸ªæç¤º: æ–¹å‘æ€§æŒ‡å¯¼,ä¸æš´éœ²å…·ä½“å®ç°
        2. ç¬¬äºŒä¸ªæç¤º: å…·ä½“åˆ°æŸä¸ªæ­¥éª¤æˆ–æ–¹æ³•
        3. ç¬¬ä¸‰ä¸ªæç¤º: æ¥è¿‘ç­”æ¡ˆ,ä½†ä»éœ€å­¦ç”Ÿæ€è€ƒ
        
        è¿”å›JSONæ•°ç»„æ ¼å¼ã€‚
        """
        
        response = await self.llm.agenerate([prompt])
        hints = json.loads(response.generations[0][0].text)
        
        return hints
```

### å¤šè½®å¯¹è¯ç®¡ç†

```python
class DialogueManager:
    """å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.sessions = {}  # user_id -> conversation history
        
    async def chat(
        self,
        user_id: int,
        message: str,
        session_id: str = None
    ) -> dict:
        """å¤šè½®å¯¹è¯"""
        # 1. è·å–æˆ–åˆ›å»ºä¼šè¯
        if session_id not in self.sessions:
            self.sessions[session_id] = {
                'history': [],
                'context': {},
                'created_at': datetime.utcnow()
            }
        
        session = self.sessions[session_id]
        
        # 2. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        session['history'].append({
            'role': 'user',
            'content': message,
            'timestamp': datetime.utcnow()
        })
        
        # 3. ä¸Šä¸‹æ–‡ç†è§£
        context = await self.understand_context(
            session['history'],
            session['context']
        )
        
        # 4. ç”Ÿæˆå›å¤
        response = await self.generate_response(
            user_id,
            message,
            session['history'],
            context
        )
        
        # 5. æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
        session['history'].append({
            'role': 'assistant',
            'content': response['text'],
            'timestamp': datetime.utcnow()
        })
        
        # 6. æ›´æ–°ä¸Šä¸‹æ–‡
        session['context'].update(response.get('context_update', {}))
        
        return response
    
    async def understand_context(
        self,
        history: List[dict],
        current_context: dict
    ) -> dict:
        """ç†è§£å¯¹è¯ä¸Šä¸‹æ–‡"""
        # åˆ†æå¯¹è¯å†å²,æå–å…³é”®ä¿¡æ¯
        # - å½“å‰è®¨è®ºçš„ä¸»é¢˜
        # - ç”¨æˆ·çš„å›°æƒ‘ç‚¹
        # - éœ€è¦æ¾„æ¸…çš„åœ°æ–¹
        
        recent_messages = history[-5:]  # æœ€è¿‘5è½®å¯¹è¯
        
        # ä½¿ç”¨LLMæå–ä¸Šä¸‹æ–‡
        messages_text = "\n".join([
            f"{msg['role']}: {msg['content']}"
            for msg in recent_messages
        ])
        
        prompt = f"""
        åˆ†æä»¥ä¸‹å¯¹è¯,æå–å…³é”®ä¸Šä¸‹æ–‡ä¿¡æ¯:
        
        {messages_text}
        
        è¿”å›JSONæ ¼å¼:
        {{
            "topic": "å½“å‰è®¨è®ºçš„ä¸»é¢˜",
            "user_confusion": "ç”¨æˆ·çš„å›°æƒ‘ç‚¹",
            "resolved": true/false,
            "next_step": "å»ºè®®çš„ä¸‹ä¸€æ­¥"
        }}
        """
        
        # ... LLMè°ƒç”¨
        
        return context
    
    async def generate_response(
        self,
        user_id: int,
        message: str,
        history: List[dict],
        context: dict
    ) -> dict:
        """ç”Ÿæˆå›å¤"""
        # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢çŸ¥è¯†
        needs_retrieval = await self.needs_knowledge_retrieval(message)
        
        if needs_retrieval:
            # ä½¿ç”¨RAGç”Ÿæˆå›å¤
            tutor = IntelligentTutorSystem()
            return await tutor.answer_question(user_id, message, context)
        else:
            # ç›´æ¥å¯¹è¯ç”Ÿæˆ
            return await self.direct_chat(message, history, context)
    
    async def direct_chat(
        self,
        message: str,
        history: List[dict],
        context: dict
    ) -> dict:
        """ç›´æ¥å¯¹è¯"""
        # æ„å»ºå¯¹è¯å†å²
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å‹å¥½çš„å­¦ä¹ åŠ©æ‰‹ã€‚"}
        ]
        
        for msg in history[-10:]:  # æœ€è¿‘10è½®
            messages.append({
                "role": msg['role'],
                "content": msg['content']
            })
        
        # è°ƒç”¨ChatGPT
        response = await openai.ChatCompletion.acreate(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.7
        )
        
        return {
            'text': response.choices[0].message.content,
            'type': 'chat'
        }
```

---

## ğŸ’» ä»£ç æ™ºèƒ½åˆ†æ

### ä»£ç è´¨é‡åˆ†æå™¨

```python
import ast
import radon.complexity as radon_complexity
import radon.metrics as radon_metrics
from pylint import lint
from pylint.reporters.text import TextReporter

class CodeIntelligenceService:
    """ä»£ç æ™ºèƒ½åˆ†ææœåŠ¡"""
    
    async def analyze_code(
        self,
        code: str,
        language: str = 'python'
    ) -> dict:
        """ç»¼åˆä»£ç åˆ†æ"""
        if language == 'python':
            return await self.analyze_python_code(code)
        else:
            return {'error': f'Unsupported language: {language}'}
    
    async def analyze_python_code(self, code: str) -> dict:
        """Pythonä»£ç åˆ†æ"""
        results = {
            'quality': {},
            'complexity': {},
            'style': {},
            'bugs': [],
            'suggestions': [],
            'score': 0
        }
        
        try:
            # 1. è¯­æ³•æ£€æŸ¥
            ast.parse(code)
            results['quality']['syntax'] = 'valid'
            
            # 2. å¤æ‚åº¦åˆ†æ
            results['complexity'] = self.analyze_complexity(code)
            
            # 3. ä»£ç é£æ ¼æ£€æŸ¥
            results['style'] = self.check_style(code)
            
            # 4. Bugæ£€æµ‹
            results['bugs'] = self.detect_bugs(code)
            
            # 5. ç”Ÿæˆå»ºè®®
            results['suggestions'] = await self.generate_suggestions(
                code,
                results
            )
            
            # 6. è®¡ç®—æ€»åˆ†
            results['score'] = self.calculate_score(results)
            
        except SyntaxError as e:
            results['quality']['syntax'] = 'invalid'
            results['bugs'].append({
                'type': 'SyntaxError',
                'line': e.lineno,
                'message': str(e),
                'severity': 'high'
            })
        
        return results
    
    def analyze_complexity(self, code: str) -> dict:
        """å¤æ‚åº¦åˆ†æ"""
        # åœˆå¤æ‚åº¦
        cc_results = radon_complexity.cc_visit(code)
        
        # è®¡ç®—å¹³å‡åœˆå¤æ‚åº¦
        if cc_results:
            avg_complexity = sum(r.complexity for r in cc_results) / len(cc_results)
        else:
            avg_complexity = 0
        
        # å¯ç»´æŠ¤æ€§æŒ‡æ•°
        mi = radon_metrics.mi_visit(code, True)
        
        # Halsteadå¤æ‚åº¦
        h = radon_metrics.h_visit(code)
        
        return {
            'cyclomatic_complexity': {
                'average': round(avg_complexity, 2),
                'functions': [
                    {
                        'name': r.name,
                        'complexity': r.complexity,
                        'rating': self.complexity_rating(r.complexity)
                    }
                    for r in cc_results
                ]
            },
            'maintainability_index': round(mi, 2),
            'halstead': {
                'volume': round(h.total.volume, 2) if h.total else 0,
                'difficulty': round(h.total.difficulty, 2) if h.total else 0
            }
        }
    
    def complexity_rating(self, complexity: int) -> str:
        """å¤æ‚åº¦è¯„çº§"""
        if complexity <= 5:
            return 'A (ç®€å•)'
        elif complexity <= 10:
            return 'B (ä¸­ç­‰)'
        elif complexity <= 20:
            return 'C (å¤æ‚)'
        elif complexity <= 30:
            return 'D (å¾ˆå¤æ‚)'
        else:
            return 'F (æå…¶å¤æ‚)'
    
    def check_style(self, code: str) -> dict:
        """ä»£ç é£æ ¼æ£€æŸ¥"""
        from io import StringIO
        
        # ä½¿ç”¨pylintæ£€æŸ¥
        output = StringIO()
        reporter = TextReporter(output)
        
        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            temp_file = f.name
        
        try:
            lint.Run([temp_file], reporter=reporter, exit=False)
            lint_output = output.getvalue()
            
            # è§£æpylintè¾“å‡º
            issues = self.parse_pylint_output(lint_output)
            
            return {
                'issues': issues,
                'count': len(issues)
            }
        finally:
            import os
            os.unlink(temp_file)
    
    def parse_pylint_output(self, output: str) -> List[dict]:
        """è§£æpylintè¾“å‡º"""
        issues = []
        
        for line in output.split('\n'):
            if ':' in line and ('error' in line.lower() or 'warning' in line.lower()):
                parts = line.split(':')
                if len(parts) >= 3:
                    issues.append({
                        'line': parts[1].strip(),
                        'type': parts[0].strip(),
                        'message': ':'.join(parts[2:]).strip()
                    })
        
        return issues
    
    def detect_bugs(self, code: str) -> List[dict]:
        """Bugæ£€æµ‹"""
        bugs = []
        
        try:
            tree = ast.parse(code)
            
            # 1. æ£€æŸ¥å¸¸è§é”™è¯¯æ¨¡å¼
            for node in ast.walk(tree):
                # é™¤é›¶é”™è¯¯
                if isinstance(node, ast.BinOp) and isinstance(node.op, ast.Div):
                    if isinstance(node.right, ast.Constant) and node.right.value == 0:
                        bugs.append({
                            'type': 'ZeroDivisionError',
                            'line': node.lineno,
                            'message': 'å¯èƒ½çš„é™¤é›¶é”™è¯¯',
                            'severity': 'high'
                        })
                
                # æœªä½¿ç”¨çš„å˜é‡
                # ... æ›´å¤šæ£€æŸ¥
        
        except:
            pass
        
        return bugs
    
    async def generate_suggestions(
        self,
        code: str,
        analysis: dict
    ) -> List[dict]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # 1. åŸºäºå¤æ‚åº¦çš„å»ºè®®
        cc = analysis['complexity']['cyclomatic_complexity']
        if cc['average'] > 10:
            suggestions.append({
                'type': 'complexity',
                'priority': 'high',
                'message': 'ä»£ç å¤æ‚åº¦è¾ƒé«˜,å»ºè®®æ‹†åˆ†å‡½æ•°',
                'detail': f'å¹³å‡åœˆå¤æ‚åº¦: {cc["average"]}, å»ºè®®æ¯ä¸ªå‡½æ•°çš„å¤æ‚åº¦ä¸è¶…è¿‡10'
            })
        
        # 2. åŸºäºé£æ ¼çš„å»ºè®®
        style_issues = analysis['style']['issues']
        if len(style_issues) > 5:
            suggestions.append({
                'type': 'style',
                'priority': 'medium',
                'message': f'å‘ç°{len(style_issues)}ä¸ªä»£ç é£æ ¼é—®é¢˜',
                'detail': 'å»ºè®®æŒ‰ç…§PEP 8è§„èŒƒè°ƒæ•´ä»£ç é£æ ¼'
            })
        
        # 3. ä½¿ç”¨AIç”Ÿæˆæ›´æ™ºèƒ½çš„å»ºè®®
        ai_suggestions = await self.ai_suggest(code, analysis)
        suggestions.extend(ai_suggestions)
        
        return suggestions
    
    async def ai_suggest(self, code: str, analysis: dict) -> List[dict]:
        """AIç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        prompt = f"""
        åˆ†æä»¥ä¸‹Pythonä»£ç å¹¶æä¾›ä¼˜åŒ–å»ºè®®:
        
        ```python
        {code}
        ```
        
        ä»£ç åˆ†æç»“æœ:
        - å¹³å‡å¤æ‚åº¦: {analysis['complexity']['cyclomatic_complexity']['average']}
        - å¯ç»´æŠ¤æ€§æŒ‡æ•°: {analysis['complexity']['maintainability_index']}
        - é£æ ¼é—®é¢˜æ•°: {analysis['style']['count']}
        - Bugæ•°: {len(analysis['bugs'])}
        
        è¯·æä¾›3-5ä¸ªå…·ä½“çš„ä¼˜åŒ–å»ºè®®,æ¯ä¸ªå»ºè®®åŒ…æ‹¬:
        1. é—®é¢˜æè¿°
        2. ä¼˜åŒ–æ–¹æ³•
        3. ä¼˜åŒ–åçš„ç¤ºä¾‹ä»£ç 
        
        è¿”å›JSONæ•°ç»„æ ¼å¼ã€‚
        """
        
        # è°ƒç”¨LLM
        response = await openai.ChatCompletion.acreate(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Pythonä»£ç å®¡æŸ¥ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )
        
        suggestions = json.loads(response.choices[0].message.content)
        
        return [
            {
                'type': 'ai_suggestion',
                'priority': 'medium',
                'message': s['description'],
                'detail': s['method'],
                'example': s.get('example_code')
            }
            for s in suggestions
        ]
    
    def calculate_score(self, analysis: dict) -> int:
        """è®¡ç®—ä»£ç è´¨é‡å¾—åˆ† (0-100)"""
        score = 100
        
        # è¯­æ³•é”™è¯¯: -50åˆ†
        if analysis['quality'].get('syntax') == 'invalid':
            score -= 50
        
        # Bug: æ¯ä¸ª-5åˆ†
        score -= len(analysis['bugs']) * 5
        
        # å¤æ‚åº¦: è¶…è¿‡10, æ¯1ç‚¹-2åˆ†
        cc_avg = analysis['complexity']['cyclomatic_complexity']['average']
        if cc_avg > 10:
            score -= int((cc_avg - 10) * 2)
        
        # é£æ ¼é—®é¢˜: æ¯ä¸ª-1åˆ†
        score -= analysis['style']['count']
        
        # å¯ç»´æŠ¤æ€§: ä½äº60, æ¯ä½1ç‚¹-0.5åˆ†
        mi = analysis['complexity']['maintainability_index']
        if mi < 60:
            score -= int((60 - mi) * 0.5)
        
        return max(0, min(100, score))

# APIç«¯ç‚¹
@router.post("/code/analyze")
async def analyze_code(
    request: CodeAnalysisRequest,
    current_user: User = Depends(get_current_user)
):
    """ä»£ç åˆ†æ"""
    service = CodeIntelligenceService()
    analysis = await service.analyze_code(
        request.code,
        request.language
    )
    
    return {'success': True, 'data': analysis}
```

---

## ğŸ“š å­¦ä¹ è·¯å¾„è§„åˆ’

```python
class LearningPathPlanner:
    """å­¦ä¹ è·¯å¾„è§„åˆ’å™¨"""
    
    async def generate_learning_path(
        self,
        user_id: int,
        goal: str,
        timeframe: int  # å¤©æ•°
    ) -> dict:
        """ç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„"""
        # 1. è¯„ä¼°ç”¨æˆ·å½“å‰æ°´å¹³
        current_level = await self.assess_user_level(user_id)
        
        # 2. åˆ†æç›®æ ‡
        goal_requirements = await self.analyze_goal(goal)
        
        # 3. è¯†åˆ«çŸ¥è¯†ç¼ºå£
        knowledge_gaps = await self.identify_gaps(
            current_level,
            goal_requirements
        )
        
        # 4. ç”Ÿæˆå­¦ä¹ è·¯å¾„
        path = await self.plan_path(
            knowledge_gaps,
            timeframe
        )
        
        # 5. é¢„ä¼°å®Œæˆæ—¶é—´
        estimation = self.estimate_completion(path, user_id)
        
        return {
            'path': path,
            'estimation': estimation,
            'milestones': self.create_milestones(path, timeframe)
        }
    
    async def assess_user_level(self, user_id: int) -> dict:
        """è¯„ä¼°ç”¨æˆ·æ°´å¹³"""
        # è·å–ç”¨æˆ·çš„çŸ¥è¯†æŒæ¡æƒ…å†µ
        mastery = await KnowledgeMastery.filter(
            user_id=user_id
        ).all()
        
        # æŒ‰ä¸»é¢˜åˆ†ç»„
        by_topic = {}
        for m in mastery:
            topic = m.knowledge_point.topic
            if topic not in by_topic:
                by_topic[topic] = []
            by_topic[topic].append(m.confidence_score)
        
        # è®¡ç®—æ¯ä¸ªä¸»é¢˜çš„å¹³å‡æŒæ¡åº¦
        level = {
            topic: {
                'score': np.mean(scores),
                'count': len(scores)
            }
            for topic, scores in by_topic.items()
        }
        
        return level
    
    async def analyze_goal(self, goal: str) -> dict:
        """åˆ†æå­¦ä¹ ç›®æ ‡"""
        # ä½¿ç”¨LLMåˆ†æç›®æ ‡
        prompt = f"""
        åˆ†æä»¥ä¸‹å­¦ä¹ ç›®æ ‡,æå–éœ€è¦æŒæ¡çš„çŸ¥è¯†ç‚¹å’ŒæŠ€èƒ½:
        
        ç›®æ ‡: {goal}
        
        è¿”å›JSONæ ¼å¼:
        {{
            "topics": ["ä¸»é¢˜1", "ä¸»é¢˜2", ...],
            "skills": ["æŠ€èƒ½1", "æŠ€èƒ½2", ...],
            "difficulty": "beginner/intermediate/advanced",
            "estimated_hours": 100
        }}
        """
        
        # ... LLMè°ƒç”¨
        
        return requirements
    
    async def identify_gaps(
        self,
        current_level: dict,
        goal_requirements: dict
    ) -> List[dict]:
        """è¯†åˆ«çŸ¥è¯†ç¼ºå£"""
        gaps = []
        
        required_topics = goal_requirements['topics']
        
        for topic in required_topics:
            current = current_level.get(topic, {'score': 0, 'count': 0})
            
            if current['score'] < 0.7:  # éœ€è¦æå‡
                gap = {
                    'topic': topic,
                    'current_score': current['score'],
                    'target_score': 0.8,
                    'priority': 'high' if current['score'] < 0.5 else 'medium'
                }
                gaps.append(gap)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        gaps.sort(key=lambda x: (
            0 if x['priority'] == 'high' else 1,
            x['current_score']
        ))
        
        return gaps
    
    async def plan_path(
        self,
        knowledge_gaps: List[dict],
        timeframe: int
    ) -> List[dict]:
        """è§„åˆ’å­¦ä¹ è·¯å¾„"""
        path = []
        
        # ä¸ºæ¯ä¸ªçŸ¥è¯†ç¼ºå£è§„åˆ’å­¦ä¹ å†…å®¹
        for gap in knowledge_gaps:
            topic = gap['topic']
            
            # æŸ¥æ‰¾ç›¸å…³ç« èŠ‚
            chapters = await Chapter.filter(
                topic=topic
            ).order_by('order')
            
            # æŸ¥æ‰¾ç›¸å…³ç»ƒä¹ 
            exercises = await Exercise.filter(
                topic=topic
            ).order_by('difficulty_score')
            
            path.append({
                'topic': topic,
                'chapters': [
                    {
                        'id': c.id,
                        'title': c.title,
                        'estimated_time': c.estimated_time
                    }
                    for c in chapters
                ],
                'exercises': [
                    {
                        'id': e.id,
                        'title': e.title,
                        'difficulty': e.difficulty
                    }
                    for e in exercises[:10]  # æ¯ä¸ªä¸»é¢˜10ä¸ªç»ƒä¹ 
                ],
                'target_score': gap['target_score']
            })
        
        return path
    
    def create_milestones(
        self,
        path: List[dict],
        timeframe: int
    ) -> List[dict]:
        """åˆ›å»ºé‡Œç¨‹ç¢‘"""
        milestones = []
        
        # å°†å­¦ä¹ è·¯å¾„åˆ†æˆå‡ ä¸ªé˜¶æ®µ
        stages = len(path)
        days_per_stage = timeframe // stages
        
        current_day = 0
        for i, stage in enumerate(path):
            milestone = {
                'stage': i + 1,
                'title': f'æŒæ¡{stage["topic"]}',
                'target_date': (
                    datetime.now() + timedelta(days=current_day + days_per_stage)
                ).isoformat(),
                'criteria': {
                    'chapters_completed': len(stage['chapters']),
                    'exercises_passed': len(stage['exercises']),
                    'target_score': stage['target_score']
                }
            }
            
            milestones.append(milestone)
            current_day += days_per_stage
        
        return milestones
```

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### AIæœåŠ¡æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            å‰ç«¯åº”ç”¨å±‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æ¨èå±•ç¤º â”‚  â”‚ å¯¹è¯ç•Œé¢ â”‚  â”‚ä»£ç åˆ†æ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–²           â–²            â–²
             â”‚           â”‚            â”‚
             â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            APIç½‘å…³å±‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   è·¯ç”± | é‰´æƒ | é™æµ | ç¼“å­˜          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–²           â–²            â–²
             â”‚           â”‚            â”‚
             â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            AIæœåŠ¡å±‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æ¨èæœåŠ¡ â”‚  â”‚ å¯¹è¯æœåŠ¡ â”‚  â”‚åˆ†ææœåŠ¡ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–²           â–²            â–²
             â”‚           â”‚            â”‚
             â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            æ¨¡å‹å±‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æ¨èæ¨¡å‹ â”‚  â”‚   LLM    â”‚  â”‚é™æ€åˆ†æ â”‚ â”‚
â”‚  â”‚(LightGBM)â”‚  â”‚(GPT-4)   â”‚  â”‚(Pylint) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–²           â–²            â–²
             â”‚           â”‚            â”‚
             â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            æ•°æ®å±‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚PostgreSQLâ”‚  â”‚ ChromaDB â”‚  â”‚  Redis  â”‚ â”‚
â”‚  â”‚(ç”¨æˆ·æ•°æ®)â”‚  â”‚(å‘é‡åº“)  â”‚  â”‚(ç¼“å­˜)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æˆæœ¬ä¼˜åŒ–ç­–ç•¥

```python
class AIServiceOptimizer:
    """AIæœåŠ¡æˆæœ¬ä¼˜åŒ–"""
    
    def __init__(self):
        self.cache = Redis()
        self.local_model = LocalModel()  # æœ¬åœ°è½»é‡æ¨¡å‹
        self.api_model = OpenAIModel()   # APIæ¨¡å‹
        
    async def query(self, request: dict) -> dict:
        """æ™ºèƒ½æŸ¥è¯¢ (æˆæœ¬ä¼˜åŒ–)"""
        # 1. æ£€æŸ¥ç¼“å­˜
        cache_key = self.generate_cache_key(request)
        cached = await self.cache.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # 2. åˆ¤æ–­å¤æ‚åº¦
        complexity = self.assess_complexity(request)
        
        # 3. é€‰æ‹©æ¨¡å‹
        if complexity == 'simple':
            # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (å…è´¹)
            result = await self.local_model.predict(request)
        else:
            # ä½¿ç”¨APIæ¨¡å‹ (ä»˜è´¹)
            result = await self.api_model.predict(request)
        
        # 4. ç¼“å­˜ç»“æœ
        await self.cache.setex(
            cache_key,
            3600,  # 1å°æ—¶
            json.dumps(result)
        )
        
        return result
    
    def assess_complexity(self, request: dict) -> str:
        """è¯„ä¼°è¯·æ±‚å¤æ‚åº¦"""
        # ç®€å•è§„åˆ™:
        # - é—®é¢˜é•¿åº¦ < 100å­—ç¬¦ -> simple
        # - æœ‰ä¸Šä¸‹æ–‡ -> complex
        # - éœ€è¦æ¨ç† -> complex
        
        if len(request.get('query', '')) < 100:
            return 'simple'
        
        return 'complex'
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-11-12
