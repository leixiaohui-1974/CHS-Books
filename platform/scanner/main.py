"""
å†…å®¹æ‰«æå™¨ä¸»ç¨‹åº
è‡ªåŠ¨æ‰«æbooksç›®å½•ï¼Œè§£æä¹¦ç±ã€ç« èŠ‚ã€æ¡ˆä¾‹ä¿¡æ¯
"""

import os
import sys
import asyncio
import json
import ast
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import re
import markdown
from loguru import logger


class ContentScanner:
    """å†…å®¹æ‰«æå™¨"""
    
    def __init__(self, books_path: str = "/workspace/books"):
        self.books_path = Path(books_path)
        self.discovered_books: List[Dict] = []
        
        logger.info(f"ğŸ” åˆå§‹åŒ–å†…å®¹æ‰«æå™¨: {books_path}")
    
    def scan_all(self) -> Dict[str, Any]:
        """å…¨é‡æ‰«ææ‰€æœ‰å†…å®¹"""
        logger.info("ğŸš€ å¼€å§‹å…¨é‡æ‰«æ...")
        
        start_time = datetime.now()
        
        # æ‰«ææ‰€æœ‰ä¹¦ç±ç›®å½•
        for item in self.books_path.iterdir():
            if item.is_dir() and not item.name.startswith(('_', '.')):
                logger.info(f"ğŸ“š æ‰«æä¹¦ç±: {item.name}")
                book_info = self.scan_book(item)
                if book_info:
                    self.discovered_books.append(book_info)
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        result = {
            "total_books": len(self.discovered_books),
            "books": self.discovered_books,
            "scan_time": elapsed,
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"âœ… æ‰«æå®Œæˆï¼å‘ç° {len(self.discovered_books)} æœ¬ä¹¦ï¼Œè€—æ—¶ {elapsed:.2f}ç§’")
        
        return result
    
    def scan_book(self, book_path: Path) -> Optional[Dict]:
        """æ‰«æå•æœ¬ä¹¦ç±"""
        try:
            readme_path = book_path / "README.md"
            if not readme_path.exists():
                logger.warning(f"âš ï¸  æœªæ‰¾åˆ°README.md: {book_path}")
                return None
            
            # è§£æREADMEè·å–ä¹¦ç±å…ƒæ•°æ®
            book_info = self.parse_book_readme(readme_path)
            book_info["slug"] = book_path.name
            book_info["github_path"] = str(book_path.relative_to(self.books_path))
            
            # æ‰«ææ¡ˆä¾‹
            examples_path = book_path / "code" / "examples"
            if examples_path.exists():
                book_info["cases"] = self.scan_cases(examples_path)
                book_info["total_cases"] = len(book_info["cases"])
            else:
                book_info["cases"] = []
                book_info["total_cases"] = 0
            
            logger.info(f"  âœ“ å‘ç° {book_info['total_cases']} ä¸ªæ¡ˆä¾‹")
            
            return book_info
            
        except Exception as e:
            logger.error(f"âŒ æ‰«æä¹¦ç±å¤±è´¥ {book_path}: {e}")
            return None
    
    def parse_book_readme(self, readme_path: Path) -> Dict:
        """è§£æREADME.mdæå–ä¹¦ç±ä¿¡æ¯"""
        with open(readme_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª#æ ‡é¢˜ï¼‰
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        title = title_match.group(1) if title_match else "æœªå‘½å"
        
        # æå–å‰¯æ ‡é¢˜ï¼ˆç¬¬äºŒä¸ª#æ ‡é¢˜æˆ–ç¬¬ä¸€è¡Œ##ï¼‰
        subtitle_match = re.search(r'^##\s+(.+)$', content, re.MULTILINE)
        subtitle = subtitle_match.group(1) if subtitle_match else None
        
        # æå–æè¿°ï¼ˆå–å‰200å­—ç¬¦ï¼‰
        # å»é™¤æ ‡é¢˜åçš„ç¬¬ä¸€æ®µå†…å®¹
        description_match = re.search(r'^#.+?\n\n(.+?)(?:\n\n|$)', content, re.DOTALL | re.MULTILINE)
        description = description_match.group(1)[:200] if description_match else None
        
        return {
            "title": title,
            "subtitle": subtitle,
            "description": description,
            "status": "published",  # é»˜è®¤ä¸ºå·²å‘å¸ƒ
            "version": "1.0.0",
        }
    
    def scan_cases(self, examples_path: Path) -> List[Dict]:
        """æ‰«ææ¡ˆä¾‹ç›®å½•"""
        cases = []
        
        for case_dir in sorted(examples_path.iterdir()):
            if not case_dir.is_dir() or case_dir.name.startswith(('_', '.')):
                continue
            
            case_info = self.scan_case(case_dir)
            if case_info:
                cases.append(case_info)
        
        return cases
    
    def scan_case(self, case_path: Path) -> Optional[Dict]:
        """æ‰«æå•ä¸ªæ¡ˆä¾‹"""
        try:
            # æå–æ¡ˆä¾‹åºå·å’Œåç§°
            # ä¾‹å¦‚: case_01_irrigation -> order=1, slug=irrigation
            match = re.match(r'case_(\d+)_(.+)', case_path.name)
            if not match:
                logger.warning(f"âš ï¸  æ— æ•ˆçš„æ¡ˆä¾‹ç›®å½•å: {case_path.name}")
                return None
            
            order = int(match.group(1))
            slug = match.group(2)
            
            case_info = {
                "order": order,
                "slug": slug,
                "directory": case_path.name,
            }
            
            # æ£€æŸ¥main.py
            main_py = case_path / "main.py"
            if main_py.exists():
                case_info["has_main"] = True
                case_info["script_path"] = str(main_py)
                
                # è§£æPythonæ–‡ä»¶æå–å·¥å…·é…ç½®
                tool_config = self.parse_main_py(main_py)
                if tool_config:
                    case_info["tool_config"] = tool_config
                    case_info["has_tool"] = True
            else:
                case_info["has_main"] = False
                case_info["has_tool"] = False
            
            # æ£€æŸ¥README.md
            readme = case_path / "README.md"
            if readme.exists():
                case_info["has_readme"] = True
                # è§£æREADMEè·å–æ ‡é¢˜ã€æè¿°
                with open(readme, 'r', encoding='utf-8') as f:
                    readme_content = f.read()
                    title_match = re.search(r'^#\s+(.+)$', readme_content, re.MULTILINE)
                    if title_match:
                        case_info["title"] = title_match.group(1)
            else:
                case_info["has_readme"] = False
                case_info["title"] = slug.replace('_', ' ').title()
            
            return case_info
            
        except Exception as e:
            logger.error(f"âŒ æ‰«ææ¡ˆä¾‹å¤±è´¥ {case_path}: {e}")
            return None
    
    def parse_main_py(self, main_py_path: Path) -> Optional[Dict]:
        """è§£æmain.pyæå–å‡½æ•°ç­¾åå’Œå‚æ•°"""
        try:
            with open(main_py_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
            
            # æŸ¥æ‰¾ä¸»å‡½æ•°
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    if node.name in ['run_simulation', 'main', 'demo', 'run']:
                        params = self.extract_function_params(node)
                        return {
                            "entry_function": node.name,
                            "inputs": params
                        }
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ è§£æmain.pyå¤±è´¥: {e}")
            return None
    
    def extract_function_params(self, func_node: ast.FunctionDef) -> List[Dict]:
        """ä»å‡½æ•°å®šä¹‰æå–å‚æ•°ä¿¡æ¯"""
        params = []
        
        for arg in func_node.args.args:
            if arg.arg == 'self':
                continue
            
            param_info = {
                "name": arg.arg,
                "type": "unknown",
                "default": None
            }
            
            # æå–ç±»å‹æ³¨è§£
            if arg.annotation:
                param_info["type"] = ast.unparse(arg.annotation)
            
            params.append(param_info)
        
        # æå–é»˜è®¤å€¼
        defaults = func_node.args.defaults
        if defaults:
            for i, default in enumerate(defaults):
                param_idx = len(params) - len(defaults) + i
                if param_idx >= 0:
                    try:
                        params[param_idx]["default"] = ast.literal_eval(default)
                    except:
                        params[param_idx]["default"] = ast.unparse(default)
        
        return params
    
    def save_results(self, output_path: str = "scan_results.json"):
        """ä¿å­˜æ‰«æç»“æœåˆ°JSONæ–‡ä»¶"""
        result = self.scan_all()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ æ‰«æç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        return result


def main():
    """ä¸»å‡½æ•°"""
    scanner = ContentScanner(books_path="/workspace/books")
    
    # æ‰§è¡Œæ‰«æ
    result = scanner.scan_all()
    
    # ä¿å­˜ç»“æœ
    scanner.save_results("/workspace/platform/scan_results.json")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*50)
    print(f"ğŸ“Š æ‰«æç»Ÿè®¡")
    print("="*50)
    print(f"æ€»ä¹¦ç±æ•°: {result['total_books']}")
    for book in result['books']:
        print(f"  ğŸ“š {book['title']}")
        print(f"     - æ¡ˆä¾‹æ•°: {book['total_cases']}")
    print("="*50)


if __name__ == "__main__":
    main()
