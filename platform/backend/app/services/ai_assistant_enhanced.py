"""
å¢å¼ºç‰ˆAIåŠ©æ‰‹æœåŠ¡
æä¾›ä»£ç è®²è§£ã€é”™è¯¯è¯Šæ–­ã€ç»“æœæ´å¯Ÿç­‰åŠŸèƒ½
"""

from typing import List, Dict, Any, Optional
from loguru import logger
import json


class AIAssistantService:
    """AIåŠ©æ‰‹æœåŠ¡"""
    
    def __init__(self, model: str = "gpt-4"):
        """
        åˆå§‹åŒ–AIåŠ©æ‰‹
        
        Args:
            model: AIæ¨¡å‹åç§°
        """
        self.model = model
        self.conversation_history: Dict[str, List[Dict]] = {}
    
    async def explain_code(
        self,
        code: str,
        context: Optional[str] = None
    ) -> str:
        """
        è®²è§£ä»£ç 
        
        Args:
            code: ä»£ç ç‰‡æ®µ
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ä»£ç è®²è§£æ–‡æœ¬
        """
        prompt = f"""
è¯·è¯¦ç»†è®²è§£ä»¥ä¸‹Pythonä»£ç ï¼ŒåŒ…æ‹¬ï¼š
1. ä»£ç çš„ä¸»è¦åŠŸèƒ½
2. å…³é”®æ­¥éª¤è¯´æ˜
3. ä½¿ç”¨çš„ç®—æ³•æˆ–æ–¹æ³•
4. éœ€è¦æ³¨æ„çš„åœ°æ–¹

ä»£ç :
```python
{code}
```

{f'ä¸Šä¸‹æ–‡: {context}' if context else ''}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè®²è§£è¦æ¸…æ™°æ˜“æ‡‚ã€‚
"""
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„LLM API
        # ä¸ºäº†æ¼”ç¤ºï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ
        explanation = f"""
## ä»£ç åŠŸèƒ½è¯´æ˜

è¿™æ®µä»£ç ä¸»è¦å®Œæˆä»¥ä¸‹åŠŸèƒ½ï¼š
- æ•°æ®åˆå§‹åŒ–å’Œé¢„å¤„ç†
- æ•°å€¼è®¡ç®—å’Œæ±‚è§£
- ç»“æœå¯è§†åŒ–

## å…³é”®æ­¥éª¤

1. **æ•°æ®å‡†å¤‡**: è®¾ç½®é—®é¢˜å‚æ•°å’Œåˆå§‹æ¡ä»¶
2. **æ•°å€¼æ±‚è§£**: ä½¿ç”¨æœ‰é™å·®åˆ†æ³•è¿›è¡Œè¿­ä»£è®¡ç®—
3. **ç»“æœå¤„ç†**: ç”Ÿæˆå›¾è¡¨å’ŒæŠ¥å‘Š

## æŠ€æœ¯è¦ç‚¹

- ä½¿ç”¨NumPyè¿›è¡Œé«˜æ•ˆæ•°ç»„è®¡ç®—
- é‡‡ç”¨Matplotlibè¿›è¡Œå¯è§†åŒ–
- æ³¨æ„æ•°å€¼ç¨³å®šæ€§æ¡ä»¶

(è¿™æ˜¯æ¼”ç¤ºç‰ˆæœ¬ï¼Œç”Ÿäº§ç¯å¢ƒåº”è°ƒç”¨å®é™…çš„AIæ¨¡å‹)
"""
        
        logger.info(f"ğŸ¤– ä»£ç è®²è§£å®Œæˆ")
        return explanation
    
    async def diagnose_error(
        self,
        code: str,
        error_message: str,
        stack_trace: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è¯Šæ–­ä»£ç é”™è¯¯
        
        Args:
            code: å‡ºé”™çš„ä»£ç 
            error_message: é”™è¯¯ä¿¡æ¯
            stack_trace: å †æ ˆè·Ÿè¸ª
            
        Returns:
            {
                "diagnosis": str,  # é”™è¯¯åŸå› åˆ†æ
                "suggestions": list,  # ä¿®å¤å»ºè®®
                "fixed_code": str  # ä¿®å¤åçš„ä»£ç ï¼ˆå¯é€‰ï¼‰
            }
        """
        diagnosis = {
            "diagnosis": f"æ£€æµ‹åˆ°é”™è¯¯: {error_message}",
            "suggestions": [
                "æ£€æŸ¥å˜é‡åæ˜¯å¦æ­£ç¡®",
                "æ£€æŸ¥å‡½æ•°å‚æ•°ç±»å‹",
                "æ£€æŸ¥æ•°ç»„ç´¢å¼•èŒƒå›´",
                "æ£€æŸ¥ä¾èµ–åº“æ˜¯å¦å®‰è£…"
            ],
            "fixed_code": None
        }
        
        # ç®€å•çš„é”™è¯¯æ¨¡å¼åŒ¹é…
        if "NameError" in error_message:
            diagnosis["diagnosis"] = "å˜é‡æœªå®šä¹‰é”™è¯¯"
            diagnosis["suggestions"] = [
                "æ£€æŸ¥å˜é‡åæ‹¼å†™",
                "ç¡®ä¿å˜é‡åœ¨ä½¿ç”¨å‰å·²å®šä¹‰",
                "æ£€æŸ¥å˜é‡ä½œç”¨åŸŸ"
            ]
        
        elif "IndexError" in error_message:
            diagnosis["diagnosis"] = "æ•°ç»„ç´¢å¼•è¶Šç•Œ"
            diagnosis["suggestions"] = [
                "æ£€æŸ¥æ•°ç»„é•¿åº¦",
                "ç¡®è®¤ç´¢å¼•èŒƒå›´æ­£ç¡®",
                "ä½¿ç”¨len()æ£€æŸ¥è¾¹ç•Œ"
            ]
        
        elif "TypeError" in error_message:
            diagnosis["diagnosis"] = "ç±»å‹é”™è¯¯"
            diagnosis["suggestions"] = [
                "æ£€æŸ¥å˜é‡ç±»å‹",
                "ä½¿ç”¨ç±»å‹è½¬æ¢å‡½æ•°",
                "æŸ¥çœ‹å‡½æ•°å‚æ•°è¦æ±‚"
            ]
        
        logger.info(f"ğŸ” é”™è¯¯è¯Šæ–­å®Œæˆ")
        return diagnosis
    
    async def generate_insights(
        self,
        result_data: Dict[str, Any]
    ) -> List[str]:
        """
        ä»è®¡ç®—ç»“æœç”Ÿæˆæ´å¯Ÿ
        
        Args:
            result_data: ç»“æœæ•°æ®
            
        Returns:
            æ´å¯Ÿåˆ—è¡¨
        """
        insights = []
        
        # åˆ†æå›¾è¡¨æ•°é‡
        if "plots" in result_data:
            plot_count = len(result_data["plots"])
            if plot_count > 0:
                insights.append(f"âœ… æˆåŠŸç”Ÿæˆ {plot_count} ä¸ªå›¾è¡¨ï¼Œå¯è§†åŒ–æ•ˆæœè‰¯å¥½")
        
        # åˆ†ææ•°å€¼æŒ‡æ ‡
        if "metrics" in result_data:
            metrics = result_data["metrics"]
            for metric in metrics[:3]:  # åªåˆ†æå‰3ä¸ª
                name = metric.get("name", "")
                value = metric.get("value", 0)
                
                insights.append(f"ğŸ“Š {name} = {value:.4f}")
        
        # åˆ†æè¡¨æ ¼æ•°æ®
        if "tables" in result_data:
            for table in result_data["tables"][:2]:
                rows = table.get("row_count", 0)
                cols = table.get("col_count", 0)
                insights.append(f"ğŸ“‹ æ•°æ®è¡¨åŒ…å« {rows} è¡Œ Ã— {cols} åˆ—")
        
        # æ·»åŠ é€šç”¨å»ºè®®
        insights.append("ğŸ’¡ å¯ä»¥å°è¯•è°ƒæ•´å‚æ•°è§‚å¯Ÿç»“æœå˜åŒ–")
        insights.append("ğŸ’¡ å»ºè®®ä¸ç†è®ºè§£å¯¹æ¯”éªŒè¯ç²¾åº¦")
        
        logger.info(f"ğŸ’¡ ç”Ÿæˆ {len(insights)} æ¡æ´å¯Ÿ")
        return insights
    
    async def answer_question(
        self,
        session_id: str,
        question: str,
        context: Optional[Dict] = None
    ) -> str:
        """
        å›ç­”é—®é¢˜
        
        Args:
            session_id: ä¼šè¯ID
            question: ç”¨æˆ·é—®é¢˜
            context: ä¸Šä¸‹æ–‡ï¼ˆä»£ç ã€æ¡ˆä¾‹ä¿¡æ¯ç­‰ï¼‰
            
        Returns:
            å›ç­”æ–‡æœ¬
        """
        # è·å–å¯¹è¯å†å²
        history = self.conversation_history.get(session_id, [])
        
        # æ·»åŠ å½“å‰é—®é¢˜åˆ°å†å²
        history.append({
            "role": "user",
            "content": question
        })
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„LLM API
        # æ¼”ç¤ºç‰ˆæœ¬è¿”å›æ¨¡æ‹Ÿç­”æ¡ˆ
        answer = f"""
æ„Ÿè°¢æ‚¨çš„æé—®ï¼å…³äº"{question}"ï¼Œæˆ‘æ¥ä¸ºæ‚¨è§£ç­”ï¼š

è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æ ¹æ®ç›¸å…³ç†è®ºå’Œå®è·µç»éªŒï¼š

1. **ç†è®ºåŸºç¡€**: [è¿™é‡Œåº”è¯¥æ˜¯ç›¸å…³çš„ç†è®ºè¯´æ˜]
2. **å®é™…åº”ç”¨**: [è¿™é‡Œåº”è¯¥æ˜¯åº”ç”¨åœºæ™¯]
3. **æ³¨æ„äº‹é¡¹**: [è¿™é‡Œåº”è¯¥æ˜¯æ³¨æ„ç‚¹]

å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šç»†èŠ‚ï¼Œå¯ä»¥ï¼š
- æŸ¥çœ‹ç›¸å…³ç« èŠ‚çš„æ•™æå†…å®¹
- è¿è¡Œç¤ºä¾‹ä»£ç è§‚å¯Ÿæ•ˆæœ
- å°è¯•è°ƒæ•´å‚æ•°è¿›è¡Œå®éªŒ

(è¿™æ˜¯æ¼”ç¤ºç‰ˆæœ¬ï¼Œç”Ÿäº§ç¯å¢ƒä¼šè°ƒç”¨å®é™…çš„AIæ¨¡å‹å¹¶ç»“åˆRAGçŸ¥è¯†åº“)
"""
        
        # æ·»åŠ ç­”æ¡ˆåˆ°å†å²
        history.append({
            "role": "assistant",
            "content": answer
        })
        
        # ä¿å­˜å†å²ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
        self.conversation_history[session_id] = history[-20:]  # åªä¿ç•™æœ€è¿‘20æ¡
        
        logger.info(f"ğŸ’¬ å›ç­”é—®é¢˜: {question[:50]}...")
        return answer
    
    async def suggest_parameters(
        self,
        case_type: str,
        current_params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ¨èå‚æ•°è®¾ç½®
        
        Args:
            case_type: æ¡ˆä¾‹ç±»å‹
            current_params: å½“å‰å‚æ•°
            
        Returns:
            æ¨èçš„å‚æ•°å’Œç†ç”±
        """
        suggestions = {
            "recommended_params": current_params.copy(),
            "reasons": [],
            "alternatives": []
        }
        
        # ç®€å•çš„è§„åˆ™åŸºäºæ¨è
        if "nx" in current_params and current_params["nx"] < 50:
            suggestions["recommended_params"]["nx"] = 100
            suggestions["reasons"].append("å»ºè®®å¢åŠ ç©ºé—´ç½‘æ ¼æ•°ä»¥æé«˜ç²¾åº¦")
        
        if "nt" in current_params:
            suggestions["alternatives"].append({
                "param": "nt",
                "value": current_params["nt"] * 2,
                "reason": "å¢åŠ æ—¶é—´æ­¥æ•°å¯ä»¥è§‚å¯Ÿæ›´é•¿æ—¶é—´çš„æ¼”åŒ–"
            })
        
        logger.info(f"ğŸ¯ ç”Ÿæˆå‚æ•°å»ºè®®")
        return suggestions
    
    def clear_conversation(self, session_id: str):
        """æ¸…é™¤å¯¹è¯å†å²"""
        if session_id in self.conversation_history:
            del self.conversation_history[session_id]
            logger.info(f"ğŸ—‘ï¸  æ¸…é™¤å¯¹è¯å†å²: {session_id}")


# å…¨å±€å®ä¾‹
ai_assistant_service = AIAssistantService()
