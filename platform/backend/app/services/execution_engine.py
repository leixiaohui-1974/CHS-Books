"""
å¢å¼ºç‰ˆä»£ç æ‰§è¡Œå¼•æ“
æ”¯æŒå®¹å™¨æ± ã€WebSocketå®æ—¶é€šä¿¡ã€ä¾èµ–ç®¡ç†
"""

import asyncio
import docker
import uuid
import os
import json
import tempfile
import shutil
from typing import Dict, Any, Optional, Callable, List
from pathlib import Path
from datetime import datetime
from loguru import logger
from queue import Queue
import time


class ContainerPool:
    """
    å®¹å™¨æ± ç®¡ç†å™¨
    å¤ç”¨å®¹å™¨ä»¥æå‡æ€§èƒ½
    """
    
    def __init__(
        self,
        docker_image: str = "python:3.11-slim",
        pool_size: int = 5,
        max_idle_time: int = 300  # 5åˆ†é’Ÿ
    ):
        """
        åˆå§‹åŒ–å®¹å™¨æ± 
        
        Args:
            docker_image: Dockeré•œåƒå
            pool_size: æ± å¤§å°
            max_idle_time: æœ€å¤§ç©ºé—²æ—¶é—´ï¼ˆç§’ï¼‰
        """
        try:
            self.client = docker.from_env()
            logger.info("âœ… Dockerå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ Dockerå®¢æˆ·ç«¯è¿æ¥å¤±è´¥: {e}")
            self.client = None
        
        self.docker_image = docker_image
        self.pool_size = pool_size
        self.max_idle_time = max_idle_time
        
        self.available_containers: Queue = Queue(maxsize=pool_size)
        self.in_use = {}  # container_id -> timestamp
        
        # å¯åŠ¨é¢„çƒ­ä»»åŠ¡
        asyncio.create_task(self._warm_up_pool())
    
    async def _warm_up_pool(self):
        """é¢„çƒ­å®¹å™¨æ± """
        if not self.client:
            logger.warning("âš ï¸  Dockerå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å®¹å™¨æ± é¢„çƒ­")
            return
        
        logger.info(f"ğŸ”¥ å¼€å§‹é¢„çƒ­å®¹å™¨æ±  (å¤§å°: {self.pool_size})...")
        
        for i in range(self.pool_size):
            try:
                container = await self._create_container(f"pool_{i}")
                self.available_containers.put(container)
                logger.info(f"  âœ“ å®¹å™¨ {i+1}/{self.pool_size} å°±ç»ª")
            except Exception as e:
                logger.error(f"  âœ— åˆ›å»ºå®¹å™¨å¤±è´¥: {e}")
        
        logger.info("âœ… å®¹å™¨æ± é¢„çƒ­å®Œæˆ")
    
    async def _create_container(self, name_suffix: str):
        """åˆ›å»ºæ–°å®¹å™¨"""
        if not self.client:
            raise Exception("Dockerå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        container_name = f"exec_container_{name_suffix}_{uuid.uuid4().hex[:8]}"
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒDockeræ“ä½œï¼ˆåŒæ­¥è½¬å¼‚æ­¥ï¼‰
        loop = asyncio.get_event_loop()
        container = await loop.run_in_executor(
            None,
            lambda: self.client.containers.create(
                image=self.docker_image,
                name=container_name,
                command="tail -f /dev/null",  # ä¿æŒè¿è¡Œ
                detach=True,
                mem_limit="1g",
                cpu_quota=200000,  # 2æ ¸
                network_mode="none",
                remove=False
            )
        )
        
        # å¯åŠ¨å®¹å™¨
        await loop.run_in_executor(None, container.start)
        
        return container
    
    async def acquire(self, timeout: float = 30.0):
        """
        è·å–å®¹å™¨
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            å®¹å™¨å¯¹è±¡
        """
        start_time = time.time()
        
        # å°è¯•ä»æ± ä¸­è·å–
        while time.time() - start_time < timeout:
            try:
                container = self.available_containers.get_nowait()
                
                # æ£€æŸ¥å®¹å™¨æ˜¯å¦è¿˜æ´»ç€
                loop = asyncio.get_event_loop()
                try:
                    await loop.run_in_executor(None, container.reload)
                    if container.status == "running":
                        self.in_use[container.id] = time.time()
                        logger.debug(f"ğŸ“¦ ä»æ± ä¸­è·å–å®¹å™¨: {container.id[:12]}")
                        return container
                except:
                    # å®¹å™¨å·²å¤±æ•ˆï¼Œåˆ›å»ºæ–°çš„
                    pass
            except:
                pass
            
            await asyncio.sleep(0.1)
        
        # è¶…æ—¶ï¼Œåˆ›å»ºä¸´æ—¶å®¹å™¨
        logger.warning("âš ï¸  å®¹å™¨æ± å·²æ»¡ï¼Œåˆ›å»ºä¸´æ—¶å®¹å™¨")
        container = await self._create_container(f"temp_{uuid.uuid4().hex[:8]}")
        self.in_use[container.id] = time.time()
        return container
    
    async def release(self, container):
        """
        é‡Šæ”¾å®¹å™¨
        
        Args:
            container: å®¹å™¨å¯¹è±¡
        """
        if container.id in self.in_use:
            del self.in_use[container.id]
        
        try:
            # æ¸…ç†å®¹å™¨
            await self._cleanup_container(container)
            
            # æ”¾å›æ± ä¸­
            if self.available_containers.qsize() < self.pool_size:
                self.available_containers.put(container)
                logger.debug(f"ğŸ“¦ é‡Šæ”¾å®¹å™¨åˆ°æ± : {container.id[:12]}")
            else:
                # æ± å·²æ»¡ï¼Œé”€æ¯å®¹å™¨
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, lambda: container.remove(force=True))
                logger.debug(f"ğŸ—‘ï¸  é”€æ¯å¤šä½™å®¹å™¨: {container.id[:12]}")
        except Exception as e:
            logger.error(f"âŒ é‡Šæ”¾å®¹å™¨å¤±è´¥: {e}")
    
    async def _cleanup_container(self, container):
        """æ¸…ç†å®¹å™¨çŠ¶æ€"""
        loop = asyncio.get_event_loop()
        
        try:
            # åœæ­¢æ‰€æœ‰è¿›ç¨‹
            await loop.run_in_executor(
                None,
                lambda: container.exec_run("pkill -9 python", detach=False)
            )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            await loop.run_in_executor(
                None,
                lambda: container.exec_run("rm -rf /workspace/* /tmp/*", detach=False)
            )
        except Exception as e:
            logger.warning(f"âš ï¸  æ¸…ç†å®¹å™¨æ—¶å‡ºé”™: {e}")
    
    def get_stats(self) -> Dict[str, int]:
        """è·å–å®¹å™¨æ± ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "available": self.available_containers.qsize(),
            "in_use": len(self.in_use),
            "total": self.pool_size
        }


class EnhancedExecutionEngine:
    """
    å¢å¼ºç‰ˆæ‰§è¡Œå¼•æ“
    """
    
    def __init__(
        self,
        docker_image: str = "python:3.11-slim",
        timeout: int = 300,
        max_memory: str = "1g",
        pool_size: int = 5
    ):
        """
        åˆå§‹åŒ–æ‰§è¡Œå¼•æ“
        
        Args:
            docker_image: Dockeré•œåƒ
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_memory: æœ€å¤§å†…å­˜
            pool_size: å®¹å™¨æ± å¤§å°
        """
        self.docker_image = docker_image
        self.timeout = timeout
        self.max_memory = max_memory
        
        # åˆ›å»ºå®¹å™¨æ± 
        self.container_pool = ContainerPool(
            docker_image=docker_image,
            pool_size=pool_size
        )
        
        # WebSocketå›è°ƒ
        self.ws_callbacks: Dict[str, Callable] = {}
    
    def register_ws_callback(self, execution_id: str, callback: Callable):
        """
        æ³¨å†ŒWebSocketå›è°ƒå‡½æ•°
        
        Args:
            execution_id: æ‰§è¡ŒID
            callback: å›è°ƒå‡½æ•°
        """
        self.ws_callbacks[execution_id] = callback
    
    def unregister_ws_callback(self, execution_id: str):
        """æ³¨é”€WebSocketå›è°ƒ"""
        if execution_id in self.ws_callbacks:
            del self.ws_callbacks[execution_id]
    
    async def _send_ws_message(self, execution_id: str, message_type: str, data: Any):
        """å‘é€WebSocketæ¶ˆæ¯"""
        if execution_id in self.ws_callbacks:
            try:
                callback = self.ws_callbacks[execution_id]
                await callback({
                    "type": message_type,
                    "data": data,
                    "timestamp": datetime.utcnow().isoformat()
                })
            except Exception as e:
                logger.error(f"âŒ WebSocketæ¶ˆæ¯å‘é€å¤±è´¥: {e}")
    
    async def execute_script(
        self,
        execution_id: str,
        script_path: str,
        input_params: Dict[str, Any],
        code_files: Optional[Dict[str, str]] = None,
        dependencies: Optional[list] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡ŒPythonè„šæœ¬
        
        Args:
            execution_id: æ‰§è¡ŒID
            script_path: è„šæœ¬æ–‡ä»¶è·¯å¾„
            input_params: è¾“å…¥å‚æ•°
            code_files: ä¿®æ”¹çš„ä»£ç æ–‡ä»¶ {path: content}
            dependencies: ä¾èµ–åˆ—è¡¨
            
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œ: {execution_id}")
        logger.info(f"   è„šæœ¬: {script_path}")
        logger.info(f"   å‚æ•°: {input_params}")
        
        result = {
            "execution_id": execution_id,
            "status": "pending",
            "output_data": None,
            "console_output": "",
            "error_message": None,
            "execution_time": 0.0,
            "result_files": []
        }
        
        container = None
        temp_dir = None
        
        try:
            # å‘é€å¼€å§‹æ¶ˆæ¯
            await self._send_ws_message(execution_id, "status", {"status": "starting"})
            
            # 1. å‡†å¤‡å·¥ä½œç›®å½•
            temp_dir = tempfile.mkdtemp(prefix=f"exec_{execution_id}_")
            workspace_dir = Path(temp_dir) / "workspace"
            workspace_dir.mkdir()
            
            # 2. å¤åˆ¶è„šæœ¬å’Œç›¸å…³æ–‡ä»¶
            await self._prepare_workspace(
                workspace_dir,
                script_path,
                code_files
            )
            
            # 3. ä¿å­˜å‚æ•°
            params_file = workspace_dir / "params.json"
            with open(params_file, 'w') as f:
                json.dump(input_params, f)
            
            # 4. è·å–å®¹å™¨
            container = await self.container_pool.acquire(timeout=30.0)
            
            # 5. å®‰è£…ä¾èµ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if dependencies:
                await self._send_ws_message(execution_id, "status", {"status": "installing_dependencies"})
                await self._install_dependencies(container, dependencies)
            
            # 6. æ‰§è¡Œè„šæœ¬
            await self._send_ws_message(execution_id, "status", {"status": "running"})
            
            start_time = time.time()
            
            execution_result = await self._run_in_container(
                container=container,
                workspace_dir=workspace_dir,
                script_path=script_path,
                execution_id=execution_id
            )
            
            execution_time = time.time() - start_time
            
            # 7. å¤„ç†ç»“æœ
            result["execution_time"] = execution_time
            result["console_output"] = execution_result.get("stdout", "")
            result["error_message"] = execution_result.get("stderr", "")
            
            if execution_result.get("exit_code") == 0:
                result["status"] = "completed"
                
                # æ”¶é›†ç»“æœæ–‡ä»¶
                result["result_files"] = await self._collect_result_files(workspace_dir)
                
                # å‘é€å®Œæˆæ¶ˆæ¯
                await self._send_ws_message(execution_id, "completed", {
                    "execution_time": execution_time,
                    "result_files": result["result_files"]
                })
                
                logger.info(f"âœ… æ‰§è¡ŒæˆåŠŸ: {execution_id} ({execution_time:.2f}s)")
            else:
                result["status"] = "failed"
                await self._send_ws_message(execution_id, "failed", {
                    "error": result["error_message"]
                })
                logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {execution_id}")
        
        except asyncio.TimeoutError:
            result["status"] = "timeout"
            result["error_message"] = f"æ‰§è¡Œè¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰"
            await self._send_ws_message(execution_id, "timeout", {})
            logger.error(f"â±ï¸  æ‰§è¡Œè¶…æ—¶: {execution_id}")
        
        except Exception as e:
            result["status"] = "failed"
            result["error_message"] = str(e)
            await self._send_ws_message(execution_id, "error", {"error": str(e)})
            logger.error(f"âŒ æ‰§è¡Œå¼‚å¸¸: {execution_id}, {e}")
        
        finally:
            # æ¸…ç†èµ„æº
            if container:
                await self.container_pool.release(container)
            
            if temp_dir and os.path.exists(temp_dir):
                shutil.rmtree(temp_dir, ignore_errors=True)
            
            # æ³¨é”€å›è°ƒ
            self.unregister_ws_callback(execution_id)
        
        return result
    
    async def _prepare_workspace(
        self,
        workspace_dir: Path,
        script_path: str,
        code_files: Optional[Dict[str, str]] = None
    ):
        """å‡†å¤‡å·¥ä½œç©ºé—´"""
        # å¤åˆ¶è„šæœ¬ç›®å½•ç»“æ„
        script_path_obj = Path(script_path)
        
        if script_path_obj.exists():
            # å¤åˆ¶æ¡ˆä¾‹ç›®å½•
            case_dir = script_path_obj.parent
            target_dir = workspace_dir / "code"
            
            shutil.copytree(case_dir, target_dir, dirs_exist_ok=True)
            
            # åº”ç”¨ç”¨æˆ·ä¿®æ”¹çš„æ–‡ä»¶
            if code_files:
                for file_path, content in code_files.items():
                    target_file = target_dir / file_path
                    target_file.parent.mkdir(parents=True, exist_ok=True)
                    target_file.write_text(content)
    
    async def _install_dependencies(self, container, dependencies: list):
        """å®‰è£…ä¾èµ–"""
        if not dependencies:
            return
        
        # åˆ›å»ºrequirements.txt
        requirements = "\n".join(dependencies)
        
        loop = asyncio.get_event_loop()
        
        # å†™å…¥requirements.txt
        exec_result = await loop.run_in_executor(
            None,
            lambda: container.exec_run(
                f"bash -c 'echo \"{requirements}\" > /tmp/requirements.txt'",
                workdir="/workspace"
            )
        )
        
        # å®‰è£…ä¾èµ–
        exec_result = await loop.run_in_executor(
            None,
            lambda: container.exec_run(
                "pip install -r /tmp/requirements.txt --quiet",
                workdir="/workspace"
            )
        )
        
        logger.info(f"âœ… ä¾èµ–å®‰è£…å®Œæˆ")
    
    async def _run_in_container(
        self,
        container,
        workspace_dir: Path,
        script_path: str,
        execution_id: str
    ) -> Dict[str, Any]:
        """åœ¨å®¹å™¨ä¸­è¿è¡Œè„šæœ¬"""
        loop = asyncio.get_event_loop()
        
        # æŒ‚è½½å·¥ä½œç›®å½•ï¼ˆDocker APIæ–¹å¼ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å…ˆå¤åˆ¶æ–‡ä»¶åˆ°å®¹å™¨
        
        # å¤åˆ¶å·¥ä½œç›®å½•åˆ°å®¹å™¨
        import tarfile
        import io
        
        # åˆ›å»ºtaræ–‡ä»¶
        tar_stream = io.BytesIO()
        with tarfile.open(fileobj=tar_stream, mode='w') as tar:
            tar.add(workspace_dir, arcname='workspace')
        tar_stream.seek(0)
        
        # ä¸Šä¼ åˆ°å®¹å™¨
        await loop.run_in_executor(
            None,
            lambda: container.put_archive('/', tar_stream.read())
        )
        
        # æ‰§è¡Œå‘½ä»¤
        script_name = Path(script_path).name
        command = f"cd /workspace/code && python {script_name}"
        
        # æ‰§è¡Œ
        exec_result = await asyncio.wait_for(
            loop.run_in_executor(
                None,
                lambda: container.exec_run(
                    command,
                    workdir="/workspace/code",
                    stream=True,
                    demux=True
                )
            ),
            timeout=self.timeout
        )
        
        # æ”¶é›†è¾“å‡º
        stdout_lines = []
        stderr_lines = []
        
        for stdout, stderr in exec_result.output:
            if stdout:
                line = stdout.decode('utf-8')
                stdout_lines.append(line)
                # å®æ—¶å‘é€è¾“å‡º
                await self._send_ws_message(execution_id, "output", {"text": line})
            
            if stderr:
                line = stderr.decode('utf-8')
                stderr_lines.append(line)
                await self._send_ws_message(execution_id, "error_output", {"text": line})
        
        return {
            "exit_code": exec_result.exit_code,
            "stdout": "".join(stdout_lines),
            "stderr": "".join(stderr_lines) if stderr_lines else None
        }
    
    async def _collect_result_files(self, workspace_dir: Path) -> List[Dict]:
        """æ”¶é›†ç»“æœæ–‡ä»¶"""
        result_files = []
        
        # æ‰«æè¾“å‡ºç›®å½•
        output_patterns = [
            "*.png", "*.jpg", "*.svg",  # å›¾ç‰‡
            "*.csv", "*.xlsx",  # è¡¨æ ¼
            "*.json",  # æ•°æ®
            "*.md", "*.txt",  # æŠ¥å‘Š
            "*.mp4", "*.gif"  # åŠ¨ç”»
        ]
        
        for pattern in output_patterns:
            for file_path in workspace_dir.rglob(pattern):
                if file_path.is_file():
                    file_info = {
                        "type": self._detect_file_type(file_path),
                        "name": file_path.name,
                        "path": str(file_path.relative_to(workspace_dir)),
                        "size": file_path.stat().st_size
                    }
                    result_files.append(file_info)
        
        return result_files
    
    def _detect_file_type(self, file_path: Path) -> str:
        """æ£€æµ‹æ–‡ä»¶ç±»å‹"""
        ext = file_path.suffix.lower()
        
        type_map = {
            '.png': 'plot', '.jpg': 'plot', '.svg': 'plot',
            '.csv': 'table', '.xlsx': 'table',
            '.json': 'data',
            '.md': 'report', '.txt': 'report',
            '.mp4': 'video', '.gif': 'animation'
        }
        
        return type_map.get(ext, 'unknown')
    
    def get_pool_stats(self) -> Dict[str, int]:
        """è·å–å®¹å™¨æ± ç»Ÿè®¡"""
        return self.container_pool.get_stats()


# å…¨å±€æ‰§è¡Œå¼•æ“å®ä¾‹
enhanced_execution_engine = EnhancedExecutionEngine(
    docker_image="python:3.11-slim",
    timeout=300,
    max_memory="1g",
    pool_size=5
)
