#!/usr/bin/env python3
"""
æ—¥å¿—åˆ†æå·¥å…·
åˆ†æåº”ç”¨æ—¥å¿—ï¼Œæå–å…³é”®ä¿¡æ¯å’Œç»Ÿè®¡æ•°æ®
"""

import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
from typing import Dict, List
import json


class LogAnalyzer:
    """æ—¥å¿—åˆ†æå™¨"""
    
    def __init__(self, log_file: str = None):
        self.log_file = log_file or "/var/log/platform/app.log"
        self.logs = []
        self.stats = defaultdict(int)
    
    def parse_log_line(self, line: str) -> Dict:
        """è§£ææ—¥å¿—è¡Œ"""
        # ç®€åŒ–çš„æ—¥å¿—æ ¼å¼è§£æ
        # 2025-11-04 14:23:45 | INFO | module.function:123 | Message
        
        pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\s+\|\s+(\w+)\s+\|\s+([\w.]+):(\d+)\s+\|\s+(.+)'
        
        match = re.match(pattern, line)
        if match:
            timestamp, level, location, lineno, message = match.groups()
            return {
                'timestamp': timestamp,
                'level': level,
                'location': location,
                'lineno': int(lineno),
                'message': message
            }
        
        return None
    
    def load_logs(self, limit: int = None):
        """åŠ è½½æ—¥å¿—æ–‡ä»¶"""
        print(f"ğŸ“‚ åŠ è½½æ—¥å¿—: {self.log_file}")
        
        try:
            log_path = Path(self.log_file)
            
            if not log_path.exists():
                print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                self.generate_sample_logs()
                return
            
            with open(log_path, 'r') as f:
                lines = f.readlines()
                
                if limit:
                    lines = lines[-limit:]
                
                for line in lines:
                    parsed = self.parse_log_line(line.strip())
                    if parsed:
                        self.logs.append(parsed)
            
            print(f"âœ“ åŠ è½½äº† {len(self.logs)} æ¡æ—¥å¿—")
            
        except Exception as e:
            print(f"âœ— åŠ è½½å¤±è´¥: {e}")
            self.generate_sample_logs()
    
    def generate_sample_logs(self):
        """ç”Ÿæˆç¤ºä¾‹æ—¥å¿—"""
        sample_logs = [
            {'timestamp': '2025-11-04 14:23:45', 'level': 'INFO', 'location': 'app.main', 'lineno': 45, 'message': 'Application started'},
            {'timestamp': '2025-11-04 14:23:46', 'level': 'INFO', 'location': 'app.api.sessions', 'lineno': 120, 'message': 'Session created: session_001'},
            {'timestamp': '2025-11-04 14:23:48', 'level': 'INFO', 'location': 'app.services.execution', 'lineno': 89, 'message': 'Execution started: exec_001'},
            {'timestamp': '2025-11-04 14:23:50', 'level': 'WARNING', 'location': 'app.services.execution', 'lineno': 156, 'message': 'High memory usage detected'},
            {'timestamp': '2025-11-04 14:23:52', 'level': 'INFO', 'location': 'app.services.execution', 'lineno': 234, 'message': 'Execution completed: exec_001'},
            {'timestamp': '2025-11-04 14:23:55', 'level': 'ERROR', 'location': 'app.services.ai', 'lineno': 67, 'message': 'API rate limit exceeded'},
            {'timestamp': '2025-11-04 14:23:58', 'level': 'INFO', 'location': 'app.api.sessions', 'lineno': 145, 'message': 'Session terminated: session_001'},
        ]
        
        self.logs = sample_logs * 10  # é‡å¤ä»¥å¢åŠ æ•°é‡
        print(f"âœ“ ç”Ÿæˆäº† {len(self.logs)} æ¡ç¤ºä¾‹æ—¥å¿—")
    
    def analyze(self):
        """åˆ†ææ—¥å¿—"""
        print("\nğŸ“Š åˆ†ææ—¥å¿—...")
        
        # æŒ‰çº§åˆ«ç»Ÿè®¡
        level_counter = Counter(log['level'] for log in self.logs)
        self.stats['by_level'] = dict(level_counter)
        
        # æŒ‰æ¨¡å—ç»Ÿè®¡
        location_counter = Counter(log['location'] for log in self.logs)
        self.stats['by_module'] = dict(location_counter.most_common(10))
        
        # é”™è¯¯ç»Ÿè®¡
        errors = [log for log in self.logs if log['level'] == 'ERROR']
        error_messages = Counter(log['message'] for log in errors)
        self.stats['top_errors'] = dict(error_messages.most_common(5))
        
        # æ—¶é—´èŒƒå›´
        if self.logs:
            self.stats['time_range'] = {
                'start': self.logs[0]['timestamp'],
                'end': self.logs[-1]['timestamp']
            }
        
        # ç»Ÿè®¡æ€»æ•°
        self.stats['total'] = len(self.logs)
        self.stats['error_rate'] = len(errors) / max(len(self.logs), 1) * 100
        
        print("âœ“ åˆ†æå®Œæˆ")
    
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("=" * 70)
        report.append(" æ—¥å¿—åˆ†ææŠ¥å‘Š")
        report.append("=" * 70)
        report.append("")
        
        # åŸºæœ¬ä¿¡æ¯
        report.append("ğŸ“‹ åŸºæœ¬ä¿¡æ¯")
        report.append("-" * 70)
        report.append(f"  æ—¥å¿—æ–‡ä»¶: {self.log_file}")
        report.append(f"  æ€»æ—¥å¿—æ•°: {self.stats['total']:,}")
        if 'time_range' in self.stats:
            report.append(f"  æ—¶é—´èŒƒå›´: {self.stats['time_range']['start']} è‡³ {self.stats['time_range']['end']}")
        report.append("")
        
        # æ—¥å¿—çº§åˆ«åˆ†å¸ƒ
        report.append("ğŸ“Š æ—¥å¿—çº§åˆ«åˆ†å¸ƒ")
        report.append("-" * 70)
        for level, count in sorted(self.stats['by_level'].items(), key=lambda x: x[1], reverse=True):
            percentage = count / self.stats['total'] * 100
            bar = 'â–ˆ' * int(percentage / 2)
            report.append(f"  {level.ljust(10)} {count:6,} ({percentage:5.1f}%)  {bar}")
        report.append("")
        
        # é”™è¯¯ç‡
        report.append("âš ï¸  é”™è¯¯ç»Ÿè®¡")
        report.append("-" * 70)
        report.append(f"  é”™è¯¯ç‡: {self.stats['error_rate']:.2f}%")
        
        if self.stats.get('top_errors'):
            report.append("\n  å¸¸è§é”™è¯¯:")
            for error, count in self.stats['top_errors'].items():
                report.append(f"    â€¢ {error[:60]} ({count}æ¬¡)")
        report.append("")
        
        # çƒ­ç‚¹æ¨¡å—
        report.append("ğŸ”¥ æ´»è·ƒæ¨¡å— (Top 10)")
        report.append("-" * 70)
        for module, count in self.stats['by_module'].items():
            report.append(f"  {module.ljust(40)} {count:6,} æ¡æ—¥å¿—")
        report.append("")
        
        report.append("=" * 70)
        
        return "\n".join(report)
    
    def export_json(self, output_file: str):
        """å¯¼å‡ºJSONæ ¼å¼"""
        data = {
            'timestamp': datetime.now().isoformat(),
            'stats': self.stats,
            'sample_logs': self.logs[:10]  # åªå¯¼å‡ºå‰10æ¡ä½œä¸ºæ ·æœ¬
        }
        
        with open(output_file, 'w') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ å¯¼å‡ºJSON: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print(" æ™ºèƒ½çŸ¥è¯†å¹³å° - æ—¥å¿—åˆ†æå·¥å…·")
    print("=" * 70)
    print()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = LogAnalyzer()
    
    # åŠ è½½æ—¥å¿—
    analyzer.load_logs(limit=1000)  # åˆ†ææœ€è¿‘1000æ¡
    
    # åˆ†æ
    analyzer.analyze()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report()
    print(report)
    
    # å¯¼å‡º
    output_file = f"log_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    analyzer.export_json(output_file)
    
    print()
    print("ğŸ’¡ æç¤º:")
    print("  â€¢ ä¿®æ”¹ log_file å‚æ•°å¯ä»¥åˆ†æä¸åŒçš„æ—¥å¿—æ–‡ä»¶")
    print("  â€¢ ä½¿ç”¨ limit å‚æ•°å¯ä»¥é™åˆ¶åˆ†æçš„æ—¥å¿—æ•°é‡")
    print("  â€¢ JSONå¯¼å‡ºæ–‡ä»¶å¯ç”¨äºè¿›ä¸€æ­¥åˆ†ææˆ–å¯è§†åŒ–")


if __name__ == "__main__":
    main()
