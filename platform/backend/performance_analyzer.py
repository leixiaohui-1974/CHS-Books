#!/usr/bin/env python3
"""
æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å·¥å…·
åˆ†æä»£ç æ€§èƒ½ç“¶é¢ˆå¹¶æä¾›ä¼˜åŒ–å»ºè®®
"""

import time
import psutil
import os
import sys
from pathlib import Path
from typing import Dict, List, Any
import json
from datetime import datetime


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.results = []
        self.recommendations = []
    
    def analyze_system_resources(self) -> Dict[str, Any]:
        """åˆ†æç³»ç»Ÿèµ„æºä½¿ç”¨"""
        print("ğŸ” åˆ†æç³»ç»Ÿèµ„æº...")
        
        # CPUä¿¡æ¯
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        cpu_freq = psutil.cpu_freq()
        
        # å†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        swap = psutil.swap_memory()
        
        # ç£ç›˜ä¿¡æ¯
        disk = psutil.disk_usage('/')
        disk_io = psutil.disk_io_counters()
        
        # ç½‘ç»œä¿¡æ¯
        net_io = psutil.net_io_counters()
        
        result = {
            'cpu': {
                'usage_percent': cpu_percent,
                'count': cpu_count,
                'frequency_mhz': cpu_freq.current if cpu_freq else None,
                'status': 'good' if cpu_percent < 70 else 'warning' if cpu_percent < 90 else 'critical'
            },
            'memory': {
                'total_gb': memory.total / (1024**3),
                'available_gb': memory.available / (1024**3),
                'used_percent': memory.percent,
                'status': 'good' if memory.percent < 70 else 'warning' if memory.percent < 90 else 'critical'
            },
            'swap': {
                'total_gb': swap.total / (1024**3),
                'used_percent': swap.percent,
                'status': 'good' if swap.percent < 50 else 'warning'
            },
            'disk': {
                'total_gb': disk.total / (1024**3),
                'used_gb': disk.used / (1024**3),
                'used_percent': disk.percent,
                'read_mb': disk_io.read_bytes / (1024**2) if disk_io else 0,
                'write_mb': disk_io.write_bytes / (1024**2) if disk_io else 0,
                'status': 'good' if disk.percent < 80 else 'warning' if disk.percent < 95 else 'critical'
            },
            'network': {
                'sent_mb': net_io.bytes_sent / (1024**2),
                'recv_mb': net_io.bytes_recv / (1024**2),
                'status': 'good'
            }
        }
        
        # ç”Ÿæˆå»ºè®®
        if result['cpu']['status'] != 'good':
            self.recommendations.append({
                'type': 'cpu',
                'level': 'high',
                'message': f"CPUä½¿ç”¨ç‡è¿‡é«˜({cpu_percent:.1f}%)ï¼Œè€ƒè™‘ä¼˜åŒ–è®¡ç®—å¯†é›†å‹ä»»åŠ¡æˆ–å¢åŠ CPUèµ„æº"
            })
        
        if result['memory']['status'] != 'good':
            self.recommendations.append({
                'type': 'memory',
                'level': 'high',
                'message': f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜({memory.percent:.1f}%)ï¼Œè€ƒè™‘ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ å†…å­˜"
            })
        
        if result['disk']['status'] != 'good':
            self.recommendations.append({
                'type': 'disk',
                'level': 'medium',
                'message': f"ç£ç›˜ç©ºé—´ä¸è¶³({disk.percent:.1f}%)ï¼Œå»ºè®®æ¸…ç†ä¸´æ—¶æ–‡ä»¶æˆ–æ‰©å±•ç£ç›˜"
            })
        
        return result
    
    def analyze_code_hotspots(self) -> Dict[str, Any]:
        """åˆ†æä»£ç çƒ­ç‚¹"""
        print("ğŸ” åˆ†æä»£ç çƒ­ç‚¹...")
        
        backend_dir = Path(__file__).parent
        
        hotspots = []
        
        # åˆ†æPythonæ–‡ä»¶
        py_files = list(backend_dir.rglob("*.py"))
        
        for py_file in py_files[:20]:  # é™åˆ¶åˆ†ææ•°é‡
            if '__pycache__' in str(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                
                # ç®€å•çš„çƒ­ç‚¹æ£€æµ‹
                issues = []
                
                # æ£€æŸ¥å¾ªç¯åµŒå¥—
                nested_loops = 0
                for line in lines:
                    stripped = line.strip()
                    if stripped.startswith('for ') or stripped.startswith('while '):
                        nested_loops += 1
                        if nested_loops > 2:
                            issues.append('æ·±åº¦åµŒå¥—å¾ªç¯')
                            break
                
                # æ£€æŸ¥å¤§å‡½æ•°
                func_lines = 0
                in_function = False
                for line in lines:
                    if line.strip().startswith('def '):
                        in_function = True
                        func_lines = 0
                    elif in_function:
                        func_lines += 1
                        if func_lines > 100:
                            issues.append('å‡½æ•°è¿‡é•¿(>100è¡Œ)')
                            in_function = False
                
                if issues:
                    hotspots.append({
                        'file': str(py_file.relative_to(backend_dir)),
                        'issues': issues,
                        'lines': len(lines)
                    })
            
            except Exception as e:
                pass
        
        result = {
            'files_analyzed': len(py_files),
            'hotspots_found': len(hotspots),
            'hotspots': hotspots[:10]  # è¿”å›å‰10ä¸ª
        }
        
        if hotspots:
            self.recommendations.append({
                'type': 'code',
                'level': 'medium',
                'message': f"å‘ç°{len(hotspots)}ä¸ªä»£ç çƒ­ç‚¹ï¼Œå»ºè®®é‡æ„ä¼˜åŒ–"
            })
        
        return result
    
    def analyze_database_queries(self) -> Dict[str, Any]:
        """åˆ†ææ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
        print("ğŸ” åˆ†ææ•°æ®åº“æŸ¥è¯¢...")
        
        # æ¨¡æ‹Ÿåˆ†æï¼ˆå®é™…éœ€è¦è¿æ¥æ•°æ®åº“ï¼‰
        result = {
            'slow_queries': 0,
            'total_queries': 0,
            'avg_query_time_ms': 0,
            'recommendations': []
        }
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ä¸­çš„æŸ¥è¯¢
        models_dir = Path(__file__).parent / 'app' / 'models'
        
        if models_dir.exists():
            model_files = list(models_dir.glob("*.py"))
            
            for model_file in model_files:
                try:
                    with open(model_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç´¢å¼•
                    if 'index=True' not in content and 'relationship' in content:
                        result['recommendations'].append(
                            f"{model_file.name}: è€ƒè™‘ä¸ºå…³è”å­—æ®µæ·»åŠ ç´¢å¼•"
                        )
                
                except Exception:
                    pass
        
        if result['recommendations']:
            self.recommendations.append({
                'type': 'database',
                'level': 'medium',
                'message': 'æ•°æ®åº“æ¨¡å‹å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ç´¢å¼•'
            })
        
        return result
    
    def analyze_api_performance(self) -> Dict[str, Any]:
        """åˆ†æAPIæ€§èƒ½"""
        print("ğŸ” åˆ†æAPIæ€§èƒ½...")
        
        api_dir = Path(__file__).parent / 'app' / 'api' / 'endpoints'
        
        endpoints = []
        
        if api_dir.exists():
            for api_file in api_dir.glob("*.py"):
                try:
                    with open(api_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ç»Ÿè®¡ç«¯ç‚¹æ•°é‡
                    import re
                    routes = re.findall(r'@router\.(get|post|put|delete|patch)', content)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰async
                    async_count = content.count('async def')
                    sync_count = content.count('def ') - async_count
                    
                    endpoints.append({
                        'file': api_file.name,
                        'routes': len(routes),
                        'async_endpoints': async_count,
                        'sync_endpoints': sync_count
                    })
                    
                    if sync_count > async_count:
                        self.recommendations.append({
                            'type': 'api',
                            'level': 'low',
                            'message': f"{api_file.name}: è€ƒè™‘ä½¿ç”¨async/awaitæé«˜å¹¶å‘æ€§èƒ½"
                        })
                
                except Exception:
                    pass
        
        result = {
            'total_endpoints': sum(e['routes'] for e in endpoints),
            'files': len(endpoints),
            'endpoints': endpoints
        }
        
        return result
    
    def analyze_dependencies(self) -> Dict[str, Any]:
        """åˆ†æä¾èµ–åŒ…æ€§èƒ½"""
        print("ğŸ” åˆ†æä¾èµ–åŒ…...")
        
        requirements_file = Path(__file__).parent / 'requirements.txt'
        
        result = {
            'total_packages': 0,
            'heavy_packages': [],
            'recommendations': []
        }
        
        if requirements_file.exists():
            with open(requirements_file, 'r') as f:
                packages = [line.strip() for line in f if line.strip() and not line.startswith('#')]
            
            result['total_packages'] = len(packages)
            
            # è¯†åˆ«é‡é‡çº§åŒ…
            heavy = ['tensorflow', 'torch', 'pandas', 'numpy', 'opencv']
            for pkg in packages:
                pkg_name = pkg.split('==')[0].split('>=')[0].lower()
                if any(h in pkg_name for h in heavy):
                    result['heavy_packages'].append(pkg)
            
            if result['heavy_packages']:
                result['recommendations'].append(
                    f"å‘ç°{len(result['heavy_packages'])}ä¸ªé‡é‡çº§ä¾èµ–ï¼Œè€ƒè™‘æŒ‰éœ€å¯¼å…¥"
                )
        
        return result
    
    def generate_optimization_plan(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆä¼˜åŒ–è®¡åˆ’"""
        print("\nğŸ“‹ ç”Ÿæˆä¼˜åŒ–è®¡åˆ’...")
        
        plan = []
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºå»ºè®®
        high_priority = [r for r in self.recommendations if r.get('level') == 'high']
        medium_priority = [r for r in self.recommendations if r.get('level') == 'medium']
        low_priority = [r for r in self.recommendations if r.get('level') == 'low']
        
        for priority, items in [('é«˜', high_priority), ('ä¸­', medium_priority), ('ä½', low_priority)]:
            for item in items:
                plan.append({
                    'priority': priority,
                    'type': item['type'],
                    'recommendation': item['message']
                })
        
        return plan
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = []
        report.append("\n" + "=" * 70)
        report.append(" æ€§èƒ½åˆ†ææŠ¥å‘Š")
        report.append("=" * 70)
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # ç³»ç»Ÿèµ„æº
        if 'system' in [r['name'] for r in self.results]:
            system = next(r for r in self.results if r['name'] == 'system')['data']
            report.append("ğŸ“Š ç³»ç»Ÿèµ„æº:")
            report.append("-" * 70)
            report.append(f"  CPU:    ä½¿ç”¨ç‡ {system['cpu']['usage_percent']:.1f}% ({system['cpu']['count']}æ ¸)")
            report.append(f"  å†…å­˜:   ä½¿ç”¨ç‡ {system['memory']['used_percent']:.1f}% ({system['memory']['available_gb']:.1f}GBå¯ç”¨)")
            report.append(f"  ç£ç›˜:   ä½¿ç”¨ç‡ {system['disk']['used_percent']:.1f}% ({system['disk']['total_gb'] - system['disk']['used_gb']:.1f}GBå¯ç”¨)")
            report.append("")
        
        # ä¼˜åŒ–å»ºè®®
        if self.recommendations:
            report.append("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            report.append("-" * 70)
            
            plan = self.generate_optimization_plan()
            for i, item in enumerate(plan, 1):
                priority_icon = "ğŸ”´" if item['priority'] == 'é«˜' else "ğŸŸ¡" if item['priority'] == 'ä¸­' else "ğŸŸ¢"
                report.append(f"  {i}. [{priority_icon} {item['priority']}] {item['type'].upper()}")
                report.append(f"     {item['recommendation']}")
            
            report.append("")
        else:
            report.append("âœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½é—®é¢˜")
            report.append("")
        
        report.append("=" * 70)
        
        return "\n".join(report)
    
    def export_json(self, filename: str):
        """å¯¼å‡ºJSONæŠ¥å‘Š"""
        data = {
            'timestamp': datetime.now().isoformat(),
            'results': self.results,
            'recommendations': self.recommendations,
            'optimization_plan': self.generate_optimization_plan()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ JSONæŠ¥å‘Šå·²å¯¼å‡º: {filename}")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("=" * 70)
        print(" æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å·¥å…·")
        print("=" * 70)
        print()
        
        # ç³»ç»Ÿèµ„æºåˆ†æ
        system_result = self.analyze_system_resources()
        self.results.append({'name': 'system', 'data': system_result})
        print("âœ“ ç³»ç»Ÿèµ„æºåˆ†æå®Œæˆ")
        
        # ä»£ç çƒ­ç‚¹åˆ†æ
        code_result = self.analyze_code_hotspots()
        self.results.append({'name': 'code', 'data': code_result})
        print("âœ“ ä»£ç çƒ­ç‚¹åˆ†æå®Œæˆ")
        
        # æ•°æ®åº“åˆ†æ
        db_result = self.analyze_database_queries()
        self.results.append({'name': 'database', 'data': db_result})
        print("âœ“ æ•°æ®åº“æŸ¥è¯¢åˆ†æå®Œæˆ")
        
        # APIæ€§èƒ½åˆ†æ
        api_result = self.analyze_api_performance()
        self.results.append({'name': 'api', 'data': api_result})
        print("âœ“ APIæ€§èƒ½åˆ†æå®Œæˆ")
        
        # ä¾èµ–åˆ†æ
        dep_result = self.analyze_dependencies()
        self.results.append({'name': 'dependencies', 'data': dep_result})
        print("âœ“ ä¾èµ–åŒ…åˆ†æå®Œæˆ")
        
        # ç”ŸæˆæŠ¥å‘Š
        print(self.generate_report())
        
        # å¯¼å‡ºJSON
        filename = f"performance_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        self.export_json(filename)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = PerformanceAnalyzer()
    analyzer.run_analysis()


if __name__ == "__main__":
    main()
