#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è€ƒç ”æ•™æä¸“ç”¨å¯¼å…¥è„šæœ¬
æ”¯æŒå¢é‡æ›´æ–°å’Œæ‰¹é‡å¯¼å…¥ï¼Œæ–¹ä¾¿éšæ—¶æ·»åŠ æ–°å†…å®¹
"""

import sys
import io
from pathlib import Path
import re
from datetime import datetime

# è®¾ç½®UTF-8è¾“å‡º
if sys.platform == 'win32' and hasattr(sys.stdout, 'buffer'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.textbook.database import SessionLocal
from services.textbook.models import Textbook, TextbookChapter, DifficultyLevel, Base
from sqlalchemy import create_engine

# é¡¹ç›®æ ¹ç›®å½•
EXAM_PREP_DIR = Path(__file__).parent.parent.parent.parent / "books" / "graduate-exam-prep"

# 15æœ¬è€ƒç ”ä¹¦é…ç½®
EXAM_BOOKS = [
    {
        "id": 1,
        "slug": "hydraulics-core-100",
        "title": "æ°´åŠ›å­¦è€ƒç ”æ ¸å¿ƒ100é¢˜",
        "subtitle": "ç²¾é€‰é¢˜ç›® + Pythonä»£ç ",
        "description": "æ°´åŠ›å­¦è€ƒç ”ç²¾é€‰100é¢˜ï¼Œæ¯é¢˜é…Pythonä»£ç å¯è§†åŒ–",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "completed",  # completed/in_progress/planned
        "priority": "P0"
    },
    {
        "id": 2,
        "slug": "hydraulics-advanced",
        "title": "æ°´åŠ›å­¦è€ƒç ”é«˜åˆ†çªç ´",
        "subtitle": "å®Œæ•´æ•™æ + çœŸé¢˜ç²¾è®²",
        "description": "æ°´åŠ›å­¦è€ƒç ”å®Œæ•´æ•™æï¼ŒåŒ…å«300+é¢˜ç›®å’ŒçœŸé¢˜ç²¾è®²",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "in_progress",  # æ­£åœ¨è¡¥å……å†…å®¹
        "priority": "P0"
    },
    {
        "id": 3,
        "slug": "hydrology-exam",
        "title": "æ°´æ–‡å­¦è€ƒç ”é«˜åˆ†çªç ´",
        "subtitle": "äº§æ±‡æµ + æ°´æ–‡ç»Ÿè®¡",
        "description": "æ°´æ–‡å­¦ä¸“ä¸šè¯¾è€ƒç ”æ•™æï¼Œæ¶µç›–äº§æ±‡æµã€æ°´æ–‡ç»Ÿè®¡ç­‰",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P0"
    },
    {
        "id": 4,
        "slug": "mathematics-for-water",
        "title": "æ°´åˆ©ç±»æ•°å­¦ä¸€é€Ÿæˆæ‰‹å†Œ",
        "subtitle": "é«˜æ•° + çº¿ä»£ + æ¦‚ç‡",
        "description": "é’ˆå¯¹æ°´åˆ©ä¸“ä¸šçš„æ•°å­¦ä¸€å¤ä¹ æ•™æ",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P1"
    },
    {
        "id": 5,
        "slug": "hydraulics-1000",
        "title": "æ°´åŠ›å­¦1000é¢˜è¯¦è§£",
        "subtitle": "æµ·é‡é¢˜åº“",
        "description": "1000+æ°´åŠ›å­¦é¢˜ç›®è¯¦è§£ï¼ŒæŒ‰éš¾åº¦åˆ†çº§",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P1"
    },
    {
        "id": 6,
        "slug": "python-for-hydraulic",
        "title": "æ°´åˆ©å·¥ç¨‹Pythonç¼–ç¨‹å®æˆ˜",
        "subtitle": "ä»£ç  + ç®—æ³•",
        "description": "50ä¸ªPythoné¡¹ç›®ï¼Œæ¶µç›–æ°´åŠ›è®¡ç®—å„ä¸ªæ–¹é¢",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P1"
    },
    {
        "id": 7,
        "slug": "30days-sprint",
        "title": "30å¤©è€ƒç ”å†²åˆºå®å…¸",
        "subtitle": "è€ƒå‰é€Ÿæˆ",
        "description": "è€ƒå‰30å¤©æ ¸å¿ƒçŸ¥è¯†ç‚¹é€Ÿæˆ",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P2"
    },
    {
        "id": 8,
        "slug": "hydraulic-structures-exam",
        "title": "æ°´å·¥å»ºç­‘ç‰©è®¾è®¡è€ƒç ”ä¸“é¢˜",
        "subtitle": "å·¥ç¨‹è®¾è®¡",
        "description": "æ°´å·¥å»ºç­‘ç‰©è®¾è®¡ä¸“é¢˜æ•™æ",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P2"
    },
    {
        "id": 9,
        "slug": "water-resources-exam",
        "title": "æ°´èµ„æºè§„åˆ’ä¸ç®¡ç†è€ƒç ”ä¸“é¢˜",
        "subtitle": "ä¼˜åŒ–è°ƒåº¦",
        "description": "æ°´èµ„æºè§„åˆ’ä¸ç®¡ç†ä¸“é¢˜æ•™æ",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P2"
    },
    {
        "id": 10,
        "slug": "ecohydraulics-exam",
        "title": "ç”Ÿæ€æ°´åŠ›å­¦è€ƒç ”ä¸“é¢˜",
        "subtitle": "ç”Ÿæ€ä¿æŠ¤",
        "description": "ç”Ÿæ€æ°´åŠ›å­¦ä¸“é¢˜æ•™æ",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P2"
    },
    {
        "id": 11,
        "slug": "groundwater-exam",
        "title": "åœ°ä¸‹æ°´åŠ¨åŠ›å­¦è€ƒç ”ä¸“é¢˜",
        "subtitle": "æ¸—æµç†è®º",
        "description": "åœ°ä¸‹æ°´åŠ¨åŠ›å­¦ä¸“é¢˜æ•™æ",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P2"
    },
    {
        "id": 12,
        "slug": "water-environment-exam",
        "title": "æ°´ç¯å¢ƒæ¨¡æ‹Ÿè€ƒç ”ä¸“é¢˜",
        "subtitle": "æ°´è´¨æ¨¡æ‹Ÿ",
        "description": "æ°´ç¯å¢ƒæ¨¡æ‹Ÿä¸“é¢˜æ•™æ",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P2"
    },
    {
        "id": 13,
        "slug": "numerical-methods-exam",
        "title": "æ°´åˆ©ç±»è€ƒç ”æ•°å€¼è®¡ç®—æ–¹æ³•",
        "subtitle": "æ•°å€¼ç®—æ³•",
        "description": "æ°´åˆ©å·¥ç¨‹ä¸­çš„æ•°å€¼è®¡ç®—æ–¹æ³•",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P2"
    },
    {
        "id": 14,
        "slug": "mock-exams",
        "title": "æ°´åˆ©ç±»è€ƒç ”å…¨çœŸæ¨¡æ‹Ÿè¯•å·",
        "subtitle": "æ¨¡æ‹Ÿæµ‹è¯•",
        "description": "10å¥—å®Œæ•´æ¨¡æ‹Ÿè¯•å·",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P3"
    },
    {
        "id": 15,
        "slug": "interview-guide",
        "title": "æ°´åˆ©è€ƒç ”é¢è¯•å®å…¸",
        "subtitle": "é¢è¯•æŠ€å·§",
        "description": "è€ƒç ”é¢è¯•æŠ€å·§ä¸æ¡ˆä¾‹",
        "target_audience": "æ°´åˆ©ç±»è€ƒç ”å­¦ç”Ÿ",
        "status": "planned",
        "priority": "P3"
    }
]


def parse_markdown_file(file_path):
    """è§£æMarkdownæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except Exception as e:
        print(f"[WARN] è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return ""


def extract_chapter_info(content, file_path):
    """ä»Markdownå†…å®¹ä¸­æå–ç« èŠ‚ä¿¡æ¯"""
    lines = content.split('\n')
    
    # æå–ç¬¬ä¸€ä¸ªæ ‡é¢˜ä½œä¸ºç« èŠ‚å
    title = file_path.stem
    for line in lines[:20]:
        if line.startswith('# '):
            title = line[2:].strip()
            break
    
    # è®¡ç®—å­—æ•°
    word_count = len(re.findall(r'[\u4e00-\u9fa5]', content))
    
    # æ£€æµ‹å†…å®¹ç‰¹å¾
    has_code = '```python' in content or '```' in content
    has_formula = '$$' in content or '$' in content or '\\[' in content
    has_image = '![' in content or '<img' in content
    
    # æå–å…³é”®è¯
    keywords = []
    keyword_map = {
        'PID': 'PIDæ§åˆ¶',
        'MPC': 'æ¨¡å‹é¢„æµ‹æ§åˆ¶',
        'è€ƒç ”': 'è€ƒç ”',
        'çœŸé¢˜': 'çœŸé¢˜',
        'æ°´ç®±': 'æ°´ç®±ç³»ç»Ÿ',
        'æ˜æ¸ ': 'æ˜æ¸ æµ',
        'ç®¡é“': 'ç®¡é“æµ',
        'æ°´åŠ›': 'æ°´åŠ›å­¦',
        'æ°´æ–‡': 'æ°´æ–‡å­¦'
    }
    
    for key, value in keyword_map.items():
        if key in content:
            keywords.append(value)
    
    return {
        'title': title,
        'content': content,
        'word_count': word_count,
        'has_code': has_code,
        'has_formula': has_formula,
        'has_image': has_image,
        'keywords': keywords[:5]
    }


def determine_chapter_number(file_path, index):
    """ç¡®å®šç« èŠ‚ç¼–å·"""
    filename = file_path.stem
    
    # åŒ¹é…ç« èŠ‚å·
    patterns = [
        r'ç¬¬(\d+)ç« ',
        r'ç¬¬(\d+)èŠ‚',
        r'chapter[_\s]?(\d+)',
        r'ch(\d+)',
        r'(\d+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, filename, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return str(index + 1)


def import_or_update_book(book_config, db, force_update=False):
    """å¯¼å…¥æˆ–æ›´æ–°å•æœ¬æ•™æ"""
    book_slug = book_config['slug']
    book_path = EXAM_PREP_DIR / book_slug
    
    if not book_path.exists():
        print(f"[SKIP] è·¯å¾„ä¸å­˜åœ¨: {book_path}")
        return None
    
    print(f"\n{'='*70}")
    print(f"[{book_config['id']}] {book_config['title']}")
    print(f"çŠ¶æ€: {book_config['status']} | ä¼˜å…ˆçº§: {book_config['priority']}")
    print(f"{'='*70}")
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    existing = db.query(Textbook).filter(Textbook.title == book_config['title']).first()
    
    if existing and not force_update:
        print(f"[EXISTS] å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼ˆä½¿ç”¨ --update å¼ºåˆ¶æ›´æ–°ï¼‰")
        return existing
    
    # æŸ¥æ‰¾ç« èŠ‚æ–‡ä»¶
    chapters_dir = book_path / "chapters"
    chapter_files = []
    
    if chapters_dir.exists():
        chapter_files = sorted(chapters_dir.glob("*.md"))
    
    if not chapter_files:
        print(f"[WARN] æœªæ‰¾åˆ°ç« èŠ‚æ–‡ä»¶")
        return None
    
    print(f"[INFO] æ‰¾åˆ° {len(chapter_files)} ä¸ªç« èŠ‚æ–‡ä»¶")
    
    # åˆ›å»ºæˆ–æ›´æ–°æ•™æè®°å½•
    if existing:
        textbook = existing
        print(f"[UPDATE] æ›´æ–°ç°æœ‰æ•™æ")
        # åˆ é™¤æ—§ç« èŠ‚
        db.query(TextbookChapter).filter(TextbookChapter.textbook_id == textbook.id).delete()
    else:
        textbook = Textbook(
            title=book_config['title'],
            subtitle=book_config.get('subtitle'),
            description=book_config['description'],
            target_audience=book_config['target_audience'],
            total_chapters=len(chapter_files),
            total_words=0,
            is_published=1 if book_config['status'] == 'completed' else 0
        )
        db.add(textbook)
        db.flush()
        print(f"[NEW] åˆ›å»ºæ–°æ•™æ")
    
    # å¯¼å…¥ç« èŠ‚
    total_words = 0
    
    for i, chapter_file in enumerate(chapter_files):
        content = parse_markdown_file(chapter_file)
        if not content:
            continue
        
        chapter_info = extract_chapter_info(content, chapter_file)
        chapter_number = determine_chapter_number(chapter_file, i)
        
        level = 1
        if '.' in chapter_number:
            level = chapter_number.count('.') + 1
        
        chapter = TextbookChapter(
            textbook_id=textbook.id,
            chapter_number=chapter_number,
            title=chapter_info['title'],
            level=level,
            order_num=i,
            content=chapter_info['content'],
            word_count=chapter_info['word_count'],
            has_code=1 if chapter_info['has_code'] else 0,
            has_formula=1 if chapter_info['has_formula'] else 0,
            has_image=1 if chapter_info['has_image'] else 0,
            keywords=chapter_info['keywords'],
            difficulty=DifficultyLevel.BEGINNER
        )
        
        db.add(chapter)
        total_words += chapter_info['word_count']
        
        print(f"  [{chapter_number}] {chapter_info['title'][:50]} ({chapter_info['word_count']} å­—)")
    
    # æ›´æ–°æ•™ææ€»å­—æ•°
    textbook.total_words = total_words
    textbook.total_chapters = len(chapter_files)
    textbook.updated_at = datetime.utcnow()
    
    db.commit()
    
    print(f"\n[OK] æˆåŠŸ: {len(chapter_files)} ç« ï¼Œå…± {total_words:,} å­—")
    return textbook


def import_all_books(force_update=False, status_filter=None):
    """æ‰¹é‡å¯¼å…¥æ‰€æœ‰è€ƒç ”æ•™æ"""
    print("\n" + "="*80)
    print("  ğŸ“š è€ƒç ”æ•™ææ‰¹é‡å¯¼å…¥")
    print("="*80)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    data_dir = Path(__file__).parent.parent / "data"
    data_dir.mkdir(exist_ok=True)
    db_path = data_dir / "textbooks.db"
    TEXTBOOK_DB_URL = f"sqlite:///{db_path}"
    engine = create_engine(TEXTBOOK_DB_URL, connect_args={"check_same_thread": False})
    Base.metadata.create_all(bind=engine)
    print(f"[OK] æ•°æ®åº“: {db_path}\n")
    
    db = SessionLocal()
    
    try:
        # è¿‡æ»¤è¦å¯¼å…¥çš„ä¹¦ç±
        books_to_import = EXAM_BOOKS
        if status_filter:
            books_to_import = [b for b in EXAM_BOOKS if b['status'] == status_filter]
            print(f"[FILTER] åªå¯¼å…¥çŠ¶æ€ä¸º '{status_filter}' çš„ä¹¦ç±\n")
        
        imported_count = 0
        updated_count = 0
        skipped_count = 0
        
        for book_config in books_to_import:
            result = import_or_update_book(book_config, db, force_update)
            
            if result:
                if force_update and db.query(Textbook).filter(
                    Textbook.title == book_config['title']
                ).count() > 0:
                    updated_count += 1
                else:
                    imported_count += 1
            else:
                skipped_count += 1
        
        # æœ€ç»ˆç»Ÿè®¡
        from sqlalchemy import func
        total_exam_books = db.query(Textbook).filter(
            Textbook.target_audience.like('%è€ƒç ”%')
        ).count()
        total_exam_chapters = db.query(TextbookChapter).join(Textbook).filter(
            Textbook.target_audience.like('%è€ƒç ”%')
        ).count()
        total_exam_words = db.query(func.sum(Textbook.total_words)).filter(
            Textbook.target_audience.like('%è€ƒç ”%')
        ).scalar() or 0
        
        print("\n" + "="*80)
        print(f"  å¯¼å…¥å®Œæˆ!")
        print("="*80)
        print(f"\nâœ… æ–°å¯¼å…¥: {imported_count} æœ¬")
        print(f"ğŸ”„ æ›´æ–°: {updated_count} æœ¬")
        print(f"â­ï¸  è·³è¿‡: {skipped_count} æœ¬")
        
        print(f"\nğŸ“Š è€ƒç ”æ•™æç»Ÿè®¡:")
        print(f"  æ•™ææ€»æ•°: {total_exam_books} æœ¬")
        print(f"  ç« èŠ‚æ€»æ•°: {total_exam_chapters} ä¸ª")
        print(f"  æ€»å­—æ•°: {total_exam_words:,} å­—")
        print()
        
    except Exception as e:
        print(f"\n[ERROR] å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
    finally:
        db.close()


def show_book_status():
    """æ˜¾ç¤ºæ‰€æœ‰è€ƒç ”ä¹¦ç±çš„çŠ¶æ€"""
    print("\n" + "="*80)
    print("  ğŸ“‹ 15æœ¬è€ƒç ”æ•™æå¼€å‘çŠ¶æ€")
    print("="*80 + "\n")
    
    status_emoji = {
        'completed': 'âœ…',
        'in_progress': 'ğŸš§',
        'planned': 'ğŸ“‹'
    }
    
    for book in EXAM_BOOKS:
        emoji = status_emoji.get(book['status'], 'â“')
        path = EXAM_PREP_DIR / book['slug']
        exists = path.exists()
        
        print(f"{book['id']:2d}. {emoji} {book['title']}")
        print(f"     çŠ¶æ€: {book['status']} | ä¼˜å…ˆçº§: {book['priority']}")
        print(f"     è·¯å¾„: {'âœ“ å­˜åœ¨' if exists else 'âœ— ä¸å­˜åœ¨'} - {path.name}")
        
        if exists:
            chapters_dir = path / "chapters"
            if chapters_dir.exists():
                chapter_count = len(list(chapters_dir.glob("*.md")))
                print(f"     ç« èŠ‚: {chapter_count} ä¸ª")
        print()


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='è€ƒç ”æ•™æå¯¼å…¥å·¥å…·')
    parser.add_argument('--update', action='store_true', help='å¼ºåˆ¶æ›´æ–°å·²å­˜åœ¨çš„æ•™æ')
    parser.add_argument('--status', choices=['completed', 'in_progress', 'planned'], 
                       help='åªå¯¼å…¥ç‰¹å®šçŠ¶æ€çš„æ•™æ')
    parser.add_argument('--list', action='store_true', help='æ˜¾ç¤ºæ‰€æœ‰æ•™æçŠ¶æ€')
    
    args = parser.parse_args()
    
    if args.list:
        show_book_status()
    else:
        import_all_books(force_update=args.update, status_filter=args.status)


if __name__ == "__main__":
    main()

