# 案例4.3：强化学习水库优化调度

## 工程背景

传统的水库优化调度依赖动态规划、遗传算法等方法，需要精确的数学模型和大量的计算。强化学习作为一种"边学边用"的方法，能够通过与环境交互自主学习最优策略，特别适合处理复杂、动态、不确定的调度问题。

## 案例目标

1. 理解强化学习的基本概念
2. 掌握Q-Learning算法原理
3. 学习水库调度环境建模
4. 能够训练和评估RL智能体

## 主要内容

### 1. 强化学习基础

**核心概念**：
- 状态（State）：水库库容、入流
- 动作（Action）：出流决策
- 奖励（Reward）：发电效益、违约惩罚
- 策略（Policy）：状态到动作的映射

**学习过程**：
```
Agent → Action → Environment
   ↑                  ↓
   ← Reward + State' ←
```

### 2. 水库调度问题

**状态空间**：
- 当前库容 V_t
- 当前入流 I_t
- 时段 t（季节信息）

**动作空间**：
- 出流 Q_t ∈ [Q_min, Q_max]
- 离散化为N个动作

**奖励函数**：
```
R = 发电效益 - 弃水惩罚 - 违约惩罚
```

### 3. 算法对比

| 方法 | 原理 | 优点 | 缺点 |
|------|------|------|------|
| DP | 全局最优 | 保证最优 | 维数灾难 |
| 贪心 | 局部最优 | 简单快速 | 次优解 |
| Q-Learning | 价值学习 | 无模型、灵活 | 收敛慢 |
| DQN | 深度Q网络 | 高维状态 | 需大量数据 |

## 技术路线

```
环境建模
  ├─ 水库模型
  ├─ 状态定义
  ├─ 动作空间
  └─ 奖励函数
         ↓
方法1：贪心策略
  ├─ 当前最优
  └─ 无学习
         ↓
方法2：Q-Learning
  ├─ Q表初始化
  ├─ ε-贪心探索
  ├─ Q值更新
  └─ 策略学习
         ↓
方法3：对比DP
  ├─ 离线优化
  └─ 性能基准
         ↓
性能评估
  ├─ 累积奖励
  ├─ 发电量
  ├─ 学习曲线
  └─ 策略分析
```

## 核心算法

### 1. Q-Learning算法

**Q值更新**：
```
Q(s,a) ← Q(s,a) + α[r + γ·max Q(s',a') - Q(s,a)]
```

**参数**：
- α：学习率（0.1）
- γ：折扣因子（0.95）
- ε：探索率（0.1，衰减）

### 2. ε-贪心策略

```python
if random() < ε:
    action = random_choice()  # 探索
else:
    action = argmax Q(s,a)    # 利用
```

### 3. 水库水量平衡

```
V_{t+1} = V_t + (I_t - Q_t) * Δt
```

### 4. 发电功率

```
P = 9.81 * Q * H * η / 1000  (MW)
```

## 运行方法

```bash
cd code/examples/case12_rl_scheduling
python main.py
```

## 预期结果

**贪心策略**：
- 累积奖励：基准
- 发电量：次优
- 无学习能力

**Q-Learning**：
- 累积奖励：优于贪心10-15%
- 发电量：接近DP
- 学习收敛：1000-2000轮

**动态规划**：
- 累积奖励：最优
- 发电量：最大
- 计算时间：较长

## 思考题

1. 强化学习相比传统方法的优势是什么？
2. Q-Learning如何平衡探索与利用？
3. 状态和动作空间如何离散化？
4. 奖励函数如何设计？
5. 如何处理连续动作空间？

## 扩展方向

1. **深度强化学习**：DQN、A3C、PPO
2. **多智能体**：梯级水库协同
3. **迁移学习**：跨流域应用
4. **安全强化学习**：约束满足
5. **元学习**：快速适应

## 参考文献

1. Sutton RS, Barto AG. Reinforcement Learning: An Introduction[M]. MIT Press, 2018.
2. Mnih V, et al. Human-level Control through Deep Reinforcement Learning[J]. Nature, 2015, 518: 529-533.
3. Wei W, et al. Deep Reinforcement Learning for Optimal Operation of Hydropower Reservoir[J]. Water Resources Management, 2020.

## 作者信息

- 案例编号：Case 4.3
- 难度等级：⭐⭐⭐⭐⭐ (高级)
- 所需时间：8-10小时
- 更新日期：2025-11-02
