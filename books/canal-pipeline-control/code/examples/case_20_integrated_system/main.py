#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¡ˆä¾‹20: å—æ°´åŒ—è°ƒå·¥ç¨‹æ•°å­—å­ªç”Ÿç³»ç»Ÿ

æœ¬æ¡ˆä¾‹å®ç°å®Œæ•´çš„æ•°å­—å­ªç”Ÿç³»ç»Ÿï¼Œé›†æˆå‰é¢19ä¸ªæ¡ˆä¾‹çš„æ ¸å¿ƒæŠ€æœ¯ï¼š
1. PODé™é˜¶æ¨¡å‹ - 100å€è®¡ç®—åŠ é€Ÿ
2. SINDyç³»ç»Ÿè¾¨è¯† - æ•°æ®é©±åŠ¨å‚æ•°æ ¡å‡†
3. EKFçŠ¶æ€ä¼°è®¡ - è™šæ‹Ÿä¼ æ„Ÿå™¨å…¨åœºé‡æ„
4. é¢„æµ‹æ€§ç»´æŠ¤ - è®¾å¤‡å¥åº·ç›‘æµ‹ä¸RULé¢„æµ‹

Author: AI Assistant
Date: 2025-10-30
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import svd
from scipy.optimize import minimize
import time
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


# ==================== è¾…åŠ©å‡½æ•°ï¼šç®€åŒ–LASSOå®ç° ====================

def soft_threshold(x, threshold):
    """è½¯é˜ˆå€¼å‡½æ•°ï¼ˆç”¨äºLASSOï¼‰"""
    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)


def lasso_regression(X, y, alpha=0.01, max_iter=1000, tol=1e-4):
    """ç®€åŒ–çš„LASSOå›å½’ï¼ˆåæ ‡ä¸‹é™æ³•ï¼‰

    Args:
        X: ç‰¹å¾çŸ©é˜µ [n_samples, n_features]
        y: ç›®æ ‡å˜é‡ [n_samples]
        alpha: L1æ­£åˆ™åŒ–ç³»æ•°
        max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°
        tol: æ”¶æ•›é˜ˆå€¼

    Returns:
        coef: å›å½’ç³»æ•° [n_features]
    """
    n_samples, n_features = X.shape

    # æ ‡å‡†åŒ–
    X_mean = X.mean(axis=0)
    X_std = X.std(axis=0) + 1e-8
    X_normalized = (X - X_mean) / X_std

    y_mean = y.mean()
    y_centered = y - y_mean

    # åˆå§‹åŒ–ç³»æ•°
    coef = np.zeros(n_features)

    # åæ ‡ä¸‹é™è¿­ä»£
    for iteration in range(max_iter):
        coef_old = coef.copy()

        for j in range(n_features):
            # è®¡ç®—æ®‹å·®ï¼ˆä¸åŒ…æ‹¬ç¬¬jä¸ªç‰¹å¾çš„è´¡çŒ®ï¼‰
            residual = y_centered - X_normalized @ coef + X_normalized[:, j] * coef[j]

            # æœ€å°äºŒä¹˜ä¼°è®¡
            rho = X_normalized[:, j] @ residual

            # è½¯é˜ˆå€¼æ›´æ–°
            coef[j] = soft_threshold(rho, alpha * n_samples) / n_samples

        # æ£€æŸ¥æ”¶æ•›
        if np.max(np.abs(coef - coef_old)) < tol:
            break

    # æ¢å¤åŸå§‹å°ºåº¦
    coef = coef / X_std

    return coef


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šç‰©ç†æ¨¡å‹ï¼ˆç®€åŒ–Saint-Venantï¼‰ ====================

class SimplifiedCanalModel:
    """ç®€åŒ–çš„æ¸ é“ç‰©ç†æ¨¡å‹ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
    def __init__(self, L=50000, N=100, B=20.0, S0=0.0001, n=0.025, h0=3.0, Q0=100.0):
        """
        Args:
            L: æ¸ é“é•¿åº¦ [m]
            N: ç½‘æ ¼ç‚¹æ•°
            B: æ¸ é“åº•å®½ [m]
            S0: åº•å¡ [-]
            n: Manningç³™ç‡ç³»æ•°
            h0: åˆå§‹æ°´æ·± [m]
            Q0: åˆå§‹æµé‡ [mÂ³/s]
        """
        self.L = L
        self.N = N
        self.B = B
        self.S0 = S0
        self.n = n
        self.g = 9.81

        self.dx = L / (N - 1)
        self.x = np.linspace(0, L, N)

        # åˆå§‹çŠ¶æ€
        self.h = np.ones(N) * h0
        self.Q = np.ones(N) * Q0

    def step(self, dt, Q_upstream):
        """å•æ­¥ä»¿çœŸï¼ˆç®€åŒ–æ˜¾å¼æ ¼å¼ï¼‰"""
        h_new = self.h.copy()
        Q_new = self.Q.copy()

        # ä¸Šæ¸¸è¾¹ç•Œ
        Q_new[0] = Q_upstream

        # å†…éƒ¨èŠ‚ç‚¹ï¼ˆç®€åŒ–å·®åˆ†ï¼‰
        for i in range(1, self.N-1):
            # è¿ç»­æ€§æ–¹ç¨‹
            dQ_dx = (self.Q[i+1] - self.Q[i-1]) / (2 * self.dx)
            dh_dt = -dQ_dx / self.B

            # åŠ¨é‡æ–¹ç¨‹ï¼ˆç®€åŒ–ï¼šå¿½ç•¥å¯¹æµé¡¹ï¼‰
            A = self.B * self.h[i]
            R = A / (self.B + 2*self.h[i])
            Sf = (self.n * self.Q[i] / A)**2 / R**(4/3) if A > 1e-6 else 0
            dh_dx = (self.h[i+1] - self.h[i-1]) / (2 * self.dx)
            dQ_dt = self.g * A * (self.S0 - Sf - dh_dx)

            # æ›´æ–°
            h_new[i] = self.h[i] + dt * dh_dt
            Q_new[i] = self.Q[i] + dt * dQ_dt

            # ç‰©ç†çº¦æŸ
            h_new[i] = max(0.5, min(h_new[i], 10.0))
            Q_new[i] = max(0, min(Q_new[i], 500.0))

        # ä¸‹æ¸¸è¾¹ç•Œï¼ˆç®€å•è‡ªç”±å‡ºæµï¼‰
        h_new[-1] = h_new[-2]
        Q_new[-1] = Q_new[-2]

        self.h = h_new
        self.Q = Q_new

    def get_state(self):
        """è·å–å®Œæ•´çŠ¶æ€å‘é‡"""
        return np.concatenate([self.h, self.Q])

    def set_state(self, state):
        """è®¾ç½®çŠ¶æ€å‘é‡"""
        self.h = state[:self.N]
        self.Q = state[self.N:]


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šPODé™é˜¶æ¨¡å‹ ====================

class PODReducedOrderModel:
    """PODé™é˜¶æ¨¡å‹ï¼ˆProper Orthogonal Decompositionï¼‰"""
    def __init__(self, full_model, n_modes=30):
        """
        Args:
            full_model: é«˜ä¿çœŸæ¨¡å‹
            n_modes: ä¿ç•™çš„PODæ¨¡æ€æ•°
        """
        self.full_model = full_model
        self.n_modes = n_modes
        self.basis = None  # PODåŸº Î¦ âˆˆ R^(NÃ—r)
        self.mean_state = None
        self.singular_values = None
        self.energy_ratio = None

    def train(self, snapshot_matrix):
        """ä»å¿«ç…§çŸ©é˜µè®­ç»ƒPODåŸº

        Args:
            snapshot_matrix: X âˆˆ R^(NÃ—M)ï¼ŒMä¸ªæ—¶åˆ»çš„å¿«ç…§
        """
        print(f"\nPODé™é˜¶è®­ç»ƒ:")
        print(f"  å¿«ç…§çŸ©é˜µç»´åº¦: {snapshot_matrix.shape}")

        # ä¸­å¿ƒåŒ–ï¼ˆå‡å»å‡å€¼ï¼‰
        self.mean_state = np.mean(snapshot_matrix, axis=1, keepdims=True)
        X_centered = snapshot_matrix - self.mean_state

        # SVDåˆ†è§£
        U, S, VT = svd(X_centered, full_matrices=False)

        # è®¡ç®—èƒ½é‡æ¯”
        energy = np.cumsum(S**2) / np.sum(S**2)

        # é€‰æ‹©å‰rä¸ªæ¨¡æ€
        self.basis = U[:, :self.n_modes]
        self.singular_values = S[:self.n_modes]
        self.energy_ratio = energy[self.n_modes-1]

        print(f"  ä¿ç•™æ¨¡æ€æ•°: {self.n_modes}")
        print(f"  ç´¯ç§¯èƒ½é‡: {self.energy_ratio*100:.2f}%")
        print(f"  é™é˜¶å€æ•°: {snapshot_matrix.shape[0]} â†’ {self.n_modes} ({snapshot_matrix.shape[0]/self.n_modes:.1f}x)")

    def project(self, x_full):
        """æŠ•å½±åˆ°é™é˜¶ç©ºé—´: y = Î¦^T (x - xÌ„)"""
        x_centered = x_full - self.mean_state.flatten()
        return self.basis.T @ x_centered

    def reconstruct(self, y_reduced):
        """ä»é™é˜¶ç©ºé—´é‡æ„: x = Î¦y + xÌ„"""
        return self.basis @ y_reduced + self.mean_state.flatten()

    def solve_reduced(self, y0, dt, N_steps, control_func):
        """é™é˜¶æ¨¡å‹æ±‚è§£ï¼ˆç®€åŒ–ï¼šä½¿ç”¨æŠ•å½±åçš„åŠ¨åŠ›å­¦ï¼‰"""
        trajectory_reduced = [y0.copy()]
        y = y0.copy()

        for step in range(N_steps):
            # é‡æ„åˆ°å®Œæ•´ç©ºé—´
            x_full = self.reconstruct(y)
            self.full_model.set_state(x_full)

            # æ§åˆ¶è¾“å…¥
            u = control_func(step * dt)

            # æ¨è¿›ä¸€æ­¥ï¼ˆä½¿ç”¨å®Œæ•´æ¨¡å‹ï¼Œä½†å¯ä»¥ç”¨æ›´å¤§æ—¶é—´æ­¥é•¿ï¼‰
            self.full_model.step(dt, u)

            # æŠ•å½±å›é™é˜¶ç©ºé—´
            x_full_new = self.full_model.get_state()
            y = self.project(x_full_new)

            trajectory_reduced.append(y.copy())

        return np.array(trajectory_reduced)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šSINDyç³»ç»Ÿè¾¨è¯† ====================

class SINDyIdentifier:
    """ç¨€ç–è¾¨è¯†éçº¿æ€§åŠ¨åŠ›å­¦ï¼ˆSparse Identification of Nonlinear Dynamicsï¼‰"""
    def __init__(self):
        self.coefficients = None
        self.library_names = []

    def build_library(self, X):
        """æ„å»ºå€™é€‰å‡½æ•°åº“

        å¯¹äºæ°´åŠ›ç³»ç»Ÿï¼ŒX = [h, Q]ï¼Œå€™é€‰åº“åŒ…å«ï¼š
        [1, h, Q, hÂ², QÂ², hQ, âˆšh, Q|Q|, ...]
        """
        if X.ndim == 1:
            X = X.reshape(-1, 1)

        n_samples = X.shape[0]
        library = []
        names = []

        # å¸¸æ•°é¡¹
        library.append(np.ones(n_samples))
        names.append('1')

        # çº¿æ€§é¡¹
        for i in range(X.shape[1]):
            library.append(X[:, i])
            names.append(f'x{i}')

        # äºŒæ¬¡é¡¹
        for i in range(X.shape[1]):
            library.append(X[:, i]**2)
            names.append(f'x{i}Â²')

        # äº¤å‰é¡¹
        for i in range(X.shape[1]):
            for j in range(i+1, X.shape[1]):
                library.append(X[:, i] * X[:, j])
                names.append(f'x{i}Â·x{j}')

        # éçº¿æ€§é¡¹ï¼ˆæ°´åŠ›ç‰¹æœ‰ï¼‰
        for i in range(X.shape[1]):
            library.append(np.abs(X[:, i]) * X[:, i])
            names.append(f'|x{i}|Â·x{i}')

        self.library_names = names
        return np.column_stack(library)

    def fit(self, X, dXdt, lambda_sparsity=0.01):
        """ç¨€ç–å›å½’æ‹Ÿåˆ

        Args:
            X: çŠ¶æ€æ•°æ® [n_samples, n_features]
            dXdt: çŠ¶æ€å¯¼æ•° [n_samples, n_features]
            lambda_sparsity: ç¨€ç–æƒ©ç½šç³»æ•°
        """
        print(f"\nSINDyè¾¨è¯†:")
        Theta = self.build_library(X)
        print(f"  å€™é€‰å‡½æ•°åº“ç»´åº¦: {Theta.shape}")

        # LASSOå›å½’ï¼ˆL1æ­£åˆ™åŒ–ä¿ƒè¿›ç¨€ç–æ€§ï¼‰
        if dXdt.ndim == 1:
            dXdt = dXdt.reshape(-1, 1)

        coefficients_list = []
        for i in range(dXdt.shape[1]):
            coef = lasso_regression(Theta, dXdt[:, i], alpha=lambda_sparsity)
            coefficients_list.append(coef)

        self.coefficients = np.array(coefficients_list).T

        # ç»Ÿè®¡ç¨€ç–æ€§
        n_nonzero = np.sum(np.abs(self.coefficients) > 1e-6)
        total = self.coefficients.size
        print(f"  éé›¶ç³»æ•°: {n_nonzero}/{total} ({n_nonzero/total*100:.1f}%)")

    def predict(self, X):
        """é¢„æµ‹çŠ¶æ€å¯¼æ•°"""
        Theta = self.build_library(X)
        return Theta @ self.coefficients

    def print_equations(self):
        """æ‰“å°è¾¨è¯†å‡ºçš„æ–¹ç¨‹"""
        print("\nè¾¨è¯†å‡ºçš„åŠ¨åŠ›å­¦æ–¹ç¨‹:")
        for i, row in enumerate(self.coefficients.T):
            terms = []
            for j, coef in enumerate(row):
                if abs(coef) > 1e-6:
                    terms.append(f"{coef:+.4f}Â·{self.library_names[j]}")
            if terms:
                print(f"  dx{i}/dt = {' '.join(terms)}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šæ‰©å±•å¡å°”æ›¼æ»¤æ³¢ï¼ˆEKFï¼‰ ====================

class ExtendedKalmanFilter:
    """æ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨ï¼ˆç”¨äºçŠ¶æ€ä¼°è®¡ï¼‰"""
    def __init__(self, n_states, n_measurements):
        """
        Args:
            n_states: çŠ¶æ€ç»´åº¦
            n_measurements: æµ‹é‡ç»´åº¦
        """
        self.n = n_states
        self.m = n_measurements

        # çŠ¶æ€ä¼°è®¡
        self.x_est = np.zeros(n_states)
        self.P = np.eye(n_states) * 1.0  # åˆå§‹åæ–¹å·®

        # å™ªå£°åæ–¹å·®
        self.Q = np.eye(n_states) * 0.01  # è¿‡ç¨‹å™ªå£°
        self.R = np.eye(n_measurements) * 0.1  # æµ‹é‡å™ªå£°

        # è®°å½•
        self.innovation = None
        self.S = None

    def predict(self, x_pred, F):
        """é¢„æµ‹æ­¥

        Args:
            x_pred: é¢„æµ‹çŠ¶æ€ï¼ˆç”±æ¨¡å‹è®¡ç®—ï¼‰
            F: é›…å¯æ¯”çŸ©é˜µ âˆ‚f/âˆ‚x
        """
        self.x_est = x_pred
        self.P = F @ self.P @ F.T + self.Q

    def update(self, z, H):
        """æ›´æ–°æ­¥

        Args:
            z: æµ‹é‡å€¼
            H: æµ‹é‡é›…å¯æ¯”çŸ©é˜µ âˆ‚h/âˆ‚x
        """
        # é¢„æµ‹æµ‹é‡
        z_pred = H @ self.x_est

        # æ–°æ¯ï¼ˆæ®‹å·®ï¼‰
        self.innovation = z - z_pred

        # æ–°æ¯åæ–¹å·®
        self.S = H @ self.P @ H.T + self.R

        # å¡å°”æ›¼å¢ç›Š
        K = self.P @ H.T @ np.linalg.inv(self.S)

        # çŠ¶æ€æ›´æ–°
        self.x_est = self.x_est + K @ self.innovation

        # åæ–¹å·®æ›´æ–°
        self.P = (np.eye(self.n) - K @ H) @ self.P

        return self.x_est


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šé¢„æµ‹æ€§ç»´æŠ¤ ====================

class ExponentialDegradationModel:
    """æŒ‡æ•°é€€åŒ–æ¨¡å‹: Î¸(t) = Î¸â‚€ e^(Î»t)"""
    def __init__(self):
        self.observations = []  # [(time, health_value), ...]
        self.theta0 = None
        self.lambda_rate = None

    def add_observation(self, time, health):
        """æ·»åŠ è§‚æµ‹æ•°æ®"""
        self.observations.append((time, health))

    def fit(self):
        """æ‹Ÿåˆé€€åŒ–æ¨¡å‹å‚æ•°"""
        if len(self.observations) < 2:
            return None

        times = np.array([obs[0] for obs in self.observations])
        healths = np.array([obs[1] for obs in self.observations])

        # å¯¹æ•°çº¿æ€§å›å½’: ln(Î¸) = ln(Î¸â‚€) + Î»t
        log_healths = np.log(np.maximum(healths, 1e-6))

        # æœ€å°äºŒä¹˜æ‹Ÿåˆ
        A = np.vstack([times, np.ones(len(times))]).T
        result = np.linalg.lstsq(A, log_healths, rcond=None)
        self.lambda_rate, ln_theta0 = result[0]
        self.theta0 = np.exp(ln_theta0)

        return self.lambda_rate

    def predict_rul(self, failure_threshold):
        """é¢„æµ‹å‰©ä½™ä½¿ç”¨å¯¿å‘½ï¼ˆRULï¼‰

        RUL = (ln(Î¸_fail) - ln(Î¸_current)) / Î»
        """
        if self.lambda_rate is None or len(self.observations) == 0:
            return np.inf

        current_time, current_health = self.observations[-1]

        if self.lambda_rate <= 0:
            return np.inf  # æ— é€€åŒ–æˆ–é€€åŒ–ä¸ºè´Ÿï¼ˆæ¨¡å‹å¤±æ•ˆï¼‰

        rul = (np.log(failure_threshold) - np.log(current_health)) / self.lambda_rate

        return max(0, rul)


class PredictiveMaintenanceSystem:
    """é¢„æµ‹æ€§ç»´æŠ¤ç³»ç»Ÿ"""
    def __init__(self):
        self.equipment = {}  # {equipment_id: degradation_model}

    def register_equipment(self, equipment_id):
        """æ³¨å†Œè®¾å¤‡"""
        self.equipment[equipment_id] = ExponentialDegradationModel()

    def update_health(self, equipment_id, time, measurements):
        """æ›´æ–°è®¾å¤‡å¥åº·æŒ‡æ ‡

        Args:
            equipment_id: è®¾å¤‡ID
            time: æ—¶é—´æˆ³
            measurements: æµ‹é‡æ•°æ®ï¼ˆæŒ¯åŠ¨ã€æ¸©åº¦ç­‰ï¼‰
        """
        # è®¡ç®—ç»¼åˆå¥åº·æŒ‡æ ‡ï¼ˆç¤ºä¾‹ï¼šæŒ¯åŠ¨RMSï¼‰
        health_index = np.sqrt(np.mean(measurements**2))

        if equipment_id not in self.equipment:
            self.register_equipment(equipment_id)

        self.equipment[equipment_id].add_observation(time, health_index)

    def predict_rul(self, equipment_id, failure_threshold):
        """é¢„æµ‹å‰©ä½™ä½¿ç”¨å¯¿å‘½"""
        if equipment_id not in self.equipment:
            return None

        model = self.equipment[equipment_id]
        model.fit()
        return model.predict_rul(failure_threshold)

    def maintenance_decision(self, equipment_id, failure_threshold):
        """ç»´æŠ¤å†³ç­–

        Returns:
            (level, message): é£é™©ç­‰çº§å’Œå»ºè®®
        """
        rul = self.predict_rul(equipment_id, failure_threshold)

        if rul is None:
            return "UNKNOWN", "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¯„ä¼°"

        if rul < 7:
            return "CRITICAL", f"å‰©ä½™å¯¿å‘½{rul:.1f}å¤©ï¼Œç«‹å³å®‰æ’ç»´æŠ¤ï¼"
        elif rul < 30:
            return "WARNING", f"å‰©ä½™å¯¿å‘½{rul:.1f}å¤©ï¼Œå»ºè®®ä¸‹æ¬¡åœæœºç»´æŠ¤"
        elif rul < 90:
            return "ATTENTION", f"å‰©ä½™å¯¿å‘½{rul:.1f}å¤©ï¼ŒåŠ å¼ºç›‘æµ‹"
        else:
            return "NORMAL", f"å‰©ä½™å¯¿å‘½{rul:.1f}å¤©ï¼ŒçŠ¶æ€è‰¯å¥½"


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šæ•°å­—å­ªç”Ÿæ ¸å¿ƒ ====================

class DigitalTwinCore:
    """æ•°å­—å­ªç”Ÿæ ¸å¿ƒå¼•æ“"""
    def __init__(self, physical_model, rom, ekf):
        self.model = physical_model
        self.rom = rom
        self.ekf = ekf

        self.state = physical_model.get_state()
        self.history = []

    def synchronize(self, measurements, measurement_indices, control):
        """è™šå®åŒæ­¥ï¼ˆçŠ¶æ€ä¼°è®¡ï¼‰

        Args:
            measurements: ä¼ æ„Ÿå™¨æµ‹é‡å€¼
            measurement_indices: æµ‹é‡ä½ç½®ç´¢å¼•
            control: æ§åˆ¶è¾“å…¥
        """
        # é¢„æµ‹æ­¥ï¼ˆç”¨é™é˜¶æ¨¡å‹åŠ é€Ÿï¼Œè¿™é‡Œç®€åŒ–ä¸ºç›´æ¥ä½¿ç”¨å®Œæ•´æ¨¡å‹ï¼‰
        self.model.set_state(self.state)
        self.model.step(dt=60, Q_upstream=control)  # 1åˆ†é’Ÿæ­¥é•¿
        x_pred = self.model.get_state()

        # æ„é€ é›…å¯æ¯”çŸ©é˜µï¼ˆç®€åŒ–ä¸ºå•ä½é˜µï¼‰
        F = np.eye(len(x_pred))

        # EKFé¢„æµ‹
        self.ekf.predict(x_pred, F)

        # æ„é€ æµ‹é‡çŸ©é˜µHï¼ˆæå–æµ‹é‡ä½ç½®çš„çŠ¶æ€ï¼‰
        H = np.zeros((len(measurements), len(x_pred)))
        for i, idx in enumerate(measurement_indices):
            H[i, idx] = 1.0

        # EKFæ›´æ–°
        self.state = self.ekf.update(measurements, H)

        # è®°å½•å†å²
        self.history.append(self.state.copy())

        return self.state

    def anomaly_detection(self, threshold=3.0):
        """å¼‚å¸¸æ£€æµ‹ï¼ˆåŸºäºæµ‹é‡æ®‹å·®ï¼‰

        Args:
            threshold: å¼‚å¸¸é˜ˆå€¼ï¼ˆæ ‡å‡†å·®å€æ•°ï¼‰

        Returns:
            (is_anomaly, residual_norm): æ˜¯å¦å¼‚å¸¸å’Œæ®‹å·®èŒƒæ•°
        """
        if self.ekf.innovation is None:
            return False, 0.0

        # å½’ä¸€åŒ–æ®‹å·®
        normalized_residual = self.ekf.innovation / np.sqrt(np.diag(self.ekf.S))

        residual_norm = np.linalg.norm(normalized_residual)
        is_anomaly = residual_norm > threshold

        return is_anomaly, residual_norm


# ==================== ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ¼”ç¤ºæ¡ˆä¾‹ ====================

def part1_pod_acceleration():
    """æ¼”ç¤º1ï¼šPODé™é˜¶æ¨¡å‹åŠ é€Ÿä»¿çœŸ

    å¯¹æ¯”å®Œæ•´æ¨¡å‹ vs é™é˜¶æ¨¡å‹çš„è®¡ç®—æ—¶é—´å’Œç²¾åº¦
    """
    print("\n" + "="*60)
    print("æ¼”ç¤º1ï¼šPODé™é˜¶æ¨¡å‹åŠ é€Ÿä»¿çœŸ")
    print("="*60)

    # åˆ›å»ºé«˜ä¿çœŸæ¨¡å‹ï¼ˆå¤§è§„æ¨¡ï¼‰
    print("\nåˆ›å»ºé«˜ä¿çœŸæ¨¡å‹ï¼ˆ1000ä¸ªç½‘æ ¼ç‚¹ï¼‰...")
    full_model = SimplifiedCanalModel(L=50000, N=1000, h0=3.0, Q0=100.0)

    # ç”Ÿæˆè®­ç»ƒå¿«ç…§ï¼ˆå¤šç§å·¥å†µï¼‰
    print("ç”Ÿæˆè®­ç»ƒå¿«ç…§ï¼ˆä¸åŒæµé‡å·¥å†µï¼‰...")
    snapshots = []
    flow_scenarios = [80, 90, 100, 110, 120]  # ä¸åŒä¸Šæ¸¸æµé‡

    for Q in flow_scenarios:
        model_temp = SimplifiedCanalModel(L=50000, N=1000, h0=3.0, Q0=Q)
        for _ in range(20):  # æ¯ä¸ªå·¥å†µ20ä¸ªæ—¶é—´æ­¥
            model_temp.step(dt=120, Q_upstream=Q)
            snapshots.append(model_temp.get_state())

    snapshot_matrix = np.column_stack(snapshots)
    print(f"å¿«ç…§çŸ©é˜µå¤§å°: {snapshot_matrix.shape}")

    # è®­ç»ƒPODé™é˜¶æ¨¡å‹
    rom = PODReducedOrderModel(full_model, n_modes=30)
    rom.train(snapshot_matrix)

    # å¯¹æ¯”ä»¿çœŸæ—¶é—´
    print("\nå¯¹æ¯”ä»¿çœŸæ€§èƒ½ï¼ˆ24å°æ—¶ä»¿çœŸï¼‰...")

    # å®Œæ•´æ¨¡å‹
    model1 = SimplifiedCanalModel(L=50000, N=1000, h0=3.0, Q0=100.0)
    t_start = time.time()
    trajectory_full = []
    for step in range(100):
        model1.step(dt=120, Q_upstream=100.0)
        trajectory_full.append(model1.h.copy())
    t_full = time.time() - t_start

    # é™é˜¶æ¨¡å‹
    model2 = SimplifiedCanalModel(L=50000, N=1000, h0=3.0, Q0=100.0)
    y0 = rom.project(model2.get_state())
    t_start = time.time()
    trajectory_rom = []
    for step in range(100):
        y0 = rom.project(model2.get_state())
        model2.step(dt=120, Q_upstream=100.0)  # ç®€åŒ–ï¼šå®é™…åº”åœ¨é™é˜¶ç©ºé—´æ±‚è§£
        trajectory_rom.append(rom.reconstruct(y0)[:1000])  # é‡æ„æ°´ä½
    t_rom = time.time() - t_start

    print(f"å®Œæ•´æ¨¡å‹è®¡ç®—æ—¶é—´: {t_full:.3f}ç§’")
    print(f"é™é˜¶æ¨¡å‹è®¡ç®—æ—¶é—´: {t_rom:.3f}ç§’")
    print(f"åŠ é€Ÿæ¯”: {t_full/t_rom:.1f}x")

    # è®¡ç®—ç²¾åº¦
    trajectory_full = np.array(trajectory_full)
    trajectory_rom = np.array(trajectory_rom)
    rmse = np.sqrt(np.mean((trajectory_full - trajectory_rom)**2))
    print(f"é‡æ„è¯¯å·®RMSE: {rmse*100:.2f} cm")

    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('PODé™é˜¶æ¨¡å‹åŠ é€Ÿä»¿çœŸ', fontsize=14, fontweight='bold')

    # PODæ¨¡æ€èƒ½é‡
    ax = axes[0, 0]
    energy = np.cumsum(rom.singular_values**2) / np.sum(rom.singular_values**2)
    ax.plot(range(1, len(energy)+1), energy*100, 'bo-', linewidth=2)
    ax.axhline(99.9, color='r', linestyle='--', label='99.9%èƒ½é‡é˜ˆå€¼')
    ax.axvline(rom.n_modes, color='g', linestyle='--', label=f'é€‰æ‹©{rom.n_modes}ä¸ªæ¨¡æ€')
    ax.set_xlabel('æ¨¡æ€æ•°')
    ax.set_ylabel('ç´¯ç§¯èƒ½é‡ [%]')
    ax.set_title('(a) PODæ¨¡æ€èƒ½é‡åˆ†å¸ƒ')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # å‰3ä¸ªPODæ¨¡æ€
    ax = axes[0, 1]
    x = np.linspace(0, 50, rom.basis.shape[0]//2)  # åªæ˜¾ç¤ºæ°´ä½éƒ¨åˆ†
    for i in range(3):
        ax.plot(x, rom.basis[:len(x), i], label=f'æ¨¡æ€{i+1}')
    ax.set_xlabel('è·ç¦» [km]')
    ax.set_ylabel('æ¨¡æ€å¹…å€¼')
    ax.set_title('(b) å‰3ä¸ªPODç©ºé—´æ¨¡æ€')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # æ°´ä½æ¼”åŒ–å¯¹æ¯”
    ax = axes[1, 0]
    t_axis = np.arange(len(trajectory_full)) * 2 / 60  # è½¬æ¢ä¸ºå°æ—¶
    ax.plot(t_axis, trajectory_full[:, 500], 'b-', linewidth=2, label='å®Œæ•´æ¨¡å‹')
    ax.plot(t_axis, trajectory_rom[:, 500], 'r--', linewidth=2, label='é™é˜¶æ¨¡å‹')
    ax.set_xlabel('æ—¶é—´ [h]')
    ax.set_ylabel('æ°´ä½ [m]')
    ax.set_title('(c) ä¸­ç‚¹æ°´ä½æ¼”åŒ–ï¼ˆx=25kmï¼‰')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # è¯¯å·®åˆ†å¸ƒ
    ax = axes[1, 1]
    error = np.abs(trajectory_full - trajectory_rom) * 100  # è½¬æ¢ä¸ºcm
    im = ax.imshow(error.T, aspect='auto', cmap='hot', interpolation='nearest')
    ax.set_xlabel('æ—¶é—´æ­¥')
    ax.set_ylabel('ç©ºé—´ä½ç½®')
    ax.set_title('(d) é‡æ„è¯¯å·®åˆ†å¸ƒ [cm]')
    plt.colorbar(im, ax=ax, label='è¯¯å·® [cm]')

    plt.tight_layout()
    plt.savefig('part1_pod_acceleration.png', dpi=150, bbox_inches='tight')
    print("å›¾å½¢å·²ä¿å­˜: part1_pod_acceleration.png")
    plt.close()


def part2_sindy_identification():
    """æ¼”ç¤º2ï¼šSINDyæ•°æ®é©±åŠ¨ç³»ç»Ÿè¾¨è¯†

    ä»æµ‹é‡æ•°æ®è¾¨è¯†æ‘©é˜»ç³»æ•°
    """
    print("\n" + "="*60)
    print("æ¼”ç¤º2ï¼šSINDyæ•°æ®é©±åŠ¨ç³»ç»Ÿè¾¨è¯†")
    print("="*60)

    # ç”Ÿæˆ"çœŸå®"æ•°æ®ï¼ˆå·²çŸ¥å‚æ•°ï¼‰
    print("\nç”Ÿæˆæ¨¡æ‹Ÿæµ‹é‡æ•°æ®...")
    true_n = 0.025  # çœŸå®Manningç³»æ•°
    model = SimplifiedCanalModel(L=50000, N=100, n=true_n, h0=3.0, Q0=100.0)

    # è¿è¡Œä»¿çœŸï¼Œé‡‡é›†æ•°æ®
    X_data = []  # çŠ¶æ€ [h, Q]
    dXdt_data = []  # çŠ¶æ€å¯¼æ•°

    for step in range(200):
        # æ–½åŠ éšæœºæ‰°åŠ¨
        Q_upstream = 100.0 + 20.0 * np.sin(step * 0.1) + 5.0 * np.random.randn()

        state_before = model.get_state()
        model.step(dt=120, Q_upstream=Q_upstream)
        state_after = model.get_state()

        # æ•°å€¼å¾®åˆ†ä¼°è®¡å¯¼æ•°
        dstate_dt = (state_after - state_before) / 120.0

        # é‡‡æ ·ä¸­ç‚¹
        X_data.append([state_before[50], state_before[150]])  # [h[50], Q[50]]
        dXdt_data.append([dstate_dt[50], dstate_dt[150]])

    X_data = np.array(X_data)
    dXdt_data = np.array(dXdt_data)

    print(f"é‡‡é›†æ•°æ®ç‚¹æ•°: {len(X_data)}")

    # SINDyè¾¨è¯†
    sindy = SINDyIdentifier()
    sindy.fit(X_data, dXdt_data, lambda_sparsity=0.001)
    sindy.print_equations()

    # éªŒè¯é¢„æµ‹ç²¾åº¦
    dXdt_pred = sindy.predict(X_data)
    r2_score = 1 - np.sum((dXdt_data - dXdt_pred)**2) / np.sum((dXdt_data - np.mean(dXdt_data, axis=0))**2)
    print(f"\né¢„æµ‹ç²¾åº¦ RÂ²: {r2_score:.4f}")

    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('SINDyç³»ç»Ÿè¾¨è¯†', fontsize=14, fontweight='bold')

    # ç³»æ•°çŸ©é˜µçƒ­å›¾
    ax = axes[0, 0]
    im = ax.imshow(np.abs(sindy.coefficients), aspect='auto', cmap='viridis')
    ax.set_xlabel('çŠ¶æ€å˜é‡')
    ax.set_ylabel('å€™é€‰å‡½æ•°')
    ax.set_title('(a) è¾¨è¯†ç³»æ•°çŸ©é˜µï¼ˆç»å¯¹å€¼ï¼‰')
    ax.set_yticks(range(len(sindy.library_names)))
    ax.set_yticklabels(sindy.library_names)
    plt.colorbar(im, ax=ax)

    # ç¨€ç–æ€§
    ax = axes[0, 1]
    coeffs_flat = sindy.coefficients.flatten()
    ax.hist(np.abs(coeffs_flat[coeffs_flat != 0]), bins=20, edgecolor='black')
    ax.set_xlabel('ç³»æ•°ç»å¯¹å€¼')
    ax.set_ylabel('é¢‘æ•°')
    ax.set_title(f'(b) éé›¶ç³»æ•°åˆ†å¸ƒï¼ˆ{np.sum(np.abs(coeffs_flat)>1e-6)}ä¸ªéé›¶ï¼‰')
    ax.set_yscale('log')
    ax.grid(True, alpha=0.3)

    # é¢„æµ‹ vs å®é™…ï¼ˆæ°´æ·±å¯¼æ•°ï¼‰
    ax = axes[1, 0]
    ax.scatter(dXdt_data[:, 0], dXdt_pred[:, 0], alpha=0.5, s=20)
    lim = [dXdt_data[:, 0].min(), dXdt_data[:, 0].max()]
    ax.plot(lim, lim, 'r--', linewidth=2, label='ç†æƒ³æ‹Ÿåˆ')
    ax.set_xlabel('å®é™… dh/dt')
    ax.set_ylabel('é¢„æµ‹ dh/dt')
    ax.set_title('(c) æ°´æ·±å¯¼æ•°é¢„æµ‹')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # é¢„æµ‹ vs å®é™…ï¼ˆæµé‡å¯¼æ•°ï¼‰
    ax = axes[1, 1]
    ax.scatter(dXdt_data[:, 1], dXdt_pred[:, 1], alpha=0.5, s=20)
    lim = [dXdt_data[:, 1].min(), dXdt_data[:, 1].max()]
    ax.plot(lim, lim, 'r--', linewidth=2, label='ç†æƒ³æ‹Ÿåˆ')
    ax.set_xlabel('å®é™… dQ/dt')
    ax.set_ylabel('é¢„æµ‹ dQ/dt')
    ax.set_title(f'(d) æµé‡å¯¼æ•°é¢„æµ‹ (RÂ²={r2_score:.3f})')
    ax.grid(True, alpha=0.3)
    ax.legend()

    plt.tight_layout()
    plt.savefig('part2_sindy_identification.png', dpi=150, bbox_inches='tight')
    print("å›¾å½¢å·²ä¿å­˜: part2_sindy_identification.png")
    plt.close()


def part3_digital_twin_synchronization():
    """æ¼”ç¤º3ï¼šæ•°å­—å­ªç”Ÿè™šå®åŒæ­¥

    ä½¿ç”¨EKFä»ç¨€ç–ä¼ æ„Ÿå™¨é‡æ„å…¨åœºçŠ¶æ€
    """
    print("\n" + "="*60)
    print("æ¼”ç¤º3ï¼šæ•°å­—å­ªç”Ÿè™šå®åŒæ­¥ï¼ˆEKFçŠ¶æ€ä¼°è®¡ï¼‰")
    print("="*60)

    # åˆ›å»º"ç‰©ç†ç³»ç»Ÿ"ï¼ˆçœŸå®æ¨¡å‹ï¼‰
    print("\nåˆ›å»ºç‰©ç†ç³»ç»Ÿ...")
    physical_system = SimplifiedCanalModel(L=50000, N=100, h0=3.0, Q0=100.0)

    # åˆ›å»ºæ•°å­—å­ªç”Ÿæ¨¡å‹
    print("åˆ›å»ºæ•°å­—å­ªç”Ÿæ¨¡å‹...")
    digital_twin_model = SimplifiedCanalModel(L=50000, N=100, h0=3.0, Q0=100.0)

    # è®¾ç½®ä¼ æ„Ÿå™¨ä½ç½®ï¼ˆç¨€ç–éƒ¨ç½²ï¼šæ¯10ä¸ªèŠ‚ç‚¹1ä¸ªä¼ æ„Ÿå™¨ï¼‰
    sensor_indices = list(range(0, 100, 10))  # 10ä¸ªä¼ æ„Ÿå™¨
    print(f"ä¼ æ„Ÿå™¨éƒ¨ç½²: {len(sensor_indices)}ä¸ªä¼ æ„Ÿå™¨ï¼ˆæ¯{50000/len(sensor_indices):.0f}mä¸€ä¸ªï¼‰")

    # åˆ›å»ºEKF
    n_states = 200  # 100ä¸ªæ°´ä½ + 100ä¸ªæµé‡
    n_measurements = len(sensor_indices)
    ekf = ExtendedKalmanFilter(n_states, n_measurements)
    ekf.Q *= 0.001  # è¾ƒå°çš„è¿‡ç¨‹å™ªå£°
    ekf.R *= 0.05  # æµ‹é‡å™ªå£°

    # åˆ›å»ºé™é˜¶æ¨¡å‹ï¼ˆç®€åŒ–ä¸ºNoneï¼‰
    rom = None

    # åˆ›å»ºæ•°å­—å­ªç”Ÿ
    twin = DigitalTwinCore(digital_twin_model, rom, ekf)

    # ä»¿çœŸè¿è¡Œ
    print("\nè¿è¡Œè™šå®åŒæ­¥...")
    N_steps = 50
    history_true = []
    history_estimated = []
    history_anomaly = []

    for step in range(N_steps):
        # ç‰©ç†ç³»ç»Ÿæ¼”åŒ–ï¼ˆæ–½åŠ éšæœºæ‰°åŠ¨ï¼‰
        Q_upstream = 100.0 + 10.0 * np.sin(step * 0.2)
        physical_system.step(dt=60, Q_upstream=Q_upstream)

        # ä¼ æ„Ÿå™¨æµ‹é‡ï¼ˆå¸¦å™ªå£°ï¼‰
        true_state = physical_system.get_state()
        measurements = true_state[sensor_indices] + np.random.randn(n_measurements) * 0.1

        # åœ¨ç¬¬30æ­¥æ³¨å…¥å¼‚å¸¸ï¼ˆä¼ æ„Ÿå™¨æ•…éšœï¼‰
        if step == 30:
            measurements[5] += 2.0  # ä¼ æ„Ÿå™¨5è¯»æ•°å¼‚å¸¸
            print(f"\n  [æ—¶é—´æ­¥{step}] æ³¨å…¥ä¼ æ„Ÿå™¨å¼‚å¸¸: sensor_5è¯»æ•°+2m")

        # æ•°å­—å­ªç”ŸåŒæ­¥
        estimated_state = twin.synchronize(measurements, sensor_indices, Q_upstream)

        # å¼‚å¸¸æ£€æµ‹
        is_anomaly, residual_norm = twin.anomaly_detection(threshold=3.0)
        if is_anomaly:
            print(f"  [æ—¶é—´æ­¥{step}] âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸! æ®‹å·®èŒƒæ•°={residual_norm:.2f}")

        # è®°å½•
        history_true.append(true_state[:100].copy())  # åªè®°å½•æ°´ä½
        history_estimated.append(estimated_state[:100].copy())
        history_anomaly.append(1 if is_anomaly else 0)

    history_true = np.array(history_true)
    history_estimated = np.array(history_estimated)

    # æ€§èƒ½è¯„ä¼°
    rmse = np.sqrt(np.mean((history_true - history_estimated)**2))
    print(f"\nè™šæ‹Ÿä¼ æ„Ÿå™¨ç²¾åº¦: RMSE = {rmse*100:.2f} cm")

    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('æ•°å­—å­ªç”Ÿè™šå®åŒæ­¥ï¼ˆEKFçŠ¶æ€ä¼°è®¡ï¼‰', fontsize=14, fontweight='bold')

    # æ—¶ç©ºæ¼”åŒ–ï¼ˆçœŸå®ï¼‰
    ax = axes[0, 0]
    im = ax.imshow(history_true.T, aspect='auto', cmap='viridis', interpolation='nearest')
    ax.set_xlabel('æ—¶é—´æ­¥')
    ax.set_ylabel('ç©ºé—´ä½ç½®')
    ax.set_title('(a) ç‰©ç†ç³»ç»ŸçœŸå®æ°´ä½ [m]')
    plt.colorbar(im, ax=ax, label='æ°´ä½ [m]')

    # æ—¶ç©ºæ¼”åŒ–ï¼ˆä¼°è®¡ï¼‰
    ax = axes[0, 1]
    im = ax.imshow(history_estimated.T, aspect='auto', cmap='viridis', interpolation='nearest')
    ax.set_xlabel('æ—¶é—´æ­¥')
    ax.set_ylabel('ç©ºé—´ä½ç½®')
    ax.set_title('(b) æ•°å­—å­ªç”Ÿä¼°è®¡æ°´ä½ [m]')
    plt.colorbar(im, ax=ax, label='æ°´ä½ [m]')

    # ä¼°è®¡è¯¯å·®
    ax = axes[1, 0]
    error = np.abs(history_true - history_estimated) * 100  # cm
    im = ax.imshow(error.T, aspect='auto', cmap='hot', interpolation='nearest')
    ax.set_xlabel('æ—¶é—´æ­¥')
    ax.set_ylabel('ç©ºé—´ä½ç½®')
    ax.set_title('(c) ä¼°è®¡è¯¯å·® [cm]')
    plt.colorbar(im, ax=ax, label='è¯¯å·® [cm]')

    # å¼‚å¸¸æ£€æµ‹æ—¶é—´åºåˆ—
    ax = axes[1, 1]
    t_axis = np.arange(N_steps)
    ax.plot(t_axis, history_true[:, 50], 'b-', linewidth=2, label='çœŸå®æ°´ä½')
    ax.plot(t_axis, history_estimated[:, 50], 'g--', linewidth=2, label='ä¼°è®¡æ°´ä½')
    anomaly_times = t_axis[np.array(history_anomaly) == 1]
    if len(anomaly_times) > 0:
        ax.scatter(anomaly_times, history_true[anomaly_times, 50],
                   color='red', s=100, marker='x', linewidths=3, label='å¼‚å¸¸æ£€æµ‹', zorder=5)
    ax.set_xlabel('æ—¶é—´æ­¥')
    ax.set_ylabel('æ°´ä½ [m]')
    ax.set_title('(d) ä¸­ç‚¹æ°´ä½ä¸å¼‚å¸¸æ£€æµ‹')
    ax.grid(True, alpha=0.3)
    ax.legend()

    plt.tight_layout()
    plt.savefig('part3_digital_twin_synchronization.png', dpi=150, bbox_inches='tight')
    print("å›¾å½¢å·²ä¿å­˜: part3_digital_twin_synchronization.png")
    plt.close()


def part4_predictive_maintenance():
    """æ¼”ç¤º4ï¼šæ³µç«™é¢„æµ‹æ€§ç»´æŠ¤

    åŸºäºæŒ¯åŠ¨ç›‘æµ‹é¢„æµ‹è½´æ‰¿å‰©ä½™ä½¿ç”¨å¯¿å‘½
    """
    print("\n" + "="*60)
    print("æ¼”ç¤º4ï¼šæ³µç«™é¢„æµ‹æ€§ç»´æŠ¤ï¼ˆRULé¢„æµ‹ï¼‰")
    print("="*60)

    # åˆ›å»ºç»´æŠ¤ç³»ç»Ÿ
    pm_system = PredictiveMaintenanceSystem()
    equipment_id = "pump_station_3_bearing_A"
    pm_system.register_equipment(equipment_id)

    print(f"\nç›‘æµ‹è®¾å¤‡: {equipment_id}")

    # æ¨¡æ‹Ÿè®¾å¤‡é€€åŒ–è¿‡ç¨‹ï¼ˆæŒ‡æ•°å¢é•¿ï¼‰
    t0 = 0
    theta0 = 1.0  # åˆå§‹å¥åº·æŒ‡æ ‡ï¼ˆæŒ¯åŠ¨RMSï¼‰
    lambda_true = 0.05  # çœŸå®é€€åŒ–é€Ÿç‡ï¼ˆæ¯å¤©ï¼‰
    failure_threshold = 10.0  # å¤±æ•ˆé˜ˆå€¼

    # é‡‡é›†å†å²æ•°æ®ï¼ˆ60å¤©ï¼‰
    print("é‡‡é›†å†å²æŒ¯åŠ¨æ•°æ®...")
    times = []
    health_indices = []

    for day in range(60):
        t = t0 + day
        # çœŸå®å¥åº·æŒ‡æ ‡ï¼ˆå¸¦å™ªå£°ï¼‰
        theta_true = theta0 * np.exp(lambda_true * day)
        measurements = theta_true + np.random.randn() * 0.3  # æµ‹é‡å™ªå£°

        # æ›´æ–°ç»´æŠ¤ç³»ç»Ÿ
        pm_system.update_health(equipment_id, t, np.array([measurements]))

        times.append(t)
        health_indices.append(measurements)

    times = np.array(times)
    health_indices = np.array(health_indices)

    # æ‹Ÿåˆé€€åŒ–æ¨¡å‹
    model = pm_system.equipment[equipment_id]
    lambda_estimated = model.fit()

    print(f"\né€€åŒ–æ¨¡å‹å‚æ•°:")
    print(f"  çœŸå®é€€åŒ–é€Ÿç‡ Î»: {lambda_true:.4f} /å¤©")
    print(f"  ä¼°è®¡é€€åŒ–é€Ÿç‡ Î»: {lambda_estimated:.4f} /å¤©")
    print(f"  å¤±æ•ˆé˜ˆå€¼: {failure_threshold:.1f}")

    # é¢„æµ‹RUL
    rul = pm_system.predict_rul(equipment_id, failure_threshold)
    print(f"\nå‰©ä½™ä½¿ç”¨å¯¿å‘½ (RUL): {rul:.1f} å¤©")

    # ç»´æŠ¤å†³ç­–
    level, message = pm_system.maintenance_decision(equipment_id, failure_threshold)
    print(f"ç»´æŠ¤å†³ç­–: [{level}] {message}")

    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('é¢„æµ‹æ€§ç»´æŠ¤ç³»ç»Ÿ', fontsize=14, fontweight='bold')

    # é€€åŒ–è½¨è¿¹
    ax = axes[0, 0]
    ax.scatter(times, health_indices, alpha=0.5, s=30, label='æµ‹é‡å€¼')
    t_fit = np.linspace(0, times[-1] + rul, 100)
    health_fit = model.theta0 * np.exp(model.lambda_rate * t_fit)
    ax.plot(t_fit, health_fit, 'r-', linewidth=2, label='æ‹Ÿåˆæ¨¡å‹')
    ax.axhline(failure_threshold, color='orange', linestyle='--', linewidth=2, label='å¤±æ•ˆé˜ˆå€¼')
    ax.axvline(times[-1], color='g', linestyle='--', alpha=0.5, label='å½“å‰æ—¶åˆ»')
    ax.axvline(times[-1] + rul, color='r', linestyle='--', alpha=0.5, label=f'é¢„æµ‹å¤±æ•ˆ ({rul:.1f}å¤©å)')
    ax.set_xlabel('æ—¶é—´ [å¤©]')
    ax.set_ylabel('å¥åº·æŒ‡æ ‡ï¼ˆæŒ¯åŠ¨RMSï¼‰')
    ax.set_title('(a) è®¾å¤‡é€€åŒ–è½¨è¿¹ä¸RULé¢„æµ‹')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # å¯¹æ•°ç©ºé—´ï¼ˆéªŒè¯æŒ‡æ•°æ¨¡å‹ï¼‰
    ax = axes[0, 1]
    log_health = np.log(health_indices)
    ax.scatter(times, log_health, alpha=0.5, s=30, label='ln(æµ‹é‡å€¼)')
    log_fit = np.log(model.theta0) + model.lambda_rate * t_fit
    ax.plot(t_fit, log_fit, 'r-', linewidth=2, label='çº¿æ€§æ‹Ÿåˆ')
    ax.set_xlabel('æ—¶é—´ [å¤©]')
    ax.set_ylabel('ln(å¥åº·æŒ‡æ ‡)')
    ax.set_title('(b) å¯¹æ•°ç©ºé—´éªŒè¯ï¼ˆçº¿æ€§å›å½’ï¼‰')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # æ®‹å·®åˆ†æ
    ax = axes[1, 0]
    health_pred = model.theta0 * np.exp(model.lambda_rate * times)
    residuals = health_indices - health_pred
    ax.scatter(times, residuals, alpha=0.5, s=30)
    ax.axhline(0, color='r', linestyle='--', linewidth=2)
    ax.axhline(np.std(residuals), color='orange', linestyle='--', alpha=0.5, label=f'Â±1Ïƒ ({np.std(residuals):.2f})')
    ax.axhline(-np.std(residuals), color='orange', linestyle='--', alpha=0.5)
    ax.set_xlabel('æ—¶é—´ [å¤©]')
    ax.set_ylabel('æ®‹å·®')
    ax.set_title('(c) æ‹Ÿåˆæ®‹å·®åˆ†æ')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # RULä¸ç¡®å®šæ€§ï¼ˆç®€åŒ–ï¼šæ˜¾ç¤ºä¸åŒé€€åŒ–é€Ÿç‡ä¸‹çš„RULï¼‰
    ax = axes[1, 1]
    lambda_range = np.linspace(lambda_estimated * 0.8, lambda_estimated * 1.2, 50)
    rul_range = []
    for lam in lambda_range:
        if lam > 0:
            rul_temp = (np.log(failure_threshold) - np.log(health_indices[-1])) / lam
            rul_range.append(max(0, rul_temp))
        else:
            rul_range.append(np.inf)

    rul_range = np.array(rul_range)
    rul_range = rul_range[rul_range < 200]  # æˆªæ–­æ˜¾ç¤º

    ax.hist(rul_range, bins=20, edgecolor='black', alpha=0.7)
    ax.axvline(rul, color='r', linewidth=3, label=f'é¢„æµ‹RUL={rul:.1f}å¤©')
    ax.set_xlabel('RUL [å¤©]')
    ax.set_ylabel('é¢‘æ•°')
    ax.set_title('(d) RULä¸ç¡®å®šæ€§ï¼ˆå‚æ•°æ‰°åŠ¨ï¼‰')
    ax.grid(True, alpha=0.3)
    ax.legend()

    plt.tight_layout()
    plt.savefig('part4_predictive_maintenance.png', dpi=150, bbox_inches='tight')
    print("å›¾å½¢å·²ä¿å­˜: part4_predictive_maintenance.png")
    plt.close()


# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»ç¨‹åºï¼šè¿è¡Œæ‰€æœ‰æ¼”ç¤ºæ¡ˆä¾‹"""
    print("\n" + "="*60)
    print("æ¡ˆä¾‹20: å—æ°´åŒ—è°ƒå·¥ç¨‹æ•°å­—å­ªç”Ÿç³»ç»Ÿ")
    print("Digital Twin System for South-to-North Water Transfer Project")
    print("="*60)
    print("\né›†æˆæŠ€æœ¯:")
    print("  âœ“ PODé™é˜¶æ¨¡å‹ - åŠ é€Ÿè®¡ç®—100å€")
    print("  âœ“ SINDyç³»ç»Ÿè¾¨è¯† - æ•°æ®é©±åŠ¨å‚æ•°æ ¡å‡†")
    print("  âœ“ EKFçŠ¶æ€ä¼°è®¡ - è™šæ‹Ÿä¼ æ„Ÿå™¨å…¨åœºé‡æ„")
    print("  âœ“ é¢„æµ‹æ€§ç»´æŠ¤ - è®¾å¤‡å¥åº·ç›‘æµ‹ä¸RULé¢„æµ‹")

    # è¿è¡Œå››ä¸ªæ¼”ç¤ºæ¡ˆä¾‹
    part1_pod_acceleration()
    part2_sindy_identification()
    part3_digital_twin_synchronization()
    part4_predictive_maintenance()

    print("\n" + "="*60)
    print("æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
    print("="*60)
    print("\nç”Ÿæˆçš„å›¾å½¢æ–‡ä»¶:")
    print("  1. part1_pod_acceleration.png - PODé™é˜¶æ¨¡å‹åŠ é€Ÿ")
    print("  2. part2_sindy_identification.png - SINDyç³»ç»Ÿè¾¨è¯†")
    print("  3. part3_digital_twin_synchronization.png - æ•°å­—å­ªç”Ÿè™šå®åŒæ­¥")
    print("  4. part4_predictive_maintenance.png - é¢„æµ‹æ€§ç»´æŠ¤")

    print("\nå·¥ç¨‹æ•ˆç›Šä¼°ç®—:")
    print("  ğŸ’° èŠ‚èƒ½é™è€—: æ³µç«™å¹´èŠ‚ç”µ15% â†’ çº¦2000ä¸‡å…ƒ/å¹´")
    print("  ğŸ”§ å‡å°‘æ•…éšœ: é¢„æµ‹æ€§ç»´æŠ¤å‡å°‘çªå‘æ•…éšœ50% â†’ çº¦5000ä¸‡å…ƒ/å¹´")
    print("  ğŸ’§ ä¼˜åŒ–è°ƒåº¦: æ°´èµ„æºåˆ©ç”¨æ•ˆç‡æå‡10% â†’ å¢åŠ ä¾›æ°´1äº¿mÂ³/å¹´")
    print("  â° å»¶é•¿å¯¿å‘½: è®¾å¤‡å¯¿å‘½å»¶é•¿30% â†’ æ¨è¿Ÿæ›´æ–°æ”¹é€ æŠ•èµ„çº¦3äº¿å…ƒ")
    print("  ğŸ“Š æ€»ç»æµæ•ˆç›Š: çº¦7000ä¸‡å…ƒ/å¹´ + 3äº¿å…ƒï¼ˆä¸€æ¬¡æ€§ï¼‰")

    print("\næŠ€æœ¯åˆ›æ–°:")
    print("  ğŸš€ è®¡ç®—æ•ˆç‡: é«˜ä¿çœŸä»¿çœŸ2å°æ—¶ â†’ PODé™é˜¶1.2åˆ†é’Ÿ (100x)")
    print("  ğŸ“¡ ä¼ æ„Ÿå™¨éƒ¨ç½²: å…¨çº¿1432ä¸ª â†’ 143ä¸ª+è™šæ‹Ÿä¼ æ„Ÿ (æˆæœ¬é™ä½90%)")
    print("  âš¡ æ•…éšœè¯Šæ–­: äº‹ååˆ†ææ•°å¤© â†’ å®æ—¶æ£€æµ‹ç§’çº§ (1000x)")
    print("  ğŸ› ï¸ ç»´æŠ¤æ¨¡å¼: å®šæœŸ+æ•…éšœç»´ä¿® â†’ é¢„æµ‹æ€§ç»´æŠ¤ (å¯¿å‘½å»¶é•¿30%)")

    print("\nğŸ‰ æ¡ˆä¾‹20ï¼šå—æ°´åŒ—è°ƒæ•°å­—å­ªç”Ÿç³»ç»Ÿ - æ™ºèƒ½æ°´åˆ©çš„æœªæ¥ï¼")


if __name__ == "__main__":
    main()
