# 第9章：优化方法进阶

**学习时间**: 5小时  
**考试频率**: ⭐⭐⭐⭐  
**难度**: ⭐⭐⭐⭐⭐

---

## 一、约束优化方法

### 1.1 拉格朗日乘数法

**问题形式**：
$$
\begin{aligned}
\min \quad & f(\mathbf{x}) \\
\text{s.t.} \quad & g_i(\mathbf{x}) = 0, \quad i = 1, 2, \ldots, m
\end{aligned}
$$

**拉格朗日函数**：
$$
L(\mathbf{x}, \boldsymbol{\lambda}) = f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i g_i(\mathbf{x})
$$

**必要条件（KKT条件简化版）**：
$$
\begin{cases}
\nabla_{\mathbf{x}} L = \nabla f + \sum_{i=1}^{m} \lambda_i \nabla g_i = \mathbf{0} \\
g_i(\mathbf{x}) = 0, \quad i = 1, \ldots, m
\end{cases}
$$

**示例**：
最小化 $f(x, y) = x^2 + y^2$，约束 $g(x, y) = x + y - 1 = 0$

拉格朗日函数：
$$
L(x, y, \lambda) = x^2 + y^2 + \lambda(x + y - 1)
$$

必要条件：
$$
\begin{cases}
\frac{\partial L}{\partial x} = 2x + \lambda = 0 \\
\frac{\partial L}{\partial y} = 2y + \lambda = 0 \\
x + y - 1 = 0
\end{cases}
$$

解得：$x = y = 0.5$, $\lambda = -1$，最小值 $f^* = 0.5$

---

### 1.2 KKT条件（含不等式约束）

**问题形式**：
$$
\begin{aligned}
\min \quad & f(\mathbf{x}) \\
\text{s.t.} \quad & g_i(\mathbf{x}) = 0, \quad i = 1, \ldots, m \\
& h_j(\mathbf{x}) \leq 0, \quad j = 1, \ldots, p
\end{aligned}
$$

**KKT条件**：
1. **平稳性**：$\nabla f(\mathbf{x}^*) + \sum_{i=1}^{m} \lambda_i \nabla g_i(\mathbf{x}^*) + \sum_{j=1}^{p} \mu_j \nabla h_j(\mathbf{x}^*) = \mathbf{0}$
2. **原始可行性**：$g_i(\mathbf{x}^*) = 0$, $h_j(\mathbf{x}^*) \leq 0$
3. **对偶可行性**：$\mu_j \geq 0$
4. **互补松弛**：$\mu_j h_j(\mathbf{x}^*) = 0$

**示例**：
最小化 $f(x, y) = (x-2)^2 + (y-1)^2$，约束 $x + y \leq 2$, $x, y \geq 0$

情况1：内点解（约束不起作用）→ 无约束最优解 $(2, 1)$

检查：$2 + 1 = 3 > 2$ 不可行

情况2：边界解（$x + y = 2$）

拉格朗日函数：
$$
L = (x-2)^2 + (y-1)^2 + \mu(x + y - 2)
$$

KKT条件：
$$
\begin{cases}
2(x-2) + \mu = 0 \\
2(y-1) + \mu = 0 \\
x + y = 2 \\
\mu \geq 0
\end{cases}
$$

解得：$x = y = 1$, $\mu = 2$，最小值 $f^* = 1$

---

### 1.3 罚函数法

**原理**：将约束优化转化为无约束优化

**外点罚函数**（Exterior Penalty）：
$$
P(\mathbf{x}, r_k) = f(\mathbf{x}) + r_k \left[ \sum_{i=1}^{m} g_i^2(\mathbf{x}) + \sum_{j=1}^{p} \max(0, h_j(\mathbf{x}))^2 \right]
$$

其中 $r_k \to \infty$ 是罚因子序列

**算法步骤**：
1. 初始化：$\mathbf{x}_0$, $r_1 > 0$, $\beta > 1$（如 $\beta = 10$）
2. 第 $k$ 次迭代：求解无约束问题 $\min P(\mathbf{x}, r_k)$ 得 $\mathbf{x}_k$
3. 更新：$r_{k+1} = \beta r_k$
4. 检查收敛：若 $\|\mathbf{x}_{k+1} - \mathbf{x}_k\| < \epsilon$ 停止

**示例**：
最小化 $f(x, y) = x + y$，约束 $x^2 + y^2 = 1$

罚函数：
$$
P(x, y, r) = x + y + r(x^2 + y^2 - 1)^2
$$

对于大的 $r$，最优解接近 $x = y = -\frac{1}{\sqrt{2}}$（约束边界上）

---

### 1.4 内点法（Interior Point Method）

**障碍函数**（对数障碍）：
$$
B(\mathbf{x}, \mu) = f(\mathbf{x}) - \mu \sum_{j=1}^{p} \ln(-h_j(\mathbf{x}))
$$

其中 $\mu \to 0^+$ 是障碍参数

**特点**：
- 迭代点始终在可行域内部
- 逐渐逼近边界
- 适用于不等式约束

**示例（线性规划内点法）**：
$$
\begin{aligned}
\min \quad & \mathbf{c}^T \mathbf{x} \\
\text{s.t.} \quad & A\mathbf{x} = \mathbf{b} \\
& \mathbf{x} \geq \mathbf{0}
\end{aligned}
$$

障碍函数：
$$
B(\mathbf{x}, \mu) = \mathbf{c}^T \mathbf{x} - \mu \sum_{i=1}^{n} \ln(x_i)
$$

KKT条件：
$$
\begin{cases}
\mathbf{c} - A^T \mathbf{y} - \mu \mathbf{X}^{-1} \mathbf{e} = \mathbf{0} \\
A\mathbf{x} = \mathbf{b} \\
\mathbf{x} > \mathbf{0}
\end{cases}
$$

其中 $\mathbf{X} = \text{diag}(x_1, \ldots, x_n)$，$\mathbf{e} = (1, \ldots, 1)^T$

---

## 二、全局优化方法

### 2.1 模拟退火算法

**原理**：模拟金属退火过程，以一定概率接受劣解，避免陷入局部最优

**Metropolis准则**：
$$
P(\text{接受新解}) = \begin{cases}
1, & f(\mathbf{x}_{\text{new}}) < f(\mathbf{x}_{\text{current}}) \\
\exp\left(-\frac{\Delta f}{T}\right), & f(\mathbf{x}_{\text{new}}) \geq f(\mathbf{x}_{\text{current}})
\end{cases}
$$

其中 $\Delta f = f(\mathbf{x}_{\text{new}}) - f(\mathbf{x}_{\text{current}})$，$T$ 是温度

**算法步骤**：
1. 初始化：$\mathbf{x}_0$, $T_0$ (初始温度), $\alpha$ (降温系数, 如 0.95)
2. 在当前温度 $T_k$：
   - 生成邻域解 $\mathbf{x}_{\text{new}}$
   - 计算 $\Delta f$
   - 以 Metropolis 准则接受/拒绝
   - 重复 $L$ 次（内循环）
3. 降温：$T_{k+1} = \alpha T_k$
4. 检查终止条件（$T < T_{\min}$ 或迭代次数）

**降温策略**：
- **线性降温**：$T_k = T_0 - k \Delta T$
- **指数降温**：$T_k = \alpha^k T_0$ （常用，$\alpha \approx 0.9 \sim 0.99$）
- **对数降温**：$T_k = \frac{T_0}{\ln(k+2)}$

---

### 2.2 遗传算法（Genetic Algorithm）

**基本概念**：
- **染色体（Chromosome）**：解的编码（二进制或实数）
- **种群（Population）**：一组候选解
- **适应度（Fitness）**：目标函数值（或其变换）
- **选择（Selection）**：按适应度选择父代
- **交叉（Crossover）**：父代基因重组产生子代
- **变异（Mutation）**：以小概率随机改变基因

**算法流程**：
1. **初始化**：随机生成初始种群 $P_0$
2. **评估**：计算每个个体的适应度
3. **选择**：轮盘赌/锦标赛选择
4. **交叉**：
   - 单点交叉：随机选择交叉点，交换后半段
   - 均匀交叉：逐位以 0.5 概率交换
   - 算术交叉：$\mathbf{x}_{\text{child}} = \lambda \mathbf{x}_1 + (1-\lambda) \mathbf{x}_2$
5. **变异**：
   - 二进制：翻转位（$p_m \approx 0.01$）
   - 实数：$x_i' = x_i + \mathcal{N}(0, \sigma^2)$
6. **替换**：生成新种群 $P_{k+1}$
7. 重复直到收敛

**参数设置**：
- 种群规模：50-200
- 交叉概率：0.6-0.9
- 变异概率：0.001-0.1
- 迭代代数：100-1000

---

### 2.3 粒子群优化（PSO）

**原理**：模拟鸟群觅食行为，粒子在搜索空间中飞行，追踪个体最优和全局最优

**速度与位置更新**：
$$
\begin{aligned}
v_i^{k+1} &= w v_i^k + c_1 r_1 (\mathbf{p}_i - \mathbf{x}_i^k) + c_2 r_2 (\mathbf{g} - \mathbf{x}_i^k) \\
\mathbf{x}_i^{k+1} &= \mathbf{x}_i^k + v_i^{k+1}
\end{aligned}
$$

其中：
- $v_i^k$：第 $i$ 个粒子的速度
- $\mathbf{x}_i^k$：第 $i$ 个粒子的位置
- $\mathbf{p}_i$：第 $i$ 个粒子的历史最优位置
- $\mathbf{g}$：全局最优位置
- $w$：惯性权重（0.4-0.9）
- $c_1, c_2$：学习因子（通常取 2）
- $r_1, r_2$：$[0, 1]$ 随机数

**算法步骤**：
1. 初始化：随机位置 $\mathbf{x}_i^0$ 和速度 $v_i^0$
2. 评估适应度，更新 $\mathbf{p}_i$ 和 $\mathbf{g}$
3. 更新速度和位置
4. 检查边界：$\mathbf{x}_i \in [\mathbf{x}_{\min}, \mathbf{x}_{\max}]$
5. 重复直到收敛

**参数设置**：
- 粒子数：20-50
- 惯性权重：线性递减 $w = w_{\max} - k \frac{w_{\max} - w_{\min}}{k_{\max}}$
- 最大速度：$(x_{\max} - x_{\min}) / 10$

---

### 2.4 差分进化（DE）

**变异策略**：
$$
\mathbf{v}_i = \mathbf{x}_{r1} + F (\mathbf{x}_{r2} - \mathbf{x}_{r3})
$$

其中 $r1, r2, r3$ 是随机选择的互异个体索引，$F \in [0.4, 1]$ 是缩放因子

**交叉**：
$$
u_{ij} = \begin{cases}
v_{ij}, & \text{rand}() < CR \text{ or } j = j_{\text{rand}} \\
x_{ij}, & \text{otherwise}
\end{cases}
$$

其中 $CR \in [0.5, 0.9]$ 是交叉概率

**选择**：
$$
\mathbf{x}_i^{k+1} = \begin{cases}
\mathbf{u}_i, & f(\mathbf{u}_i) < f(\mathbf{x}_i^k) \\
\mathbf{x}_i^k, & \text{otherwise}
\end{cases}
$$

**特点**：
- 简单高效
- 参数少（$F, CR$）
- 适用于连续优化

---

## 三、多目标优化

### 3.1 Pareto最优

**支配关系**：
对于最小化多目标问题，$\mathbf{x}$ 支配 $\mathbf{y}$ 当且仅当：
$$
f_i(\mathbf{x}) \leq f_i(\mathbf{y}), \quad \forall i \in \{1, \ldots, m\}
$$
且至少存在一个 $j$ 使得 $f_j(\mathbf{x}) < f_j(\mathbf{y})$

**Pareto最优解**：不被任何其他可行解支配的解

**Pareto前沿（Pareto Front）**：所有Pareto最优解在目标空间的映像

**示例（双目标）**：
$$
\begin{aligned}
\min \quad & f_1(\mathbf{x}), \quad f_2(\mathbf{x}) \\
\text{s.t.} \quad & \mathbf{x} \in \Omega
\end{aligned}
$$

Pareto前沿是 $f_1$ 和 $f_2$ 的权衡曲线

---

### 3.2 加权法

**原理**：将多目标转化为单目标

**加权和**：
$$
\min \quad F(\mathbf{x}) = \sum_{i=1}^{m} w_i f_i(\mathbf{x})
$$

其中 $w_i \geq 0$, $\sum_{i=1}^{m} w_i = 1$

**特点**：
- 简单直观
- 通过改变权重可得到不同的Pareto最优解
- 无法得到非凸Pareto前沿的凹部分

---

### 3.3 ε-约束法

**原理**：优化一个目标，其他目标作为约束

$$
\begin{aligned}
\min \quad & f_j(\mathbf{x}) \\
\text{s.t.} \quad & f_i(\mathbf{x}) \leq \epsilon_i, \quad i \neq j \\
& \mathbf{x} \in \Omega
\end{aligned}
$$

**特点**：
- 可以得到非凸Pareto前沿
- 需要多次求解（改变 $\epsilon_i$）

---

### 3.4 NSGA-II

**Non-dominated Sorting Genetic Algorithm II**

**关键机制**：
1. **快速非支配排序**：
   - 第1层：所有非支配解
   - 第2层：去除第1层后的非支配解
   - 依次类推

2. **拥挤度距离**（Crowding Distance）：
   - 衡量解在目标空间的密集程度
   - 边界解设为 $\infty$
   - 中间解：相邻解目标值差的归一化和

3. **精英策略**：
   - 父代和子代合并
   - 按非支配层级和拥挤度选择

**算法流程**：
1. 初始化种群 $P_0$
2. 生成子代 $Q_0$（选择、交叉、变异）
3. 合并 $R_0 = P_0 \cup Q_0$
4. 非支配排序和拥挤度计算
5. 选择前 $N$ 个个体作为新父代 $P_1$
6. 重复直到收敛

---

## 四、Python实现

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from typing import Callable, Tuple, List


class ConstrainedOptimization:
    """约束优化方法"""
    
    @staticmethod
    def lagrange_multiplier(f, g, x0, tol=1e-6):
        """
        拉格朗日乘数法（数值求解）
        
        参数:
            f: 目标函数 f(x)
            g: 等式约束列表 [g1, g2, ...]
            x0: 初始点
            tol: 容差
        """
        # 使用scipy优化求解
        constraints = [{'type': 'eq', 'fun': gi} for gi in g]
        result = minimize(f, x0, method='SLSQP', constraints=constraints,
                         options={'ftol': tol})
        
        return result.x, result.fun, result.success
    
    @staticmethod
    def penalty_method(f, g, h, x0, r_init=1, beta=10, max_iter=50):
        """
        外点罚函数法
        
        参数:
            f: 目标函数
            g: 等式约束列表
            h: 不等式约束列表（h <= 0）
            x0: 初始点
            r_init: 初始罚因子
            beta: 罚因子增长因子
            max_iter: 最大迭代次数
        """
        def penalty_function(x, r):
            penalty = 0
            for gi in g:
                penalty += gi(x)**2
            for hi in h:
                penalty += max(0, hi(x))**2
            return f(x) + r * penalty
        
        x_k = x0
        r_k = r_init
        history = []
        
        for k in range(max_iter):
            # 求解无约束问题
            result = minimize(lambda x: penalty_function(x, r_k), x_k,
                            method='BFGS')
            x_k = result.x
            f_k = f(x_k)
            
            # 计算约束违反度
            violation = sum(gi(x_k)**2 for gi in g) + \
                       sum(max(0, hi(x_k))**2 for hi in h)
            
            history.append({
                'x': x_k.copy(),
                'f': f_k,
                'r': r_k,
                'violation': violation
            })
            
            if violation < 1e-6:
                break
            
            r_k *= beta
        
        return x_k, f_k, history


class GlobalOptimization:
    """全局优化方法"""
    
    @staticmethod
    def simulated_annealing(f, bounds, T_init=100, T_min=0.01, alpha=0.95,
                           L=100):
        """
        模拟退火算法
        
        参数:
            f: 目标函数
            bounds: 变量界 [(x1_min, x1_max), (x2_min, x2_max), ...]
            T_init: 初始温度
            T_min: 最低温度
            alpha: 降温系数
            L: 每个温度的迭代次数
        """
        dim = len(bounds)
        
        # 初始解
        x_current = np.array([np.random.uniform(low, high) 
                             for low, high in bounds])
        f_current = f(x_current)
        
        x_best = x_current.copy()
        f_best = f_current
        
        T = T_init
        history = []
        
        while T > T_min:
            for _ in range(L):
                # 生成邻域解（高斯扰动）
                x_new = x_current + np.random.randn(dim) * T / T_init * 0.1 * \
                        np.array([high - low for low, high in bounds])
                
                # 边界处理
                x_new = np.clip(x_new, 
                               [low for low, _ in bounds],
                               [high for _, high in bounds])
                
                f_new = f(x_new)
                delta_f = f_new - f_current
                
                # Metropolis准则
                if delta_f < 0 or np.random.rand() < np.exp(-delta_f / T):
                    x_current = x_new
                    f_current = f_new
                    
                    if f_current < f_best:
                        x_best = x_current.copy()
                        f_best = f_current
            
            history.append({'T': T, 'f_best': f_best})
            T *= alpha
        
        return x_best, f_best, history
    
    @staticmethod
    def genetic_algorithm(f, bounds, pop_size=100, n_gen=200,
                         p_cross=0.8, p_mut=0.1):
        """
        遗传算法（实数编码）
        
        参数:
            f: 目标函数（最小化）
            bounds: 变量界
            pop_size: 种群规模
            n_gen: 迭代代数
            p_cross: 交叉概率
            p_mut: 变异概率
        """
        dim = len(bounds)
        bounds = np.array(bounds)
        
        # 初始化种群
        population = np.random.uniform(bounds[:, 0], bounds[:, 1],
                                      (pop_size, dim))
        
        history = []
        
        for gen in range(n_gen):
            # 评估适应度
            fitness = np.array([f(ind) for ind in population])
            
            # 转换为最大化（取负）
            fitness_scaled = -fitness
            fitness_scaled -= fitness_scaled.min()
            fitness_scaled += 1e-10
            
            best_idx = fitness.argmin()
            history.append({
                'gen': gen,
                'best_fitness': fitness[best_idx],
                'mean_fitness': fitness.mean()
            })
            
            # 选择（轮盘赌）
            prob = fitness_scaled / fitness_scaled.sum()
            selected_idx = np.random.choice(pop_size, size=pop_size, p=prob)
            selected = population[selected_idx]
            
            # 交叉
            offspring = []
            for i in range(0, pop_size, 2):
                parent1, parent2 = selected[i], selected[i+1]
                
                if np.random.rand() < p_cross:
                    # 算术交叉
                    alpha = np.random.rand()
                    child1 = alpha * parent1 + (1 - alpha) * parent2
                    child2 = (1 - alpha) * parent1 + alpha * parent2
                else:
                    child1, child2 = parent1.copy(), parent2.copy()
                
                offspring.extend([child1, child2])
            
            offspring = np.array(offspring)
            
            # 变异
            for i in range(pop_size):
                if np.random.rand() < p_mut:
                    mut_idx = np.random.randint(dim)
                    offspring[i, mut_idx] = np.random.uniform(
                        bounds[mut_idx, 0], bounds[mut_idx, 1])
            
            # 精英保留
            offspring[0] = population[best_idx]
            
            population = offspring
        
        # 最终评估
        fitness = np.array([f(ind) for ind in population])
        best_idx = fitness.argmin()
        
        return population[best_idx], fitness[best_idx], history
    
    @staticmethod
    def particle_swarm(f, bounds, n_particles=30, n_iter=200,
                      w=0.7, c1=2.0, c2=2.0):
        """
        粒子群优化
        
        参数:
            f: 目标函数
            bounds: 变量界
            n_particles: 粒子数
            n_iter: 迭代次数
            w: 惯性权重
            c1, c2: 学习因子
        """
        dim = len(bounds)
        bounds = np.array(bounds)
        
        # 初始化
        positions = np.random.uniform(bounds[:, 0], bounds[:, 1],
                                     (n_particles, dim))
        velocities = np.random.uniform(-1, 1, (n_particles, dim))
        
        # 个体最优
        p_best = positions.copy()
        p_best_fitness = np.array([f(p) for p in positions])
        
        # 全局最优
        g_best_idx = p_best_fitness.argmin()
        g_best = p_best[g_best_idx].copy()
        g_best_fitness = p_best_fitness[g_best_idx]
        
        history = []
        
        for iter_i in range(n_iter):
            for i in range(n_particles):
                # 更新速度
                r1, r2 = np.random.rand(2)
                velocities[i] = (w * velocities[i] +
                                c1 * r1 * (p_best[i] - positions[i]) +
                                c2 * r2 * (g_best - positions[i]))
                
                # 限制速度
                v_max = 0.2 * (bounds[:, 1] - bounds[:, 0])
                velocities[i] = np.clip(velocities[i], -v_max, v_max)
                
                # 更新位置
                positions[i] += velocities[i]
                positions[i] = np.clip(positions[i], bounds[:, 0], bounds[:, 1])
                
                # 更新个体最优
                fitness = f(positions[i])
                if fitness < p_best_fitness[i]:
                    p_best[i] = positions[i].copy()
                    p_best_fitness[i] = fitness
                    
                    # 更新全局最优
                    if fitness < g_best_fitness:
                        g_best = positions[i].copy()
                        g_best_fitness = fitness
            
            history.append({
                'iter': iter_i,
                'g_best_fitness': g_best_fitness,
                'mean_fitness': p_best_fitness.mean()
            })
        
        return g_best, g_best_fitness, history


class MultiObjectiveOptimization:
    """多目标优化"""
    
    @staticmethod
    def is_dominated(f1, f2):
        """判断f1是否被f2支配（最小化）"""
        return np.all(f2 <= f1) and np.any(f2 < f1)
    
    @staticmethod
    def pareto_front(objectives):
        """
        计算Pareto前沿
        
        参数:
            objectives: (n_solutions, n_objectives) 数组
        """
        n = objectives.shape[0]
        is_pareto = np.ones(n, dtype=bool)
        
        for i in range(n):
            for j in range(n):
                if i != j and MultiObjectiveOptimization.is_dominated(
                    objectives[i], objectives[j]):
                    is_pareto[i] = False
                    break
        
        return is_pareto
    
    @staticmethod
    def weighted_sum(objectives_funcs, weights, x0, bounds):
        """
        加权和法
        
        参数:
            objectives_funcs: 目标函数列表
            weights: 权重（和为1）
            x0: 初始点
            bounds: 变量界
        """
        def weighted_obj(x):
            return sum(w * f(x) for w, f in zip(weights, objectives_funcs))
        
        result = minimize(weighted_obj, x0, bounds=bounds, method='L-BFGS-B')
        
        return result.x, [f(result.x) for f in objectives_funcs]


# 测试示例
if __name__ == "__main__":
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False
    
    print("="*60)
    print("优化方法进阶演示")
    print("="*60)
    
    # 1. 约束优化
    print("\n1. 约束优化 - 罚函数法")
    
    def f(x):
        return (x[0] - 2)**2 + (x[1] - 1)**2
    
    def g1(x):
        return x[0] + x[1] - 2
    
    co = ConstrainedOptimization()
    x_opt, f_opt, history = co.penalty_method(f, [g1], [], np.array([0.0, 0.0]))
    
    print(f"最优解: x = {x_opt}, f(x) = {f_opt:.6f}")
    print(f"约束违反度: {g1(x_opt)**2:.6e}")
    
    # 2. 模拟退火
    print("\n" + "="*60)
    print("2. 模拟退火 - Rastrigin函数")
    
    def rastrigin(x):
        return 10 * len(x) + sum(xi**2 - 10 * np.cos(2 * np.pi * xi) 
                                 for xi in x)
    
    bounds = [(-5.12, 5.12)] * 2
    go = GlobalOptimization()
    x_sa, f_sa, hist_sa = go.simulated_annealing(rastrigin, bounds, L=50)
    
    print(f"最优解: x = {x_sa}, f(x) = {f_sa:.6f}")
    print(f"理论最优: x = [0, 0], f(x) = 0")
    
    # 3. 遗传算法
    print("\n" + "="*60)
    print("3. 遗传算法 - Rosenbrock函数")
    
    def rosenbrock(x):
        return sum(100 * (x[i+1] - x[i]**2)**2 + (1 - x[i])**2 
                  for i in range(len(x) - 1))
    
    bounds = [(-5, 5)] * 2
    x_ga, f_ga, hist_ga = go.genetic_algorithm(rosenbrock, bounds, 
                                              pop_size=50, n_gen=100)
    
    print(f"最优解: x = {x_ga}, f(x) = {f_ga:.6f}")
    print(f"理论最优: x = [1, 1], f(x) = 0")
    
    # 4. 粒子群优化
    print("\n" + "="*60)
    print("4. 粒子群优化 - Sphere函数")
    
    def sphere(x):
        return sum(xi**2 for xi in x)
    
    bounds = [(-10, 10)] * 3
    x_pso, f_pso, hist_pso = go.particle_swarm(sphere, bounds, n_particles=20)
    
    print(f"最优解: x = {x_pso}, f(x) = {f_pso:.6e}")
    
    # 5. 多目标优化
    print("\n" + "="*60)
    print("5. 多目标优化 - 加权和法")
    
    def f1(x):
        return x[0]**2 + x[1]**2
    
    def f2(x):
        return (x[0] - 1)**2 + (x[1] - 1)**2
    
    moo = MultiObjectiveOptimization()
    
    # 不同权重下的Pareto解
    pareto_solutions = []
    for w1 in np.linspace(0, 1, 11):
        w2 = 1 - w1
        x_opt, obj_vals = moo.weighted_sum([f1, f2], [w1, w2],
                                          [0.5, 0.5], [(-2, 2), (-2, 2)])
        pareto_solutions.append(obj_vals)
    
    pareto_solutions = np.array(pareto_solutions)
    
    # 可视化
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 模拟退火收敛曲线
    ax = axes[0, 0]
    temps = [h['T'] for h in hist_sa]
    f_bests = [h['f_best'] for h in hist_sa]
    ax.plot(temps, f_bests, 'b-o', markersize=4)
    ax.set_xlabel('温度 T')
    ax.set_ylabel('最优目标值')
    ax.set_title('模拟退火收敛曲线')
    ax.set_xscale('log')
    ax.grid(True, alpha=0.3)
    
    # 遗传算法收敛曲线
    ax = axes[0, 1]
    gens = [h['gen'] for h in hist_ga]
    best_fit = [h['best_fitness'] for h in hist_ga]
    mean_fit = [h['mean_fitness'] for h in hist_ga]
    ax.plot(gens, best_fit, 'r-', label='最优适应度', linewidth=2)
    ax.plot(gens, mean_fit, 'b--', label='平均适应度', linewidth=1.5)
    ax.set_xlabel('代数')
    ax.set_ylabel('适应度')
    ax.set_title('遗传算法收敛曲线')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_yscale('log')
    
    # 粒子群优化收敛曲线
    ax = axes[1, 0]
    iters = [h['iter'] for h in hist_pso]
    g_best = [h['g_best_fitness'] for h in hist_pso]
    mean_fit = [h['mean_fitness'] for h in hist_pso]
    ax.plot(iters, g_best, 'g-', label='全局最优', linewidth=2)
    ax.plot(iters, mean_fit, 'm--', label='平均适应度', linewidth=1.5)
    ax.set_xlabel('迭代次数')
    ax.set_ylabel('适应度')
    ax.set_title('粒子群优化收敛曲线')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_yscale('log')
    
    # Pareto前沿
    ax = axes[1, 1]
    ax.plot(pareto_solutions[:, 0], pareto_solutions[:, 1], 'ro-',
           markersize=8, linewidth=2, label='Pareto前沿')
    ax.set_xlabel('$f_1(x)$')
    ax.set_ylabel('$f_2(x)$')
    ax.set_title('多目标优化 - Pareto前沿')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('optimization_advanced_demo.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("\n图表已保存为 optimization_advanced_demo.png")
```

---

## 五、本章要点

1. **约束优化**：
   - 拉格朗日乘数法（等式约束）
   - KKT条件（不等式约束）
   - 罚函数法、内点法

2. **全局优化**：
   - 模拟退火（Metropolis准则、降温策略）
   - 遗传算法（选择、交叉、变异）
   - 粒子群优化（速度更新、位置更新）
   - 差分进化（变异、交叉、选择）

3. **多目标优化**：
   - Pareto最优、Pareto前沿
   - 加权和法、ε-约束法
   - NSGA-II（非支配排序、拥挤度）

4. **应用场景**：
   - 水库优化调度
   - 管网优化设计
   - 参数反演
   - 多目标决策

---

**下一章**：数值计算综合案例
