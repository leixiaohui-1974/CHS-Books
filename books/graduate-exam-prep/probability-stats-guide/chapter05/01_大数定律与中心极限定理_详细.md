# 第5章：大数定律与中心极限定理

**学习时间**: 4小时  
**难度**: ⭐⭐⭐⭐⭐  
**重要性**: 理论基石

---

## 一、大数定律

### 1.1 切比雪夫不等式

**定理**：设随机变量$X$，$E(X)=\mu$，$D(X)=\sigma^2$，则对$\forall \varepsilon > 0$：

$$P(|X - \mu| \geq \varepsilon) \leq \frac{\sigma^2}{\varepsilon^2}$$

或：
$$P(|X - \mu| < \varepsilon) \geq 1 - \frac{\sigma^2}{\varepsilon^2}$$

**意义**：$X$落在$(\mu-\varepsilon, \mu+\varepsilon)$内的概率至少为$1 - \frac{\sigma^2}{\varepsilon^2}$

**应用**：概率下界估计

### 1.2 切比雪夫大数定律

**定理**：设$X_1, X_2, \ldots, X_n$相互独立，$E(X_i)=\mu$，$D(X_i) \leq C$（有界），则：

$$\frac{1}{n}\sum_{i=1}^{n}X_i \xrightarrow{P} \mu$$

**记号说明**：$\xrightarrow{P}$表示依概率收敛

**含义**：样本均值依概率收敛到总体均值

### 1.3 伯努利大数定律

**定理**：设$n_A$是$n$次独立重复试验中事件$A$发生的次数，$p$是每次试验$A$发生的概率，则：

$$\frac{n_A}{n} \xrightarrow{P} p$$

**含义**：频率依概率收敛到概率

### 1.4 辛钦大数定律

**定理**：设$X_1, X_2, \ldots, X_n$独立同分布，$E(X_i)=\mu$，则：

$$\frac{1}{n}\sum_{i=1}^{n}X_i \xrightarrow{P} \mu$$

**注意**：不要求方差存在

---

## 二、中心极限定理

### 2.1 独立同分布的中心极限定理（林德伯格-列维定理）

**定理**：设$X_1, X_2, \ldots, X_n$独立同分布，$E(X_i)=\mu$，$D(X_i)=\sigma^2 > 0$，则：

$$\frac{\sum_{i=1}^{n}X_i - n\mu}{\sqrt{n}\sigma} \xrightarrow{L} N(0, 1)$$

或等价地：
$$\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \xrightarrow{L} N(0, 1)$$

**记号说明**：$\xrightarrow{L}$表示依分布收敛

**含义**：$n$个独立同分布随机变量之和的标准化，当$n$充分大时，近似服从标准正态分布

**实用形式**：
$$\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right) \quad (n \text{较大})$$

$$\sum_{i=1}^{n}X_i \sim N(n\mu, n\sigma^2) \quad (n \text{较大})$$

### 2.2 棣莫弗-拉普拉斯定理

**定理**：设$\eta_n \sim B(n, p)$，则：

$$\frac{\eta_n - np}{\sqrt{np(1-p)}} \xrightarrow{L} N(0, 1)$$

**含义**：二项分布的正态近似

**应用条件**：$np(1-p) > 9$

**实用公式**：
$$\eta_n \sim N(np, np(1-p)) \quad (n \text{很大})$$

### Python实现

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

class LawOfLargeNumbers:
    """大数定律与中心极限定理"""
    
    @staticmethod
    def chebyshev_inequality(mu, sigma, epsilon):
        """
        切比雪夫不等式
        
        P(|X-μ| < ε) ≥ 1 - σ²/ε²
        
        参数:
            mu: 期望
            sigma: 标准差
            epsilon: 偏差
        """
        lower_bound = 1 - sigma**2 / epsilon**2
        
        return max(0, lower_bound)
    
    @staticmethod
    def simulate_law_of_large_numbers(distribution, params, n_max=10000):
        """
        模拟大数定律
        
        参数:
            distribution: 'uniform', 'exponential', 'normal'
            params: 分布参数
            n_max: 最大样本量
        """
        # 生成样本
        if distribution == 'uniform':
            a, b = params
            samples = np.random.uniform(a, b, n_max)
            true_mean = (a + b) / 2
        elif distribution == 'exponential':
            lam = params
            samples = np.random.exponential(1/lam, n_max)
            true_mean = 1 / lam
        elif distribution == 'normal':
            mu, sigma = params
            samples = np.random.normal(mu, sigma, n_max)
            true_mean = mu
        
        # 计算累计均值
        n_values = np.arange(1, n_max+1)
        cumulative_means = np.cumsum(samples) / n_values
        
        return n_values, cumulative_means, true_mean
    
    @staticmethod
    def simulate_clt(distribution, params, sample_size, n_samples=10000):
        """
        模拟中心极限定理
        
        参数:
            distribution: 分布类型
            params: 分布参数
            sample_size: 每个样本的大小
            n_samples: 样本数量
        """
        sample_means = []
        
        for _ in range(n_samples):
            if distribution == 'uniform':
                a, b = params
                sample = np.random.uniform(a, b, sample_size)
                mu = (a + b) / 2
                sigma = np.sqrt((b - a)**2 / 12)
            elif distribution == 'exponential':
                lam = params
                sample = np.random.exponential(1/lam, sample_size)
                mu = 1 / lam
                sigma = 1 / lam
            elif distribution == 'chi2':
                df = params
                sample = np.random.chisquare(df, sample_size)
                mu = df
                sigma = np.sqrt(2 * df)
            
            sample_mean = np.mean(sample)
            sample_means.append(sample_mean)
        
        sample_means = np.array(sample_means)
        
        # 标准化
        standardized = (sample_means - mu) / (sigma / np.sqrt(sample_size))
        
        return sample_means, standardized, mu, sigma
    
    @staticmethod
    def binomial_normal_approximation(n, p, k):
        """
        二项分布的正态近似
        
        P(X=k) ≈ φ((k-np)/√(np(1-p)))
        
        参数:
            n: 试验次数
            p: 成功概率
            k: 成功次数
        """
        # 精确值
        exact = stats.binom.pmf(k, n, p)
        
        # 正态近似（连续性修正）
        mu = n * p
        sigma = np.sqrt(n * p * (1 - p))
        
        # P(X=k) ≈ P(k-0.5 < Y < k+0.5)，Y~N(μ,σ²)
        approx = stats.norm.cdf(k + 0.5, mu, sigma) - \
                 stats.norm.cdf(k - 0.5, mu, sigma)
        
        return exact, approx
    
    @staticmethod
    def plot_law_of_large_numbers():
        """绘制大数定律演示"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        distributions = [
            ('uniform', (0, 1), 'U(0,1)'),
            ('exponential', 1, 'Exp(1)'),
            ('normal', (5, 2), 'N(5,4)'),
            ('chi2', 3, 'χ²(3)')
        ]
        
        for idx, (ax, (dist, params, name)) in enumerate(zip(axes.flat, distributions)):
            lln = LawOfLargeNumbers()
            
            n_values, cum_means, true_mean = lln.simulate_law_of_large_numbers(
                dist, params, n_max=5000)
            
            ax.plot(n_values, cum_means, 'b-', linewidth=1, alpha=0.7,
                   label='样本均值')
            ax.axhline(true_mean, color='r', linestyle='--', linewidth=2,
                      label=f'理论均值 μ={true_mean:.2f}')
            
            # 置信带（±2σ/√n）
            if dist == 'uniform':
                a, b = params
                sigma = np.sqrt((b - a)**2 / 12)
            elif dist == 'exponential':
                sigma = 1 / params
            elif dist == 'normal':
                sigma = params[1]
            
            upper = true_mean + 2 * sigma / np.sqrt(n_values)
            lower = true_mean - 2 * sigma / np.sqrt(n_values)
            
            ax.fill_between(n_values[::10], lower[::10], upper[::10],
                           alpha=0.2, color='green', label='95%置信区间')
            
            ax.set_xlabel('样本量 n', fontsize=11)
            ax.set_ylabel('累计均值', fontsize=11)
            ax.set_title(f'大数定律：{name}', fontsize=13)
            ax.legend(loc='best')
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('law_of_large_numbers.png', dpi=300)
        plt.show()
    
    @staticmethod
    def plot_central_limit_theorem():
        """绘制中心极限定理演示"""
        fig, axes = plt.subplots(3, 3, figsize=(18, 16))
        
        # 三种分布
        distributions = [
            ('uniform', (0, 1), 'U(0,1)'),
            ('exponential', 1, 'Exp(1)'),
            ('chi2', 2, 'χ²(2)')
        ]
        
        # 三种样本量
        sample_sizes = [5, 30, 100]
        
        for row, (dist, params, name) in enumerate(distributions):
            for col, n in enumerate(sample_sizes):
                ax = axes[row, col]
                
                lln = LawOfLargeNumbers()
                sample_means, standardized, mu, sigma = \
                    lln.simulate_clt(dist, params, n, n_samples=10000)
                
                # 绘制标准化后的直方图
                ax.hist(standardized, bins=50, density=True, alpha=0.6,
                       color='skyblue', edgecolor='black', label='样本均值（标准化）')
                
                # 标准正态分布曲线
                x = np.linspace(-4, 4, 200)
                ax.plot(x, stats.norm.pdf(x), 'r-', linewidth=2.5,
                       label='N(0,1)')
                
                ax.set_xlabel('(X̄-μ)/(σ/√n)', fontsize=10)
                ax.set_ylabel('密度', fontsize=10)
                ax.set_title(f'{name}, n={n}', fontsize=12)
                ax.legend(loc='upper right', fontsize=9)
                ax.grid(True, alpha=0.3)
                ax.set_xlim([-4, 4])
        
        plt.suptitle('中心极限定理：不同分布、不同样本量', fontsize=16, y=0.995)
        plt.tight_layout()
        plt.savefig('central_limit_theorem.png', dpi=300)
        plt.show()

# 示例1：切比雪夫不等式
print("="*60)
print("示例1：切比雪夫不等式")
print("="*60)

lln = LawOfLargeNumbers()

mu = 100
sigma = 15
epsilons = [10, 20, 30]

print(f"随机变量 X ~ 均值μ={mu}, 标准差σ={sigma}")

print(f"\n切比雪夫不等式：P(|X-μ| < ε) ≥ 1 - σ²/ε²")
print(f"\n{'ε':>6s} {'下界':>10s} {'含义':>40s}")
print("-" * 60)

for eps in epsilons:
    lower_bound = lln.chebyshev_inequality(mu, sigma, eps)
    print(f"{eps:6d} {lower_bound:10.4f}    "
          f"P({mu-eps} < X < {mu+eps}) ≥ {lower_bound:.4f}")

# 蒙特卡洛验证
print(f"\n蒙特卡洛验证（N(100,225)，10万次）:")
samples = np.random.normal(mu, sigma, 100000)

for eps in epsilons:
    actual_prob = np.mean(np.abs(samples - mu) < eps)
    lower_bound = lln.chebyshev_inequality(mu, sigma, eps)
    
    print(f"  ε={eps}: 实际概率={actual_prob:.4f}, "
          f"切比雪夫下界={lower_bound:.4f}, "
          f"{'✓满足' if actual_prob >= lower_bound else '✗不满足'}")

# 示例2：大数定律模拟
print("\n" + "="*60)
print("示例2：大数定律收敛演示")
print("="*60)

# 指数分布 Exp(1)
n_values, cum_means, true_mean = lln.simulate_law_of_large_numbers(
    'exponential', 1, n_max=10000)

print(f"指数分布 Exp(1), 理论均值 μ = {true_mean}")

checkpoints = [10, 100, 1000, 10000]
print(f"\n{'n':>8s} {'样本均值':>12s} {'误差':>12s}")
print("-" * 35)

for n in checkpoints:
    idx = n - 1
    sample_mean = cum_means[idx]
    error = abs(sample_mean - true_mean)
    
    print(f"{n:8d} {sample_mean:12.6f} {error:12.6f}")

print("\n随着n增大，样本均值收敛到理论均值！")

# 示例3：中心极限定理
print("\n" + "="*60)
print("示例3：中心极限定理演示")
print("="*60)

# 均匀分布U(0,1)
dist = 'uniform'
params = (0, 1)
mu_theory = 0.5
sigma_theory = np.sqrt(1/12)

print(f"原始分布: U(0,1), μ={mu_theory}, σ={sigma_theory:.4f}")

for n in [5, 30, 100]:
    sample_means, standardized, mu, sigma = lln.simulate_clt(
        dist, params, n, n_samples=10000)
    
    # 正态性检验（KS检验）
    ks_stat, p_value = stats.kstest(standardized, 'norm')
    
    print(f"\n样本量 n={n}:")
    print(f"  样本均值的均值: {np.mean(sample_means):.4f} (理论{mu:.4f})")
    print(f"  样本均值的标准差: {np.std(sample_means):.4f} "
          f"(理论{sigma/np.sqrt(n):.4f})")
    print(f"  标准化后的KS检验: p={p_value:.4f} "
          f"({'拒绝' if p_value < 0.05 else '接受'}H₀:正态分布)")

# 示例4：二项分布正态近似
print("\n" + "="*60)
print("示例4：二项分布的正态近似")
print("="*60)

n_binom = 100
p_binom = 0.3

print(f"二项分布 B({n_binom}, {p_binom})")
print(f"正态近似: N({n_binom*p_binom}, {n_binom*p_binom*(1-p_binom):.2f})")

# 检验np(1-p)条件
condition = n_binom * p_binom * (1 - p_binom)
print(f"\nnp(1-p) = {condition:.1f} > 9? {'✓是' if condition > 9 else '✗否'}")

print(f"\n{'k':>6s} {'精确值':>12s} {'正态近似':>12s} {'相对误差':>12s}")
print("-" * 48)

k_values = [20, 25, 30, 35, 40]

for k in k_values:
    exact, approx = lln.binomial_normal_approximation(n_binom, p_binom, k)
    rel_error = abs(exact - approx) / exact * 100
    
    print(f"{k:6d} {exact:12.6f} {approx:12.6f} {rel_error:11.2f}%")

# 绘制大数定律
print("\n绘制大数定律收敛图...")
lln.plot_law_of_large_numbers()

# 绘制中心极限定理
print("绘制中心极限定理分布图...")
lln.plot_central_limit_theorem()
```

---

## 三、典型考题

### 【例题1】切比雪夫不等式（10分）

**题目**：$X \sim N(10, 4)$，用切比雪夫不等式估计$P(6 < X < 14)$的下界。

**【解答】**

$\mu = 10$，$\sigma^2 = 4$，$\sigma = 2$

$P(6 < X < 14) = P(|X - 10| < 4)$

由切比雪夫不等式：
$$P(|X - \mu| < \varepsilon) \geq 1 - \frac{\sigma^2}{\varepsilon^2}$$

$$P(|X - 10| < 4) \geq 1 - \frac{4}{16} = 0.75$$

**注**：实际$P(6 < X < 14) = 0.9544$（正态分布），切比雪夫给出的是保守估计。

---

### 【例题2】大数定律应用（12分）

**题目**：抛硬币1000次，估计正面出现次数在480-520之间的概率下界。

**【解答】**

设$X_i$为第$i$次抛硬币结果（正面=1，反面=0），$p=0.5$

$S_n = \sum_{i=1}^{1000} X_i$，$E(S_n) = 1000 \times 0.5 = 500$

$D(S_n) = 1000 \times 0.5 \times 0.5 = 250$

$$P(480 < S_n < 520) = P(|S_n - 500| < 20)$$

由切比雪夫不等式：
$$P(|S_n - 500| < 20) \geq 1 - \frac{250}{400} = 0.375$$

---

### 【例题3】中心极限定理（15分）

**题目**：$X_i \sim U(0, 1)$独立同分布，$n=100$，求$P(\bar{X} > 0.55)$近似值。

**【解答】**

$\mu = 0.5$，$\sigma^2 = \frac{1}{12}$，$\sigma = \frac{1}{\sqrt{12}}$

由中心极限定理：
$$\bar{X} \sim N\left(0.5, \frac{1}{1200}\right)$$

标准化：
$$P(\bar{X} > 0.55) = P\left(\frac{\bar{X} - 0.5}{1/\sqrt{1200}} > \frac{0.55 - 0.5}{1/\sqrt{1200}}\right)$$

$$= P(Z > 1.73) = 1 - \Phi(1.73) = 1 - 0.9582 = 0.0418$$

---

## 四、速记口诀

> 切比雪夫给下界  
> 大数定律看均值  
> 中心极限近正态  
> 样本越大越精确

---

**本章重点**：
- 切比雪夫不等式（概率下界）
- 大数定律（频率→概率，样本均值→总体均值）
- 中心极限定理（和的分布→正态分布）
- 二项分布正态近似

**下一章**：参数估计
