# 第8章：回归分析

**学习时间**: 4小时  
**考试频率**: ⭐⭐⭐⭐⭐  
**难度**: ⭐⭐⭐⭐⭐

---

## 一、一元线性回归

### 1.1 模型建立

**经验回归方程**：

$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x$$

**理论回归方程**：

$$Y = \beta_0 + \beta_1 x + \varepsilon, \quad \varepsilon \sim N(0, \sigma^2)$$

### 1.2 最小二乘估计

**目标**：最小化残差平方和

$$Q = \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2$$

**正规方程**：

$$\frac{\partial Q}{\partial \hat{\beta}_0} = 0, \quad \frac{\partial Q}{\partial \hat{\beta}_1} = 0$$

**解**：

$$\hat{\beta}_1 = \frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sum(x_i - \bar{x})^2} = \frac{L_{xy}}{L_{xx}}$$

$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$$

**简化公式**：

$$L_{xx} = \sum x_i^2 - \frac{(\sum x_i)^2}{n}$$

$$L_{yy} = \sum y_i^2 - \frac{(\sum y_i)^2}{n}$$

$$L_{xy} = \sum x_i y_i - \frac{\sum x_i \sum y_i}{n}$$

---

## 二、回归方程显著性检验

### 2.1 相关系数

**样本相关系数**：

$$r = \frac{L_{xy}}{\sqrt{L_{xx} L_{yy}}}$$

**性质**：
- $-1 \leq r \leq 1$
- $|r|$越接近1，线性相关越强
- $r > 0$：正相关；$r < 0$：负相关

### 2.2 决定系数

**定义**：

$$R^2 = \frac{SS_R}{SS_T} = 1 - \frac{SS_E}{SS_T}$$

- $SS_T = \sum(y_i - \bar{y})^2$：总平方和
- $SS_R = \sum(\hat{y}_i - \bar{y})^2$：回归平方和
- $SS_E = \sum(y_i - \hat{y}_i)^2$：残差平方和

**关系**：$R^2 = r^2$（一元回归）

**意义**：$R^2$越接近1，拟合越好

### 2.3 F检验

**假设**：

$$H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \neq 0$$

**检验统计量**：

$$F = \frac{SS_R / 1}{SS_E / (n-2)} = \frac{MS_R}{MS_E}$$

在$H_0$下，$F \sim F(1, n-2)$

**拒绝域**：$F > F_\alpha(1, n-2)$

---

## 三、回归系数的检验与估计

### 3.1 t检验

**检验$\beta_1$**：

$$t = \frac{\hat{\beta}_1}{\sqrt{\hat{\sigma}^2 / L_{xx}}} \sim t(n-2)$$

其中$\hat{\sigma}^2 = \frac{SS_E}{n-2}$

### 3.2 置信区间

**$\beta_1$的置信区间**：

$$\hat{\beta}_1 \pm t_{\alpha/2}(n-2) \cdot \sqrt{\frac{\hat{\sigma}^2}{L_{xx}}}$$

**均值$E(Y|x_0)$的置信区间**：

$$\hat{y}_0 \pm t_{\alpha/2}(n-2) \cdot \hat{\sigma} \sqrt{\frac{1}{n} + \frac{(x_0-\bar{x})^2}{L_{xx}}}$$

### 3.3 预测区间

**个体$Y_0$的预测区间**：

$$\hat{y}_0 \pm t_{\alpha/2}(n-2) \cdot \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_0-\bar{x})^2}{L_{xx}}}$$

---

## 四、多元线性回归

### 4.1 模型

$$Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p + \varepsilon$$

**矩阵形式**：

$$\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon}$$

### 4.2 最小二乘估计

$$\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$$

### 4.3 多重判定系数

$$R^2 = 1 - \frac{SS_E}{SS_T}$$

**调整$R^2$**：

$$R_a^2 = 1 - \frac{SS_E/(n-p-1)}{SS_T/(n-1)}$$

---

## 五、残差分析

### 5.1 残差检验

**标准化残差**：

$$e_i^* = \frac{e_i}{\hat{\sigma}\sqrt{1 - h_{ii}}}$$

其中$h_{ii}$为帽子矩阵对角元

### 5.2 正态性检验

- Q-Q图
- Shapiro-Wilk检验

### 5.3 异方差检验

- 残差图
- White检验

---

## 六、Python实现

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import pandas as pd

class LinearRegression:
    """线性回归分析"""
    
    def __init__(self):
        self.beta0 = None
        self.beta1 = None
        self.fitted = False
    
    def fit(self, X, y):
        """
        拟合一元线性回归
        
        参数:
            X: 自变量（一维数组）
            y: 因变量（一维数组）
        """
        X = np.array(X)
        y = np.array(y)
        n = len(X)
        
        # 计算统计量
        x_bar = np.mean(X)
        y_bar = np.mean(y)
        
        L_xx = np.sum((X - x_bar)**2)
        L_yy = np.sum((y - y_bar)**2)
        L_xy = np.sum((X - x_bar) * (y - y_bar))
        
        # 回归系数
        self.beta1 = L_xy / L_xx
        self.beta0 = y_bar - self.beta1 * x_bar
        
        # 拟合值和残差
        y_pred = self.beta0 + self.beta1 * X
        residuals = y - y_pred
        
        # 平方和
        SS_T = L_yy
        SS_R = np.sum((y_pred - y_bar)**2)
        SS_E = np.sum(residuals**2)
        
        # 相关系数和决定系数
        self.r = L_xy / np.sqrt(L_xx * L_yy)
        self.R2 = SS_R / SS_T
        
        # 误差方差估计
        self.sigma_sq = SS_E / (n - 2)
        
        # 存储数据和结果
        self.X = X
        self.y = y
        self.n = n
        self.y_pred = y_pred
        self.residuals = residuals
        self.SS_T = SS_T
        self.SS_R = SS_R
        self.SS_E = SS_E
        self.L_xx = L_xx
        self.x_bar = x_bar
        self.y_bar = y_bar
        
        self.fitted = True
        
        return self
    
    def predict(self, X_new):
        """预测"""
        if not self.fitted:
            raise ValueError("模型未拟合")
        
        X_new = np.array(X_new)
        return self.beta0 + self.beta1 * X_new
    
    def summary(self):
        """输出回归结果摘要"""
        if not self.fitted:
            raise ValueError("模型未拟合")
        
        # t检验
        se_beta1 = np.sqrt(self.sigma_sq / self.L_xx)
        t_stat = self.beta1 / se_beta1
        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), self.n - 2))
        
        # F检验
        MS_R = self.SS_R / 1
        MS_E = self.SS_E / (self.n - 2)
        F_stat = MS_R / MS_E
        F_p_value = 1 - stats.f.cdf(F_stat, 1, self.n - 2)
        
        print("="*60)
        print("一元线性回归摘要")
        print("="*60)
        print(f"样本量 n = {self.n}")
        print(f"\n回归方程:")
        print(f"  ŷ = {self.beta0:.4f} + {self.beta1:.4f}x")
        print(f"\n回归系数:")
        print(f"  β₀ (截距) = {self.beta0:.4f}")
        print(f"  β₁ (斜率) = {self.beta1:.4f}")
        print(f"    标准误 = {se_beta1:.4f}")
        print(f"    t统计量 = {t_stat:.3f}")
        print(f"    p值 = {p_value:.4f}")
        print(f"\n模型评价:")
        print(f"  相关系数 r = {self.r:.4f}")
        print(f"  决定系数 R² = {self.R2:.4f}")
        print(f"  残差标准误 σ̂ = {np.sqrt(self.sigma_sq):.4f}")
        print(f"\n方差分析:")
        print(f"  回归平方和 SS_R = {self.SS_R:.2f}")
        print(f"  残差平方和 SS_E = {self.SS_E:.2f}")
        print(f"  总平方和 SS_T = {self.SS_T:.2f}")
        print(f"  F统计量 = {F_stat:.3f}")
        print(f"  p值 = {F_p_value:.4f}")
        
        if F_p_value < 0.05:
            print(f"\n结论：回归方程显著（p < 0.05）")
        else:
            print(f"\n结论：回归方程不显著（p ≥ 0.05）")
        
        print("="*60)
    
    def confidence_interval(self, x0, alpha=0.05, interval_type='mean'):
        """
        计算置信区间或预测区间
        
        参数:
            x0: 预测点
            alpha: 显著性水平
            interval_type: 'mean'均值置信区间, 'prediction'个体预测区间
        """
        if not self.fitted:
            raise ValueError("模型未拟合")
        
        y0_hat = self.predict(x0)
        t_crit = stats.t.ppf(1 - alpha/2, self.n - 2)
        
        if interval_type == 'mean':
            # 均值置信区间
            se = np.sqrt(self.sigma_sq * (1/self.n + (x0 - self.x_bar)**2 / self.L_xx))
        else:
            # 预测区间
            se = np.sqrt(self.sigma_sq * (1 + 1/self.n + (x0 - self.x_bar)**2 / self.L_xx))
        
        lower = y0_hat - t_crit * se
        upper = y0_hat + t_crit * se
        
        return y0_hat, lower, upper
    
    def plot_regression_analysis(self):
        """绘制回归分析图"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. 散点图和回归线
        ax1 = axes[0, 0]
        
        ax1.scatter(self.X, self.y, s=100, alpha=0.7, color='blue',
                   edgecolors='black', linewidth=1.5, label='观测值')
        
        # 回归线
        X_line = np.linspace(self.X.min(), self.X.max(), 100)
        y_line = self.predict(X_line)
        ax1.plot(X_line, y_line, 'r-', linewidth=2.5, label='回归线')
        
        # 置信带
        for x0 in X_line:
            _, lower, upper = self.confidence_interval(x0, interval_type='mean')
            ax1.plot([x0, x0], [lower, upper], 'g-', alpha=0.1, linewidth=1)
        
        # 残差线
        for i in range(self.n):
            ax1.plot([self.X[i], self.X[i]], [self.y[i], self.y_pred[i]],
                    'k--', alpha=0.3, linewidth=1)
        
        ax1.set_xlabel('X', fontsize=11)
        ax1.set_ylabel('Y', fontsize=11)
        ax1.set_title(f'回归分析散点图\nŷ = {self.beta0:.2f} + {self.beta1:.2f}x, R²={self.R2:.3f}',
                     fontsize=13, fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. 残差图
        ax2 = axes[0, 1]
        
        ax2.scatter(self.y_pred, self.residuals, s=100, alpha=0.7,
                   color='purple', edgecolors='black', linewidth=1.5)
        ax2.axhline(0, color='r', linestyle='--', linewidth=2)
        
        # 标准化残差界限（±2σ）
        sigma_hat = np.sqrt(self.sigma_sq)
        ax2.axhline(2*sigma_hat, color='orange', linestyle=':', linewidth=2,
                   label='±2σ̂')
        ax2.axhline(-2*sigma_hat, color='orange', linestyle=':', linewidth=2)
        
        ax2.set_xlabel('拟合值 ŷ', fontsize=11)
        ax2.set_ylabel('残差 e', fontsize=11)
        ax2.set_title('残差图（检验异方差）', fontsize=13, fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. 残差正态Q-Q图
        ax3 = axes[1, 0]
        
        # 标准化残差
        residuals_std = self.residuals / np.sqrt(self.sigma_sq)
        residuals_std_sorted = np.sort(residuals_std)
        
        # 理论分位数
        theoretical_quantiles = stats.norm.ppf(
            (np.arange(1, self.n + 1) - 0.5) / self.n)
        
        ax3.scatter(theoretical_quantiles, residuals_std_sorted,
                   s=100, alpha=0.7, color='green',
                   edgecolors='black', linewidth=1.5)
        
        # 参考线
        ax3.plot(theoretical_quantiles, theoretical_quantiles,
                'r--', linewidth=2.5, label='理论线')
        
        ax3.set_xlabel('理论分位数', fontsize=11)
        ax3.set_ylabel('样本分位数', fontsize=11)
        ax3.set_title('Q-Q图（检验正态性）', fontsize=13, fontweight='bold')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. 置信区间和预测区间
        ax4 = axes[1, 1]
        
        ax4.scatter(self.X, self.y, s=100, alpha=0.7, color='blue',
                   edgecolors='black', linewidth=1.5, label='观测值')
        
        # 回归线
        ax4.plot(X_line, y_line, 'r-', linewidth=2.5, label='回归线')
        
        # 置信区间
        ci_lower = []
        ci_upper = []
        pi_lower = []
        pi_upper = []
        
        for x0 in X_line:
            _, cl, cu = self.confidence_interval(x0, interval_type='mean')
            _, pl, pu = self.confidence_interval(x0, interval_type='prediction')
            ci_lower.append(cl)
            ci_upper.append(cu)
            pi_lower.append(pl)
            pi_upper.append(pu)
        
        ax4.fill_between(X_line, ci_lower, ci_upper,
                        alpha=0.3, color='green', label='95%置信区间（均值）')
        ax4.fill_between(X_line, pi_lower, pi_upper,
                        alpha=0.2, color='orange', label='95%预测区间（个体）')
        
        ax4.set_xlabel('X', fontsize=11)
        ax4.set_ylabel('Y', fontsize=11)
        ax4.set_title('置信区间与预测区间', fontsize=13, fontweight='bold')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('regression_analysis.png', dpi=300)
        plt.show()

# 示例计算
print("="*60)
print("回归分析")
print("="*60)

# 示例数据：身高(cm)与体重(kg)
height = np.array([165, 170, 175, 180, 185, 160, 172, 178, 168, 182])
weight = np.array([55, 62, 68, 75, 80, 50, 65, 72, 58, 78])

print("数据：身高(cm)与体重(kg)")
data_df = pd.DataFrame({'身高': height, '体重': weight})
print(data_df)

# 拟合模型
model = LinearRegression()
model.fit(height, weight)

# 输出摘要
print("\n")
model.summary()

# 预测
print("\n" + "="*60)
print("预测示例：")
x_new = 176
y_pred, ci_lower, ci_upper = model.confidence_interval(x_new, interval_type='mean')
_, pi_lower, pi_upper = model.confidence_interval(x_new, interval_type='prediction')

print(f"身高 x = {x_new} cm")
print(f"预测体重 ŷ = {y_pred:.2f} kg")
print(f"95%置信区间（均值）: [{ci_lower:.2f}, {ci_upper:.2f}] kg")
print(f"95%预测区间（个体）: [{pi_lower:.2f}, {pi_upper:.2f}] kg")

# 绘图
print("\n绘制回归分析图...")
model.plot_regression_analysis()
```

---

## 七、典型考题

### 【例题1】回归系数计算（15分）

**题目**：广告费$x$（万元）与销售额$y$（万元）数据：

| $x$ | 1 | 2 | 3 | 4 | 5 |
|-----|---|---|---|---|---|
| $y$ | 3 | 5 | 6 | 8 | 9 |

求回归方程。

**【解答】**

$n=5$，$\sum x = 15$，$\sum y = 31$

$$\bar{x} = 3, \quad \bar{y} = 6.2$$

$$L_{xx} = (1^2+2^2+\cdots+5^2) - \frac{15^2}{5} = 55 - 45 = 10$$

$$L_{xy} = (1 \times 3 + 2 \times 5 + \cdots + 5 \times 9) - \frac{15 \times 31}{5} = 103 - 93 = 10$$

$$\hat{\beta}_1 = \frac{10}{10} = 1.0$$

$$\hat{\beta}_0 = 6.2 - 1.0 \times 3 = 3.2$$

**回归方程**：$\hat{y} = 3.2 + 1.0x$

---

**本章重点**：
- 最小二乘法
- 回归方程显著性检验
- 置信区间与预测区间
- 残差分析

**全书完成！**
